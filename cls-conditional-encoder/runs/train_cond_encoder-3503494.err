/home/nklotts/.conda/envs/pgwtd/lib/python3.9/site-packages/wandb/apis/public.py:3109: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import parse_version
/home/nklotts/tencdm/model/enc_normalizer.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(enc_mean_path, map_location=location)[None, None, :],
/home/nklotts/tencdm/model/enc_normalizer.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(enc_std_path, map_location=location)[None, None, :],
/home/nklotts/.conda/envs/pgwtd/lib/python3.9/site-packages/wandb/apis/public.py:3109: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import parse_version
wandb: Tracking run with wandb version 0.15.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Dataset preprocessing (num_proc=30):   0%|          | 0/88161 [00:00<?, ? examples/s]Dataset preprocessing (num_proc=30):   3%|▎         | 2939/88161 [00:00<00:13, 6313.70 examples/s]Dataset preprocessing (num_proc=30):   7%|▋         | 5878/88161 [00:00<00:08, 10059.70 examples/s]Dataset preprocessing (num_proc=30):  10%|█         | 8817/88161 [00:00<00:06, 12223.07 examples/s]Dataset preprocessing (num_proc=30):  13%|█▎        | 11756/88161 [00:01<00:06, 12531.73 examples/s]Dataset preprocessing (num_proc=30):  17%|█▋        | 14695/88161 [00:01<00:06, 11824.70 examples/s]Dataset preprocessing (num_proc=30):  23%|██▎       | 20573/88161 [00:01<00:04, 14941.02 examples/s]Dataset preprocessing (num_proc=30):  27%|██▋       | 23512/88161 [00:01<00:04, 14985.39 examples/s]Dataset preprocessing (num_proc=30):  30%|███       | 26451/88161 [00:01<00:04, 15016.62 examples/s]Dataset preprocessing (num_proc=30):  33%|███▎      | 29390/88161 [00:02<00:04, 13879.99 examples/s]Dataset preprocessing (num_proc=30):  40%|████      | 35268/88161 [00:02<00:03, 16261.61 examples/s]Dataset preprocessing (num_proc=30):  43%|████▎     | 38207/88161 [00:02<00:03, 15731.87 examples/s]Dataset preprocessing (num_proc=30):  47%|████▋     | 41146/88161 [00:02<00:02, 17524.90 examples/s]Dataset preprocessing (num_proc=30):  50%|█████     | 44085/88161 [00:03<00:02, 16393.47 examples/s]Dataset preprocessing (num_proc=30):  53%|█████▎    | 47024/88161 [00:03<00:02, 17506.38 examples/s]Dataset preprocessing (num_proc=30):  57%|█████▋    | 49963/88161 [00:03<00:02, 15510.22 examples/s]Dataset preprocessing (num_proc=30):  60%|██████    | 52902/88161 [00:03<00:02, 17462.31 examples/s]Dataset preprocessing (num_proc=30):  63%|██████▎   | 55841/88161 [00:03<00:01, 16981.21 examples/s]Dataset preprocessing (num_proc=30):  67%|██████▋   | 58780/88161 [00:03<00:01, 17822.34 examples/s]Dataset preprocessing (num_proc=30):  70%|███████   | 61719/88161 [00:04<00:01, 17325.84 examples/s]Dataset preprocessing (num_proc=30):  73%|███████▎  | 64657/88161 [00:04<00:01, 15710.18 examples/s]Dataset preprocessing (num_proc=30):  77%|███████▋  | 67595/88161 [00:04<00:01, 17980.87 examples/s]Dataset preprocessing (num_proc=30):  80%|████████  | 70533/88161 [00:04<00:01, 16939.88 examples/s]Dataset preprocessing (num_proc=30):  83%|████████▎ | 73471/88161 [00:04<00:00, 16349.81 examples/s]Dataset preprocessing (num_proc=30):  87%|████████▋ | 76409/88161 [00:04<00:00, 16321.48 examples/s]Dataset preprocessing (num_proc=30):  90%|█████████ | 79347/88161 [00:05<00:00, 14950.51 examples/s]Dataset preprocessing (num_proc=30):  93%|█████████▎| 82285/88161 [00:05<00:00, 14230.34 examples/s]Dataset preprocessing (num_proc=30):  97%|█████████▋| 85223/88161 [00:05<00:00, 16420.27 examples/s]Dataset preprocessing (num_proc=30): 100%|██████████| 88161/88161 [00:05<00:00, 17659.23 examples/s]Dataset preprocessing (num_proc=30): 100%|██████████| 88161/88161 [00:05<00:00, 15072.94 examples/s]
Dataset preprocessing (num_proc=30):   0%|          | 0/10000 [00:00<?, ? examples/s]Dataset preprocessing (num_proc=30):   3%|▎         | 334/10000 [00:00<00:05, 1879.81 examples/s]Dataset preprocessing (num_proc=30):  17%|█▋        | 1670/10000 [00:00<00:01, 6344.17 examples/s]Dataset preprocessing (num_proc=30):  33%|███▎      | 3340/10000 [00:00<00:00, 8719.98 examples/s]Dataset preprocessing (num_proc=30):  53%|█████▎    | 5338/10000 [00:00<00:00, 11787.35 examples/s]Dataset preprocessing (num_proc=30):  67%|██████▋   | 6670/10000 [00:00<00:00, 11998.59 examples/s]Dataset preprocessing (num_proc=30):  83%|████████▎ | 8335/10000 [00:00<00:00, 12650.60 examples/s]Dataset preprocessing (num_proc=30): 100%|██████████| 10000/10000 [00:00<00:00, 13563.85 examples/s]Dataset preprocessing (num_proc=30): 100%|██████████| 10000/10000 [00:00<00:00, 10157.01 examples/s]
  0%|          | 0/1378 [00:00<?, ?it/s]
=== RAW TEXT CHECK ===
text_src[0]: 'It was Christmas morning. Gary was trying to help his kids open their toys. The doll he was trying to get was wrapped in plastic.'
text_trg[0]: 'He couldn't get the ties undone. Finally, he had to grab a knife just to free the toy.'
Are texts identical? False

=== TOKENIZATION CHECK ===
src input_ids[0]: tensor([  101,  1135,  1108,  3394,  2106,   119,  4926,  1108,  1774,  1106,
         1494,  1117,  4067,  1501,  1147, 12967,   119,  1109, 13559,  1119,
         1108,  1774,  1106,  1243,  1108,  4293,  1107,  5828,   119,   102,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0],
       device='cuda:0')
trg input_ids[0]: tensor([  101,  1124,  1577,   112,   189,  1243,  1103,  7057,  5576,  4798,
          119,  4428,   117,  1119,  1125,  1106,  6387,   170,  4937,  1198,
         1106,  1714,  1103, 10929,   119,   102,     0,     0,     0,     0,
            0,     0,     0,     0,     0], device='cuda:0')
Are input_ids identical? False

=== EMBEDDINGS ===
cls_src shape: torch.Size([64, 768])
cls_trg shape: torch.Size([64, 768])
src mean: -0.0073, std: 0.5908
trg mean: -0.0074, std: 0.5935

=== COSINE SIMILARITY ===
POSITIVE pairs: 0.9655 ± 0.0103
NEGATIVE pairs: 0.9463 ± 0.0120
Difference: 0.0192
Pos src: It was Christmas morning. Gary was trying to help ...
Pos trg: He couldn't get the ties undone. Finally, he had t...
Neg trg: Finally I ended up winning. I was thrilled....
---
Pos src: Crystal decided to learn how to sew. She worked ha...
Pos trg: She had created a beautiful pillowcase! Crystal de...
Neg trg: When he got home he drank all the booze. Weeks wen...
---
Pos src: Luke drove a semi for a living. He was on the road...
Pos trg: He hated being gone all the time. Luke decided to ...
Neg trg: He goes through his coins every time he is given c...
---

=== LOSS & METRICS ===
loss_pos: 0.6726
loss_neg: 0.7099
total loss: 0.6913

Probs positive (first 5): tensor([0.5358, 0.5027, 0.5241, 0.5089, 0.5224], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5135, 0.5129, 0.4841, 0.5317, 0.5053], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5105
probs_neg mean: 0.5082

Pred distribution: 0=25, 1=103
Label distribution: 0=64, 1=64
Accuracy positive: 0.8438
Accuracy negative: 0.2344
  0%|          | 0/1378 [00:00<?, ?it/s, Stage=Training, Epoch=1/5, Loss=0.691]  0%|          | 1/1378 [00:00<16:02,  1.43it/s, Stage=Training, Epoch=1/5, Loss=0.691]Pos src: Tiffany wanted to grow her hair long. She decided ...
Pos trg: When the year was over she straightened her hair. ...
Neg trg: Steve went into the store and bought a loaf of bre...
---
Pos src: Jeff was addicted to coffee. He had three cups in ...
Pos trg: Not having fresh grounds he ran to the store. The ...
Neg trg: The singer tried to get better. They just kicked h...
---
Pos src: James wanted to bring a water bottle to camp. He f...
Pos trg: He realized the water bottle hadn't been rinsed we...
Neg trg: They came home and prepared tacos. The Johnsons ha...
---

=== LOSS & METRICS ===
loss_pos: 0.6749
loss_neg: 0.7197
total loss: 0.6973

Probs positive (first 5): tensor([0.5124, 0.5135, 0.5226, 0.5129, 0.5197], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5013, 0.4983, 0.5266, 0.5136, 0.5097], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5093
probs_neg mean: 0.5130

Pred distribution: 0=16, 1=112
Label distribution: 0=64, 1=64
Accuracy positive: 0.8438
Accuracy negative: 0.0938
  0%|          | 1/1378 [00:00<16:02,  1.43it/s, Stage=Training, Epoch=1/5, Loss=0.697]  0%|          | 2/1378 [00:00<09:00,  2.55it/s, Stage=Training, Epoch=1/5, Loss=0.697]Pos src: Tom liked the winter Olympics. He wanted to play a...
Pos trg: Tom found a curling arena. Tom had fun trying to p...
Neg trg: One kid got a bloody nose. Everyone had fun....
---
Pos src: Gina was just arriving home from school. It was a ...
Pos trg: She stopped in her tracks and dropped her head. Sh...
Neg trg: But 50 minutes later he remembered he forgot about...
---
Pos src: Bart was the oldest of two siblings. His brother M...
Pos trg: Once, he shoved Markus on the ground and made him ...
Neg trg: That night we found she had torn the bag with her ...
---

=== LOSS & METRICS ===
loss_pos: 0.6753
loss_neg: 0.7135
total loss: 0.6944

Probs positive (first 5): tensor([0.4991, 0.4883, 0.5204, 0.5020, 0.5107], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5069, 0.5050, 0.4917, 0.5043, 0.5091], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5091
probs_neg mean: 0.5100

Pred distribution: 0=16, 1=112
Label distribution: 0=64, 1=64
Accuracy positive: 0.8281
Accuracy negative: 0.0781
  0%|          | 2/1378 [00:01<09:00,  2.55it/s, Stage=Training, Epoch=1/5, Loss=0.694]  0%|          | 3/1378 [00:01<07:23,  3.10it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6685
loss_neg: 0.7124
total loss: 0.6905

Probs positive (first 5): tensor([0.5166, 0.4992, 0.5063, 0.5031, 0.5094], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5041, 0.5071, 0.5212, 0.4998, 0.5071], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5125
probs_neg mean: 0.5095

Pred distribution: 0=15, 1=113
Label distribution: 0=64, 1=64
Accuracy positive: 0.8906
Accuracy negative: 0.1250
  0%|          | 3/1378 [00:01<07:23,  3.10it/s, Stage=Training, Epoch=1/5, Loss=0.69]   0%|          | 4/1378 [00:01<06:04,  3.77it/s, Stage=Training, Epoch=1/5, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6695
loss_neg: 0.7157
total loss: 0.6926

Probs positive (first 5): tensor([0.5102, 0.5135, 0.5229, 0.5170, 0.5200], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5047, 0.5295, 0.5301, 0.4924, 0.5096], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5120
probs_neg mean: 0.5110

Pred distribution: 0=15, 1=113
Label distribution: 0=64, 1=64
Accuracy positive: 0.9219
Accuracy negative: 0.1562
  0%|          | 4/1378 [00:01<06:04,  3.77it/s, Stage=Training, Epoch=1/5, Loss=0.693]  0%|          | 5/1378 [00:01<05:27,  4.20it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6763
loss_neg: 0.7163
total loss: 0.6963

Probs positive (first 5): tensor([0.5182, 0.5067, 0.4941, 0.5131, 0.5180], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5187, 0.5103, 0.5224, 0.4992, 0.5109], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5086
probs_neg mean: 0.5114

Pred distribution: 0=20, 1=108
Label distribution: 0=64, 1=64
Accuracy positive: 0.7812
Accuracy negative: 0.0938
  0%|          | 5/1378 [00:01<05:27,  4.20it/s, Stage=Training, Epoch=1/5, Loss=0.696]  0%|          | 6/1378 [00:01<05:04,  4.50it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6759
loss_neg: 0.7113
total loss: 0.6936

Probs positive (first 5): tensor([0.5148, 0.5055, 0.5204, 0.5050, 0.5084], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5082, 0.4919, 0.5187, 0.5114, 0.5000], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5088
probs_neg mean: 0.5089

Pred distribution: 0=18, 1=110
Label distribution: 0=64, 1=64
Accuracy positive: 0.8594
Accuracy negative: 0.1406
  0%|          | 6/1378 [00:01<05:04,  4.50it/s, Stage=Training, Epoch=1/5, Loss=0.694]  1%|          | 7/1378 [00:01<04:44,  4.82it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6681
loss_neg: 0.7113
total loss: 0.6897

Probs positive (first 5): tensor([0.5086, 0.5029, 0.5051, 0.5010, 0.5048], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5046, 0.5060, 0.5135, 0.5038, 0.4963], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5128
probs_neg mean: 0.5089

Pred distribution: 0=16, 1=112
Label distribution: 0=64, 1=64
Accuracy positive: 0.9219
Accuracy negative: 0.1719
  1%|          | 7/1378 [00:02<04:44,  4.82it/s, Stage=Training, Epoch=1/5, Loss=0.69]   1%|          | 8/1378 [00:02<04:36,  4.95it/s, Stage=Training, Epoch=1/5, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6696
loss_neg: 0.7123
total loss: 0.6910

Probs positive (first 5): tensor([0.5010, 0.5040, 0.5295, 0.5085, 0.5379], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5149, 0.4985, 0.4928, 0.5362, 0.5157], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5120
probs_neg mean: 0.5094

Pred distribution: 0=17, 1=111
Label distribution: 0=64, 1=64
Accuracy positive: 0.9219
Accuracy negative: 0.1875
  1%|          | 8/1378 [00:02<04:36,  4.95it/s, Stage=Training, Epoch=1/5, Loss=0.691]  1%|          | 9/1378 [00:02<04:22,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6715
loss_neg: 0.7165
total loss: 0.6940

Probs positive (first 5): tensor([0.5099, 0.5063, 0.5077, 0.5175, 0.5201], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5040, 0.5103, 0.4981, 0.5233, 0.5007], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5110
probs_neg mean: 0.5114

Pred distribution: 0=14, 1=114
Label distribution: 0=64, 1=64
Accuracy positive: 0.9375
Accuracy negative: 0.1562
  1%|          | 9/1378 [00:02<04:22,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.694]  1%|          | 10/1378 [00:02<04:06,  5.55it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6745
loss_neg: 0.7108
total loss: 0.6927

Probs positive (first 5): tensor([0.5175, 0.5090, 0.5185, 0.5163, 0.5139], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4977, 0.5126, 0.5098, 0.4992, 0.5255], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5095
probs_neg mean: 0.5087

Pred distribution: 0=24, 1=104
Label distribution: 0=64, 1=64
Accuracy positive: 0.8281
Accuracy negative: 0.2031
  1%|          | 10/1378 [00:02<04:06,  5.55it/s, Stage=Training, Epoch=1/5, Loss=0.693]  1%|          | 11/1378 [00:02<04:00,  5.68it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6752
loss_neg: 0.7146
total loss: 0.6949

Probs positive (first 5): tensor([0.5051, 0.5291, 0.5216, 0.5075, 0.5122], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5108, 0.5219, 0.5050, 0.5107, 0.5242], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5092
probs_neg mean: 0.5105

Pred distribution: 0=18, 1=110
Label distribution: 0=64, 1=64
Accuracy positive: 0.8438
Accuracy negative: 0.1250
  1%|          | 11/1378 [00:02<04:00,  5.68it/s, Stage=Training, Epoch=1/5, Loss=0.695]  1%|          | 12/1378 [00:02<04:00,  5.67it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6719
loss_neg: 0.7111
total loss: 0.6915

Probs positive (first 5): tensor([0.5004, 0.5034, 0.5060, 0.5072, 0.5001], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5171, 0.5061, 0.5184, 0.5013, 0.5031], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5108
probs_neg mean: 0.5087

Pred distribution: 0=15, 1=113
Label distribution: 0=64, 1=64
Accuracy positive: 0.8906
Accuracy negative: 0.1250
  1%|          | 12/1378 [00:02<04:00,  5.67it/s, Stage=Training, Epoch=1/5, Loss=0.692]  1%|          | 13/1378 [00:02<04:03,  5.61it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6763
loss_neg: 0.7111
total loss: 0.6937

Probs positive (first 5): tensor([0.4956, 0.5167, 0.5152, 0.5087, 0.5081], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5015, 0.5215, 0.5008, 0.5011, 0.5038], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5086
probs_neg mean: 0.5088

Pred distribution: 0=19, 1=109
Label distribution: 0=64, 1=64
Accuracy positive: 0.7969
Accuracy negative: 0.0938
  1%|          | 13/1378 [00:03<04:03,  5.61it/s, Stage=Training, Epoch=1/5, Loss=0.694]  1%|          | 14/1378 [00:03<04:09,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6742
loss_neg: 0.7091
total loss: 0.6916

Probs positive (first 5): tensor([0.5030, 0.5113, 0.5074, 0.5009, 0.5189], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5028, 0.5046, 0.4931, 0.5150, 0.4973], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5097
probs_neg mean: 0.5078

Pred distribution: 0=25, 1=103
Label distribution: 0=64, 1=64
Accuracy positive: 0.8281
Accuracy negative: 0.2188
  1%|          | 14/1378 [00:03<04:09,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.692]  1%|          | 15/1378 [00:03<04:09,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6705
loss_neg: 0.7123
total loss: 0.6914

Probs positive (first 5): tensor([0.5005, 0.4949, 0.5048, 0.5067, 0.5092], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5207, 0.5007, 0.5067, 0.4991, 0.5011], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5115
probs_neg mean: 0.5094

Pred distribution: 0=13, 1=115
Label distribution: 0=64, 1=64
Accuracy positive: 0.9062
Accuracy negative: 0.1094
  1%|          | 15/1378 [00:03<04:09,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.691]  1%|          | 16/1378 [00:03<04:11,  5.41it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6752
loss_neg: 0.7101
total loss: 0.6926

Probs positive (first 5): tensor([0.5199, 0.5183, 0.5087, 0.5006, 0.5073], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5118, 0.4988, 0.5171, 0.5155, 0.5008], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5091
probs_neg mean: 0.5083

Pred distribution: 0=27, 1=101
Label distribution: 0=64, 1=64
Accuracy positive: 0.8125
Accuracy negative: 0.2344
  1%|          | 16/1378 [00:03<04:11,  5.41it/s, Stage=Training, Epoch=1/5, Loss=0.693]  1%|          | 17/1378 [00:03<04:13,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6732
loss_neg: 0.7105
total loss: 0.6918

Probs positive (first 5): tensor([0.5125, 0.5123, 0.5128, 0.5289, 0.5063], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4871, 0.4889, 0.5207, 0.4834, 0.5163], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5102
probs_neg mean: 0.5085

Pred distribution: 0=20, 1=108
Label distribution: 0=64, 1=64
Accuracy positive: 0.8281
Accuracy negative: 0.1406
  1%|          | 17/1378 [00:03<04:13,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.692]  1%|▏         | 18/1378 [00:03<04:14,  5.35it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6766
loss_neg: 0.7116
total loss: 0.6941

Probs positive (first 5): tensor([0.4953, 0.5133, 0.5042, 0.5034, 0.5274], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5170, 0.5109, 0.4978, 0.4997, 0.5130], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5084
probs_neg mean: 0.5091

Pred distribution: 0=20, 1=108
Label distribution: 0=64, 1=64
Accuracy positive: 0.8594
Accuracy negative: 0.1719
  1%|▏         | 18/1378 [00:04<04:14,  5.35it/s, Stage=Training, Epoch=1/5, Loss=0.694]  1%|▏         | 19/1378 [00:04<04:06,  5.52it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6743
loss_neg: 0.7068
total loss: 0.6905

Probs positive (first 5): tensor([0.5072, 0.5047, 0.5080, 0.5079, 0.5183], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5041, 0.5076, 0.5045, 0.4942, 0.5106], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5096
probs_neg mean: 0.5067

Pred distribution: 0=24, 1=104
Label distribution: 0=64, 1=64
Accuracy positive: 0.8750
Accuracy negative: 0.2500
  1%|▏         | 19/1378 [00:04<04:06,  5.52it/s, Stage=Training, Epoch=1/5, Loss=0.691]  1%|▏         | 20/1378 [00:04<04:00,  5.65it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6774
loss_neg: 0.7151
total loss: 0.6962

Probs positive (first 5): tensor([0.4837, 0.4949, 0.5198, 0.5007, 0.4961], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4917, 0.4980, 0.4999, 0.5132, 0.5211], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5081
probs_neg mean: 0.5108

Pred distribution: 0=21, 1=107
Label distribution: 0=64, 1=64
Accuracy positive: 0.7969
Accuracy negative: 0.1250
  1%|▏         | 20/1378 [00:04<04:00,  5.65it/s, Stage=Training, Epoch=1/5, Loss=0.696]  2%|▏         | 21/1378 [00:04<03:58,  5.68it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6793
loss_neg: 0.7128
total loss: 0.6960

Probs positive (first 5): tensor([0.5034, 0.5055, 0.5257, 0.5198, 0.5216], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5043, 0.5142, 0.5030, 0.5103, 0.4996], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5071
probs_neg mean: 0.5096

Pred distribution: 0=28, 1=100
Label distribution: 0=64, 1=64
Accuracy positive: 0.7344
Accuracy negative: 0.1719
  2%|▏         | 21/1378 [00:04<03:58,  5.68it/s, Stage=Training, Epoch=1/5, Loss=0.696]  2%|▏         | 22/1378 [00:04<04:05,  5.53it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6765
loss_neg: 0.7114
total loss: 0.6940

Probs positive (first 5): tensor([0.5056, 0.5141, 0.5126, 0.5279, 0.5014], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5021, 0.4943, 0.5092, 0.5116, 0.5104], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5085
probs_neg mean: 0.5090

Pred distribution: 0=17, 1=111
Label distribution: 0=64, 1=64
Accuracy positive: 0.8594
Accuracy negative: 0.1250
  2%|▏         | 22/1378 [00:04<04:05,  5.53it/s, Stage=Training, Epoch=1/5, Loss=0.694]  2%|▏         | 23/1378 [00:04<04:09,  5.43it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6788
loss_neg: 0.7188
total loss: 0.6988

Probs positive (first 5): tensor([0.5050, 0.4956, 0.5223, 0.5175, 0.5128], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4970, 0.5244, 0.5063, 0.5034, 0.5110], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5073
probs_neg mean: 0.5126

Pred distribution: 0=19, 1=109
Label distribution: 0=64, 1=64
Accuracy positive: 0.8438
Accuracy negative: 0.1406
  2%|▏         | 23/1378 [00:04<04:09,  5.43it/s, Stage=Training, Epoch=1/5, Loss=0.699]  2%|▏         | 24/1378 [00:04<04:06,  5.48it/s, Stage=Training, Epoch=1/5, Loss=0.699]
=== LOSS & METRICS ===
loss_pos: 0.6788
loss_neg: 0.7088
total loss: 0.6938

Probs positive (first 5): tensor([0.5204, 0.5171, 0.4840, 0.5033, 0.5112], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5206, 0.5082, 0.5118, 0.5048, 0.5199], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5073
probs_neg mean: 0.5077

Pred distribution: 0=30, 1=98
Label distribution: 0=64, 1=64
Accuracy positive: 0.7500
Accuracy negative: 0.2188
  2%|▏         | 24/1378 [00:05<04:06,  5.48it/s, Stage=Training, Epoch=1/5, Loss=0.694]  2%|▏         | 25/1378 [00:05<04:08,  5.44it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6780
loss_neg: 0.7131
total loss: 0.6955

Probs positive (first 5): tensor([0.5201, 0.4993, 0.5173, 0.4973, 0.5039], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4959, 0.5054, 0.5172, 0.4914, 0.5201], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5077
probs_neg mean: 0.5098

Pred distribution: 0=27, 1=101
Label distribution: 0=64, 1=64
Accuracy positive: 0.7188
Accuracy negative: 0.1406
  2%|▏         | 25/1378 [00:05<04:08,  5.44it/s, Stage=Training, Epoch=1/5, Loss=0.696]  2%|▏         | 26/1378 [00:05<04:08,  5.44it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6742
loss_neg: 0.7074
total loss: 0.6908

Probs positive (first 5): tensor([0.5130, 0.5113, 0.5149, 0.5025, 0.5117], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5046, 0.5241, 0.5021, 0.5046, 0.5052], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5096
probs_neg mean: 0.5070

Pred distribution: 0=22, 1=106
Label distribution: 0=64, 1=64
Accuracy positive: 0.8906
Accuracy negative: 0.2344
  2%|▏         | 26/1378 [00:05<04:08,  5.44it/s, Stage=Training, Epoch=1/5, Loss=0.691]  2%|▏         | 27/1378 [00:05<04:07,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6778
loss_neg: 0.7057
total loss: 0.6917

Probs positive (first 5): tensor([0.5132, 0.5034, 0.4917, 0.5018, 0.5065], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5014, 0.4907, 0.4962, 0.4932, 0.5121], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5078
probs_neg mean: 0.5061

Pred distribution: 0=29, 1=99
Label distribution: 0=64, 1=64
Accuracy positive: 0.8438
Accuracy negative: 0.2969
  2%|▏         | 27/1378 [00:05<04:07,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.692]  2%|▏         | 28/1378 [00:05<04:08,  5.44it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6786
loss_neg: 0.7071
total loss: 0.6928

Probs positive (first 5): tensor([0.5138, 0.5066, 0.5114, 0.5154, 0.5027], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5162, 0.5121, 0.5105, 0.5026, 0.5107], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5074
probs_neg mean: 0.5068

Pred distribution: 0=35, 1=93
Label distribution: 0=64, 1=64
Accuracy positive: 0.7188
Accuracy negative: 0.2656
  2%|▏         | 28/1378 [00:05<04:08,  5.44it/s, Stage=Training, Epoch=1/5, Loss=0.693]  2%|▏         | 29/1378 [00:05<04:07,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6749
loss_neg: 0.7049
total loss: 0.6899

Probs positive (first 5): tensor([0.5139, 0.5146, 0.5129, 0.5110, 0.5079], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5158, 0.5037, 0.4968, 0.5172, 0.5084], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5093
probs_neg mean: 0.5057

Pred distribution: 0=23, 1=105
Label distribution: 0=64, 1=64
Accuracy positive: 0.8594
Accuracy negative: 0.2188
  2%|▏         | 29/1378 [00:06<04:07,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.69]   2%|▏         | 30/1378 [00:06<04:03,  5.54it/s, Stage=Training, Epoch=1/5, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6812
loss_neg: 0.7068
total loss: 0.6940

Probs positive (first 5): tensor([0.4889, 0.4903, 0.5123, 0.5058, 0.5095], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4974, 0.4799, 0.5100, 0.5079, 0.5025], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5061
probs_neg mean: 0.5067

Pred distribution: 0=33, 1=95
Label distribution: 0=64, 1=64
Accuracy positive: 0.7344
Accuracy negative: 0.2500
  2%|▏         | 30/1378 [00:06<04:03,  5.54it/s, Stage=Training, Epoch=1/5, Loss=0.694]  2%|▏         | 31/1378 [00:06<03:59,  5.62it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6809
loss_neg: 0.7025
total loss: 0.6917

Probs positive (first 5): tensor([0.5169, 0.5059, 0.5007, 0.5005, 0.5036], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4918, 0.5055, 0.5034, 0.5011, 0.4965], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5062
probs_neg mean: 0.5046

Pred distribution: 0=32, 1=96
Label distribution: 0=64, 1=64
Accuracy positive: 0.7969
Accuracy negative: 0.2969
  2%|▏         | 31/1378 [00:06<03:59,  5.62it/s, Stage=Training, Epoch=1/5, Loss=0.692]  2%|▏         | 32/1378 [00:06<03:59,  5.61it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6777
loss_neg: 0.7058
total loss: 0.6918

Probs positive (first 5): tensor([0.4926, 0.5122, 0.5238, 0.5118, 0.5017], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5114, 0.5058, 0.5032, 0.4977, 0.4980], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5078
probs_neg mean: 0.5062

Pred distribution: 0=22, 1=106
Label distribution: 0=64, 1=64
Accuracy positive: 0.8594
Accuracy negative: 0.2031
  2%|▏         | 32/1378 [00:06<03:59,  5.61it/s, Stage=Training, Epoch=1/5, Loss=0.692]  2%|▏         | 33/1378 [00:06<04:00,  5.59it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6840
loss_neg: 0.7071
total loss: 0.6955

Probs positive (first 5): tensor([0.5159, 0.5098, 0.5172, 0.5021, 0.5107], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5053, 0.5166, 0.5110, 0.5293, 0.5216], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5047
probs_neg mean: 0.5068

Pred distribution: 0=37, 1=91
Label distribution: 0=64, 1=64
Accuracy positive: 0.7031
Accuracy negative: 0.2812
  2%|▏         | 33/1378 [00:06<04:00,  5.59it/s, Stage=Training, Epoch=1/5, Loss=0.696]  2%|▏         | 34/1378 [00:06<04:01,  5.56it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6751
loss_neg: 0.7049
total loss: 0.6900

Probs positive (first 5): tensor([0.5233, 0.4952, 0.5021, 0.4908, 0.5032], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5037, 0.5031, 0.5159, 0.4929, 0.4948], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5092
probs_neg mean: 0.5058

Pred distribution: 0=28, 1=100
Label distribution: 0=64, 1=64
Accuracy positive: 0.7969
Accuracy negative: 0.2344
  2%|▏         | 34/1378 [00:06<04:01,  5.56it/s, Stage=Training, Epoch=1/5, Loss=0.69]   3%|▎         | 35/1378 [00:06<04:05,  5.47it/s, Stage=Training, Epoch=1/5, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6786
loss_neg: 0.7044
total loss: 0.6915

Probs positive (first 5): tensor([0.5085, 0.5056, 0.5218, 0.5195, 0.5089], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5161, 0.5107, 0.4935, 0.5228, 0.4926], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5074
probs_neg mean: 0.5055

Pred distribution: 0=34, 1=94
Label distribution: 0=64, 1=64
Accuracy positive: 0.7812
Accuracy negative: 0.3125
  3%|▎         | 35/1378 [00:07<04:05,  5.47it/s, Stage=Training, Epoch=1/5, Loss=0.691]  3%|▎         | 36/1378 [00:07<04:06,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6808
loss_neg: 0.7098
total loss: 0.6953

Probs positive (first 5): tensor([0.5075, 0.5014, 0.5052, 0.5099, 0.4964], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5153, 0.5229, 0.5352, 0.5198, 0.4950], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5063
probs_neg mean: 0.5082

Pred distribution: 0=35, 1=93
Label distribution: 0=64, 1=64
Accuracy positive: 0.7031
Accuracy negative: 0.2500
  3%|▎         | 36/1378 [00:07<04:06,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.695]  3%|▎         | 37/1378 [00:07<04:07,  5.42it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6845
loss_neg: 0.7034
total loss: 0.6940

Probs positive (first 5): tensor([0.5210, 0.4931, 0.5003, 0.5080, 0.5213], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4992, 0.4956, 0.5052, 0.5298, 0.4974], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5044
probs_neg mean: 0.5050

Pred distribution: 0=40, 1=88
Label distribution: 0=64, 1=64
Accuracy positive: 0.6562
Accuracy negative: 0.2812
  3%|▎         | 37/1378 [00:07<04:07,  5.42it/s, Stage=Training, Epoch=1/5, Loss=0.694]  3%|▎         | 38/1378 [00:07<04:08,  5.39it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6850
loss_neg: 0.7014
total loss: 0.6932

Probs positive (first 5): tensor([0.5273, 0.5041, 0.4992, 0.5025, 0.5118], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5101, 0.5147, 0.5281, 0.5022, 0.5044], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5042
probs_neg mean: 0.5040

Pred distribution: 0=46, 1=82
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.3594
  3%|▎         | 38/1378 [00:07<04:08,  5.39it/s, Stage=Training, Epoch=1/5, Loss=0.693]  3%|▎         | 39/1378 [00:07<04:09,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6830
loss_neg: 0.7039
total loss: 0.6935

Probs positive (first 5): tensor([0.5058, 0.5064, 0.5128, 0.5006, 0.5041], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5099, 0.5106, 0.4986, 0.5177, 0.4922], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5052
probs_neg mean: 0.5052

Pred distribution: 0=36, 1=92
Label distribution: 0=64, 1=64
Accuracy positive: 0.7188
Accuracy negative: 0.2812
  3%|▎         | 39/1378 [00:07<04:09,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.693]  3%|▎         | 40/1378 [00:07<04:06,  5.43it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6835
loss_neg: 0.6999
total loss: 0.6917

Probs positive (first 5): tensor([0.5061, 0.5096, 0.5123, 0.4924, 0.4907], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5022, 0.5214, 0.5025, 0.5073, 0.4981], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5049
probs_neg mean: 0.5033

Pred distribution: 0=38, 1=90
Label distribution: 0=64, 1=64
Accuracy positive: 0.7656
Accuracy negative: 0.3594
  3%|▎         | 40/1378 [00:07<04:06,  5.43it/s, Stage=Training, Epoch=1/5, Loss=0.692]  3%|▎         | 41/1378 [00:07<03:59,  5.58it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6814
loss_neg: 0.7044
total loss: 0.6929

Probs positive (first 5): tensor([0.4955, 0.5144, 0.5060, 0.5032, 0.5018], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5134, 0.4947, 0.4861, 0.5119, 0.5192], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5060
probs_neg mean: 0.5055

Pred distribution: 0=41, 1=87
Label distribution: 0=64, 1=64
Accuracy positive: 0.6719
Accuracy negative: 0.3125
  3%|▎         | 41/1378 [00:08<03:59,  5.58it/s, Stage=Training, Epoch=1/5, Loss=0.693]  3%|▎         | 42/1378 [00:08<03:55,  5.68it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6802
loss_neg: 0.7067
total loss: 0.6934

Probs positive (first 5): tensor([0.5061, 0.5140, 0.5024, 0.5137, 0.4919], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5038, 0.5117, 0.5033, 0.5251, 0.4983], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5066
probs_neg mean: 0.5066

Pred distribution: 0=33, 1=95
Label distribution: 0=64, 1=64
Accuracy positive: 0.7188
Accuracy negative: 0.2344
  3%|▎         | 42/1378 [00:08<03:55,  5.68it/s, Stage=Training, Epoch=1/5, Loss=0.693]  3%|▎         | 43/1378 [00:08<03:56,  5.65it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6820
loss_neg: 0.7000
total loss: 0.6910

Probs positive (first 5): tensor([0.4919, 0.5100, 0.5018, 0.4936, 0.5130], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5038, 0.5052, 0.4918, 0.4760, 0.4963], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5057
probs_neg mean: 0.5034

Pred distribution: 0=44, 1=84
Label distribution: 0=64, 1=64
Accuracy positive: 0.7031
Accuracy negative: 0.3906
  3%|▎         | 43/1378 [00:08<03:56,  5.65it/s, Stage=Training, Epoch=1/5, Loss=0.691]  3%|▎         | 44/1378 [00:08<03:50,  5.80it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6868
loss_neg: 0.6994
total loss: 0.6931

Probs positive (first 5): tensor([0.5184, 0.4983, 0.5013, 0.5155, 0.5060], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5000, 0.5009, 0.5099, 0.5214, 0.5075], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5033
probs_neg mean: 0.5031

Pred distribution: 0=45, 1=83
Label distribution: 0=64, 1=64
Accuracy positive: 0.6250
Accuracy negative: 0.3281
  3%|▎         | 44/1378 [00:08<03:50,  5.80it/s, Stage=Training, Epoch=1/5, Loss=0.693]  3%|▎         | 45/1378 [00:08<03:52,  5.73it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6867
loss_neg: 0.7036
total loss: 0.6951

Probs positive (first 5): tensor([0.5122, 0.4976, 0.5018, 0.5019, 0.4937], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4986, 0.4970, 0.5051, 0.5158, 0.5030], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5033
probs_neg mean: 0.5051

Pred distribution: 0=40, 1=88
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.2656
  3%|▎         | 45/1378 [00:08<03:52,  5.73it/s, Stage=Training, Epoch=1/5, Loss=0.695]  3%|▎         | 46/1378 [00:08<03:52,  5.73it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6841
loss_neg: 0.7011
total loss: 0.6926

Probs positive (first 5): tensor([0.5047, 0.4832, 0.5074, 0.5032, 0.4995], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4915, 0.5050, 0.4939, 0.4979, 0.4950], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5046
probs_neg mean: 0.5039

Pred distribution: 0=41, 1=87
Label distribution: 0=64, 1=64
Accuracy positive: 0.6875
Accuracy negative: 0.3281
  3%|▎         | 46/1378 [00:09<03:52,  5.73it/s, Stage=Training, Epoch=1/5, Loss=0.693]  3%|▎         | 47/1378 [00:09<03:56,  5.63it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6795
loss_neg: 0.6984
total loss: 0.6890

Probs positive (first 5): tensor([0.5149, 0.4889, 0.4967, 0.5128, 0.4968], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4972, 0.5109, 0.5013, 0.5002, 0.4969], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5070
probs_neg mean: 0.5026

Pred distribution: 0=37, 1=91
Label distribution: 0=64, 1=64
Accuracy positive: 0.7812
Accuracy negative: 0.3594
  3%|▎         | 47/1378 [00:09<03:56,  5.63it/s, Stage=Training, Epoch=1/5, Loss=0.689]  3%|▎         | 48/1378 [00:09<03:58,  5.58it/s, Stage=Training, Epoch=1/5, Loss=0.689]
=== LOSS & METRICS ===
loss_pos: 0.6897
loss_neg: 0.7003
total loss: 0.6950

Probs positive (first 5): tensor([0.4979, 0.4867, 0.4978, 0.5122, 0.4883], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5140, 0.4899, 0.5130, 0.5008, 0.5035], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5018
probs_neg mean: 0.5035

Pred distribution: 0=49, 1=79
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.3594
  3%|▎         | 48/1378 [00:09<03:58,  5.58it/s, Stage=Training, Epoch=1/5, Loss=0.695]  4%|▎         | 49/1378 [00:09<04:01,  5.51it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6920
loss_neg: 0.6994
total loss: 0.6957

Probs positive (first 5): tensor([0.5005, 0.5059, 0.4971, 0.5103, 0.4891], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5081, 0.5155, 0.4876, 0.4960, 0.4975], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.5030

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.4062
  4%|▎         | 49/1378 [00:09<04:01,  5.51it/s, Stage=Training, Epoch=1/5, Loss=0.696]  4%|▎         | 50/1378 [00:09<04:07,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6884
loss_neg: 0.7006
total loss: 0.6945

Probs positive (first 5): tensor([0.5060, 0.4978, 0.5143, 0.5028, 0.4946], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5031, 0.4988, 0.5181, 0.4962, 0.5058], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5024
probs_neg mean: 0.5036

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.3906
  4%|▎         | 50/1378 [00:09<04:07,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.695]  4%|▎         | 51/1378 [00:09<04:09,  5.31it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6883
loss_neg: 0.7000
total loss: 0.6941

Probs positive (first 5): tensor([0.5034, 0.4978, 0.5024, 0.5068, 0.5037], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5096, 0.5028, 0.4976, 0.5102, 0.5198], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5025
probs_neg mean: 0.5033

Pred distribution: 0=53, 1=75
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.3906
  4%|▎         | 51/1378 [00:09<04:09,  5.31it/s, Stage=Training, Epoch=1/5, Loss=0.694]  4%|▍         | 52/1378 [00:09<03:58,  5.55it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6849
loss_neg: 0.7021
total loss: 0.6935

Probs positive (first 5): tensor([0.5046, 0.5012, 0.4945, 0.4937, 0.4989], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5042, 0.5171, 0.5196, 0.5175, 0.5171], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5042
probs_neg mean: 0.5044

Pred distribution: 0=44, 1=84
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.3281
  4%|▍         | 52/1378 [00:10<03:58,  5.55it/s, Stage=Training, Epoch=1/5, Loss=0.694]  4%|▍         | 53/1378 [00:10<03:57,  5.59it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6867
loss_neg: 0.6974
total loss: 0.6921

Probs positive (first 5): tensor([0.5010, 0.5092, 0.5026, 0.5064, 0.5119], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5164, 0.5052, 0.5173, 0.4972, 0.5037], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5033
probs_neg mean: 0.5020

Pred distribution: 0=47, 1=81
Label distribution: 0=64, 1=64
Accuracy positive: 0.6562
Accuracy negative: 0.3906
  4%|▍         | 53/1378 [00:10<03:57,  5.59it/s, Stage=Training, Epoch=1/5, Loss=0.692]  4%|▍         | 54/1378 [00:10<04:00,  5.51it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6905
loss_neg: 0.7000
total loss: 0.6952

Probs positive (first 5): tensor([0.5034, 0.5061, 0.4976, 0.4964, 0.5075], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5018, 0.5028, 0.4940, 0.5087, 0.4881], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5014
probs_neg mean: 0.5033

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.4062
  4%|▍         | 54/1378 [00:10<04:00,  5.51it/s, Stage=Training, Epoch=1/5, Loss=0.695]  4%|▍         | 55/1378 [00:10<04:02,  5.45it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6881
loss_neg: 0.6954
total loss: 0.6918

Probs positive (first 5): tensor([0.5024, 0.4975, 0.5052, 0.5046, 0.4925], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5158, 0.5121, 0.4728, 0.5144, 0.4891], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5026
probs_neg mean: 0.5010

Pred distribution: 0=50, 1=78
Label distribution: 0=64, 1=64
Accuracy positive: 0.6719
Accuracy negative: 0.4531
  4%|▍         | 55/1378 [00:10<04:02,  5.45it/s, Stage=Training, Epoch=1/5, Loss=0.692]  4%|▍         | 56/1378 [00:10<04:05,  5.38it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6883
loss_neg: 0.6954
total loss: 0.6918

Probs positive (first 5): tensor([0.4849, 0.5037, 0.5126, 0.4991, 0.4904], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5038, 0.4995, 0.5100, 0.4910, 0.4895], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5025
probs_neg mean: 0.5010

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.4062
  4%|▍         | 56/1378 [00:10<04:05,  5.38it/s, Stage=Training, Epoch=1/5, Loss=0.692]  4%|▍         | 57/1378 [00:10<04:05,  5.39it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6875
loss_neg: 0.7005
total loss: 0.6940

Probs positive (first 5): tensor([0.4930, 0.5019, 0.4903, 0.5161, 0.5036], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4975, 0.5179, 0.5300, 0.4988, 0.5161], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5029
probs_neg mean: 0.5036

Pred distribution: 0=47, 1=81
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.3750
  4%|▍         | 57/1378 [00:11<04:05,  5.39it/s, Stage=Training, Epoch=1/5, Loss=0.694]  4%|▍         | 58/1378 [00:11<03:57,  5.55it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6842
loss_neg: 0.7025
total loss: 0.6933

Probs positive (first 5): tensor([0.4944, 0.5098, 0.5019, 0.5015, 0.4963], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5036, 0.4923, 0.5083, 0.5056, 0.4917], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5046
probs_neg mean: 0.5046

Pred distribution: 0=41, 1=87
Label distribution: 0=64, 1=64
Accuracy positive: 0.6719
Accuracy negative: 0.3125
  4%|▍         | 58/1378 [00:11<03:57,  5.55it/s, Stage=Training, Epoch=1/5, Loss=0.693]  4%|▍         | 59/1378 [00:11<03:50,  5.72it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6916
loss_neg: 0.6969
total loss: 0.6943

Probs positive (first 5): tensor([0.4885, 0.5099, 0.5036, 0.4968, 0.4884], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5118, 0.4968, 0.5032, 0.4822, 0.5152], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5009
probs_neg mean: 0.5018

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.4219
  4%|▍         | 59/1378 [00:11<03:50,  5.72it/s, Stage=Training, Epoch=1/5, Loss=0.694]  4%|▍         | 60/1378 [00:11<03:51,  5.70it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6861
loss_neg: 0.7010
total loss: 0.6935

Probs positive (first 5): tensor([0.5168, 0.5029, 0.5103, 0.5103, 0.5001], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5037, 0.4854, 0.5028, 0.4980, 0.5095], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5036
probs_neg mean: 0.5038

Pred distribution: 0=44, 1=84
Label distribution: 0=64, 1=64
Accuracy positive: 0.6875
Accuracy negative: 0.3750
  4%|▍         | 60/1378 [00:11<03:51,  5.70it/s, Stage=Training, Epoch=1/5, Loss=0.694]  4%|▍         | 61/1378 [00:11<03:52,  5.67it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6866
loss_neg: 0.6977
total loss: 0.6922

Probs positive (first 5): tensor([0.4995, 0.4982, 0.5141, 0.4986, 0.4928], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5076, 0.4979, 0.5184, 0.5008, 0.5082], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5034
probs_neg mean: 0.5022

Pred distribution: 0=46, 1=82
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.3594
  4%|▍         | 61/1378 [00:11<03:52,  5.67it/s, Stage=Training, Epoch=1/5, Loss=0.692]  4%|▍         | 62/1378 [00:11<03:55,  5.59it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6916
loss_neg: 0.6933
total loss: 0.6925

Probs positive (first 5): tensor([0.4955, 0.4993, 0.4922, 0.4904, 0.5030], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4997, 0.4930, 0.5041, 0.4951, 0.5093], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5008
probs_neg mean: 0.5000

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.5156
  4%|▍         | 62/1378 [00:11<03:55,  5.59it/s, Stage=Training, Epoch=1/5, Loss=0.692]  5%|▍         | 63/1378 [00:11<03:58,  5.51it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6930
loss_neg: 0.6991
total loss: 0.6960

Probs positive (first 5): tensor([0.5060, 0.4951, 0.5070, 0.4833, 0.4901], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5153, 0.5194, 0.5064, 0.4831, 0.5173], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5002
probs_neg mean: 0.5029

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.4062
  5%|▍         | 63/1378 [00:12<03:58,  5.51it/s, Stage=Training, Epoch=1/5, Loss=0.696]  5%|▍         | 64/1378 [00:12<04:00,  5.47it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6900
loss_neg: 0.6941
total loss: 0.6920

Probs positive (first 5): tensor([0.4977, 0.5021, 0.4994, 0.5080, 0.4992], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4991, 0.4913, 0.5083, 0.5031, 0.4835], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5017
probs_neg mean: 0.5004

Pred distribution: 0=60, 1=68
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.5156
  5%|▍         | 64/1378 [00:12<04:00,  5.47it/s, Stage=Training, Epoch=1/5, Loss=0.692]  5%|▍         | 65/1378 [00:12<04:02,  5.41it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6902
loss_neg: 0.6981
total loss: 0.6941

Probs positive (first 5): tensor([0.4860, 0.5028, 0.4955, 0.5206, 0.4960], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4980, 0.5031, 0.5033, 0.4918, 0.4919], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5016
probs_neg mean: 0.5024

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.4375
  5%|▍         | 65/1378 [00:12<04:02,  5.41it/s, Stage=Training, Epoch=1/5, Loss=0.694]  5%|▍         | 66/1378 [00:12<03:51,  5.66it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6913
loss_neg: 0.6990
total loss: 0.6952

Probs positive (first 5): tensor([0.4921, 0.5137, 0.4874, 0.4965, 0.4987], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5170, 0.5079, 0.5128, 0.4920, 0.4998], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5010
probs_neg mean: 0.5028

Pred distribution: 0=50, 1=78
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.3906
  5%|▍         | 66/1378 [00:12<03:51,  5.66it/s, Stage=Training, Epoch=1/5, Loss=0.695]  5%|▍         | 67/1378 [00:12<03:51,  5.66it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6926
loss_neg: 0.6974
total loss: 0.6950

Probs positive (first 5): tensor([0.4982, 0.4799, 0.5046, 0.4928, 0.5056], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4906, 0.5071, 0.5071, 0.4830, 0.4999], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5004
probs_neg mean: 0.5020

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.4219
  5%|▍         | 67/1378 [00:12<03:51,  5.66it/s, Stage=Training, Epoch=1/5, Loss=0.695]  5%|▍         | 68/1378 [00:12<03:48,  5.74it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6919
loss_neg: 0.6955
total loss: 0.6937

Probs positive (first 5): tensor([0.5162, 0.5129, 0.5042, 0.4900, 0.5143], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5025, 0.4964, 0.5102, 0.4894, 0.5186], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5007
probs_neg mean: 0.5011

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.4375
  5%|▍         | 68/1378 [00:12<03:48,  5.74it/s, Stage=Training, Epoch=1/5, Loss=0.694]  5%|▌         | 69/1378 [00:12<03:44,  5.82it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6951
loss_neg: 0.6934
total loss: 0.6943

Probs positive (first 5): tensor([0.5073, 0.4993, 0.5071, 0.4995, 0.4818], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5067, 0.5046, 0.4972, 0.5182, 0.4982], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4991
probs_neg mean: 0.5000

Pred distribution: 0=70, 1=58
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.5469
  5%|▌         | 69/1378 [00:13<03:44,  5.82it/s, Stage=Training, Epoch=1/5, Loss=0.694]  5%|▌         | 70/1378 [00:13<03:47,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6942
loss_neg: 0.6929
total loss: 0.6936

Probs positive (first 5): tensor([0.4985, 0.5078, 0.5021, 0.4851, 0.4985], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4898, 0.4952, 0.4992, 0.5160, 0.5031], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4996
probs_neg mean: 0.4998

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.4688
  5%|▌         | 70/1378 [00:13<03:47,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.694]  5%|▌         | 71/1378 [00:13<03:50,  5.66it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6959
loss_neg: 0.6957
total loss: 0.6958

Probs positive (first 5): tensor([0.4880, 0.4923, 0.4950, 0.5089, 0.4998], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5304, 0.5064, 0.4970, 0.5011, 0.5062], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4987
probs_neg mean: 0.5012

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.4531
  5%|▌         | 71/1378 [00:13<03:50,  5.66it/s, Stage=Training, Epoch=1/5, Loss=0.696]  5%|▌         | 72/1378 [00:13<03:52,  5.61it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6946
loss_neg: 0.6943
total loss: 0.6945

Probs positive (first 5): tensor([0.4890, 0.5081, 0.4992, 0.5089, 0.5101], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5018, 0.5124, 0.5105, 0.4919, 0.4938], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4993
probs_neg mean: 0.5005

Pred distribution: 0=69, 1=59
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.5000
  5%|▌         | 72/1378 [00:13<03:52,  5.61it/s, Stage=Training, Epoch=1/5, Loss=0.694]  5%|▌         | 73/1378 [00:13<03:45,  5.78it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6956
loss_neg: 0.6885
total loss: 0.6920

Probs positive (first 5): tensor([0.5070, 0.5096, 0.4936, 0.5148, 0.4987], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4971, 0.5086, 0.4978, 0.5077, 0.5070], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.4976

Pred distribution: 0=76, 1=52
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.6094
  5%|▌         | 73/1378 [00:13<03:45,  5.78it/s, Stage=Training, Epoch=1/5, Loss=0.692]  5%|▌         | 74/1378 [00:13<03:42,  5.86it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6952
loss_neg: 0.6926
total loss: 0.6939

Probs positive (first 5): tensor([0.4954, 0.4999, 0.5088, 0.5123, 0.4924], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4941, 0.4840, 0.4875, 0.5011, 0.4991], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4991
probs_neg mean: 0.4997

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.4688
  5%|▌         | 74/1378 [00:14<03:42,  5.86it/s, Stage=Training, Epoch=1/5, Loss=0.694]  5%|▌         | 75/1378 [00:14<03:38,  5.97it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6908
loss_neg: 0.6922
total loss: 0.6915

Probs positive (first 5): tensor([0.4748, 0.5046, 0.4921, 0.4965, 0.5083], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4865, 0.5026, 0.4982, 0.4893, 0.5025], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5013
probs_neg mean: 0.4994

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.5625
  5%|▌         | 75/1378 [00:14<03:38,  5.97it/s, Stage=Training, Epoch=1/5, Loss=0.691]  6%|▌         | 76/1378 [00:14<03:43,  5.83it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6958
loss_neg: 0.6918
total loss: 0.6938

Probs positive (first 5): tensor([0.4996, 0.4969, 0.4938, 0.4968, 0.5074], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5010, 0.5217, 0.4919, 0.5005, 0.5023], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4988
probs_neg mean: 0.4993

Pred distribution: 0=77, 1=51
Label distribution: 0=64, 1=64
Accuracy positive: 0.3594
Accuracy negative: 0.5625
  6%|▌         | 76/1378 [00:14<03:43,  5.83it/s, Stage=Training, Epoch=1/5, Loss=0.694]  6%|▌         | 77/1378 [00:14<03:47,  5.71it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6921
loss_neg: 0.6950
total loss: 0.6936

Probs positive (first 5): tensor([0.5086, 0.5045, 0.5070, 0.4959, 0.5012], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4843, 0.4964, 0.4980, 0.5057, 0.5036], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.5008

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.4531
  6%|▌         | 77/1378 [00:14<03:47,  5.71it/s, Stage=Training, Epoch=1/5, Loss=0.694]  6%|▌         | 78/1378 [00:14<03:50,  5.65it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6991
loss_neg: 0.6908
total loss: 0.6949

Probs positive (first 5): tensor([0.5029, 0.4935, 0.4994, 0.4916, 0.4965], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5033, 0.4894, 0.4941, 0.5005, 0.5114], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4971
probs_neg mean: 0.4987

Pred distribution: 0=80, 1=48
Label distribution: 0=64, 1=64
Accuracy positive: 0.2969
Accuracy negative: 0.5469
  6%|▌         | 78/1378 [00:14<03:50,  5.65it/s, Stage=Training, Epoch=1/5, Loss=0.695]  6%|▌         | 79/1378 [00:14<03:53,  5.56it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6961
loss_neg: 0.6917
total loss: 0.6939

Probs positive (first 5): tensor([0.5058, 0.4960, 0.5112, 0.5108, 0.5081], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5044, 0.5026, 0.4861, 0.5003, 0.4950], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4986
probs_neg mean: 0.4992

Pred distribution: 0=69, 1=59
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.5156
  6%|▌         | 79/1378 [00:14<03:53,  5.56it/s, Stage=Training, Epoch=1/5, Loss=0.694]  6%|▌         | 80/1378 [00:14<03:57,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6929
loss_neg: 0.6934
total loss: 0.6932

Probs positive (first 5): tensor([0.5062, 0.5098, 0.4946, 0.4868, 0.5114], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5069, 0.5100, 0.5124, 0.4956, 0.4676], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5002
probs_neg mean: 0.5000

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.5625
  6%|▌         | 80/1378 [00:15<03:57,  5.46it/s, Stage=Training, Epoch=1/5, Loss=0.693]  6%|▌         | 81/1378 [00:15<04:01,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6950
loss_neg: 0.6950
total loss: 0.6950

Probs positive (first 5): tensor([0.4998, 0.5005, 0.5068, 0.5109, 0.5053], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5069, 0.4958, 0.4930, 0.4954, 0.5098], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4992
probs_neg mean: 0.5008

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.4688
  6%|▌         | 81/1378 [00:15<04:01,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.695]  6%|▌         | 82/1378 [00:15<04:01,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6957
loss_neg: 0.6964
total loss: 0.6960

Probs positive (first 5): tensor([0.5000, 0.4921, 0.4966, 0.5128, 0.4897], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5084, 0.5042, 0.5095, 0.5017, 0.4919], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4988
probs_neg mean: 0.5015

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.3906
  6%|▌         | 82/1378 [00:15<04:01,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.696]  6%|▌         | 83/1378 [00:15<04:03,  5.32it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6915
loss_neg: 0.6926
total loss: 0.6920

Probs positive (first 5): tensor([0.5015, 0.5050, 0.5121, 0.5252, 0.4910], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5177, 0.4901, 0.5151, 0.4967, 0.5089], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5009
probs_neg mean: 0.4996

Pred distribution: 0=59, 1=69
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.5156
  6%|▌         | 83/1378 [00:15<04:03,  5.32it/s, Stage=Training, Epoch=1/5, Loss=0.692]  6%|▌         | 84/1378 [00:15<04:01,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6909
loss_neg: 0.6948
total loss: 0.6928

Probs positive (first 5): tensor([0.5025, 0.5072, 0.4950, 0.5092, 0.4945], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4740, 0.5180, 0.4977, 0.4888, 0.4946], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5012
probs_neg mean: 0.5007

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.4375
  6%|▌         | 84/1378 [00:15<04:01,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.693]  6%|▌         | 85/1378 [00:15<04:01,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6900
loss_neg: 0.6936
total loss: 0.6918

Probs positive (first 5): tensor([0.5184, 0.4961, 0.5020, 0.5007, 0.5091], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5016, 0.5055, 0.5122, 0.4984, 0.4919], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5017
probs_neg mean: 0.5001

Pred distribution: 0=51, 1=77
Label distribution: 0=64, 1=64
Accuracy positive: 0.6875
Accuracy negative: 0.4844
  6%|▌         | 85/1378 [00:16<04:01,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.692]  6%|▌         | 86/1378 [00:16<04:03,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6971
loss_neg: 0.6943
total loss: 0.6957

Probs positive (first 5): tensor([0.4949, 0.4887, 0.4944, 0.4823, 0.4864], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5028, 0.4970, 0.5059, 0.4853, 0.5056], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4981
probs_neg mean: 0.5005

Pred distribution: 0=66, 1=62
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.4219
  6%|▌         | 86/1378 [00:16<04:03,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.696]  6%|▋         | 87/1378 [00:16<04:10,  5.15it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6903
loss_neg: 0.6954
total loss: 0.6929

Probs positive (first 5): tensor([0.4962, 0.5238, 0.5008, 0.5005, 0.5026], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5124, 0.5094, 0.5033, 0.5097, 0.4929], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5015
probs_neg mean: 0.5010

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.4219
  6%|▋         | 87/1378 [00:16<04:10,  5.15it/s, Stage=Training, Epoch=1/5, Loss=0.693]  6%|▋         | 88/1378 [00:16<04:09,  5.17it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6897
loss_neg: 0.6911
total loss: 0.6904

Probs positive (first 5): tensor([0.5025, 0.5155, 0.4951, 0.5237, 0.5032], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4875, 0.5023, 0.5138, 0.4991, 0.5040], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5018
probs_neg mean: 0.4989

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.5938
  6%|▋         | 88/1378 [00:16<04:09,  5.17it/s, Stage=Training, Epoch=1/5, Loss=0.69]   6%|▋         | 89/1378 [00:16<04:07,  5.20it/s, Stage=Training, Epoch=1/5, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6930
loss_neg: 0.6956
total loss: 0.6943

Probs positive (first 5): tensor([0.5058, 0.5010, 0.5111, 0.4993, 0.4876], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5009, 0.5027, 0.5014, 0.5105, 0.4859], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5001
probs_neg mean: 0.5012

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.3906
  6%|▋         | 89/1378 [00:16<04:07,  5.20it/s, Stage=Training, Epoch=1/5, Loss=0.694]  7%|▋         | 90/1378 [00:16<04:07,  5.20it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6912
loss_neg: 0.6934
total loss: 0.6923

Probs positive (first 5): tensor([0.4639, 0.4973, 0.4807, 0.5030, 0.5113], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5001, 0.5011, 0.4959, 0.5030, 0.4976], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5011
probs_neg mean: 0.5001

Pred distribution: 0=59, 1=69
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.5156
  7%|▋         | 90/1378 [00:17<04:07,  5.20it/s, Stage=Training, Epoch=1/5, Loss=0.692]  7%|▋         | 91/1378 [00:17<04:06,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6937
loss_neg: 0.6953
total loss: 0.6945

Probs positive (first 5): tensor([0.4971, 0.4986, 0.4973, 0.4979, 0.5062], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4989, 0.4997, 0.5013, 0.5084, 0.5086], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4998
probs_neg mean: 0.5010

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.4688
  7%|▋         | 91/1378 [00:17<04:06,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.695]  7%|▋         | 92/1378 [00:17<04:06,  5.22it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6921
loss_neg: 0.6944
total loss: 0.6933

Probs positive (first 5): tensor([0.4831, 0.5088, 0.4961, 0.4978, 0.5022], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5059, 0.5109, 0.4991, 0.5123, 0.4951], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.5006

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.4688
  7%|▋         | 92/1378 [00:17<04:06,  5.22it/s, Stage=Training, Epoch=1/5, Loss=0.693]  7%|▋         | 93/1378 [00:17<04:06,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6916
loss_neg: 0.6969
total loss: 0.6942

Probs positive (first 5): tensor([0.5110, 0.5028, 0.5135, 0.5021, 0.5105], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5023, 0.4927, 0.5003, 0.5091, 0.5169], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5009
probs_neg mean: 0.5018

Pred distribution: 0=59, 1=69
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.4375
  7%|▋         | 93/1378 [00:17<04:06,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.694]  7%|▋         | 94/1378 [00:17<04:07,  5.18it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6954
loss_neg: 0.6942
total loss: 0.6948

Probs positive (first 5): tensor([0.4973, 0.5064, 0.4892, 0.5011, 0.4982], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4949, 0.5059, 0.4980, 0.5056, 0.4967], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4990
probs_neg mean: 0.5005

Pred distribution: 0=66, 1=62
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.5312
  7%|▋         | 94/1378 [00:17<04:07,  5.18it/s, Stage=Training, Epoch=1/5, Loss=0.695]  7%|▋         | 95/1378 [00:17<04:06,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6913
loss_neg: 0.6934
total loss: 0.6924

Probs positive (first 5): tensor([0.5104, 0.4959, 0.5185, 0.5060, 0.4892], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5094, 0.5023, 0.5031, 0.5089, 0.5199], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5010
probs_neg mean: 0.5001

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.5000
  7%|▋         | 95/1378 [00:18<04:06,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.692]  7%|▋         | 96/1378 [00:18<04:03,  5.27it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6892
loss_neg: 0.6929
total loss: 0.6911

Probs positive (first 5): tensor([0.4985, 0.5009, 0.4868, 0.5038, 0.5231], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4940, 0.4890, 0.4959, 0.4913, 0.4905], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5021
probs_neg mean: 0.4998

Pred distribution: 0=53, 1=75
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.4688
  7%|▋         | 96/1378 [00:18<04:03,  5.27it/s, Stage=Training, Epoch=1/5, Loss=0.691]  7%|▋         | 97/1378 [00:18<04:04,  5.24it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6911
loss_neg: 0.6940
total loss: 0.6925

Probs positive (first 5): tensor([0.4981, 0.5032, 0.5018, 0.4935, 0.4942], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5082, 0.5011, 0.4863, 0.4968, 0.5084], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5012
probs_neg mean: 0.5003

Pred distribution: 0=63, 1=65
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.5312
  7%|▋         | 97/1378 [00:18<04:04,  5.24it/s, Stage=Training, Epoch=1/5, Loss=0.693]  7%|▋         | 98/1378 [00:18<04:03,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6912
loss_neg: 0.6966
total loss: 0.6939

Probs positive (first 5): tensor([0.5127, 0.4991, 0.4880, 0.4891, 0.4965], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4969, 0.4761, 0.4988, 0.5084, 0.5109], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5010
probs_neg mean: 0.5016

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.4062
  7%|▋         | 98/1378 [00:18<04:03,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.694]  7%|▋         | 99/1378 [00:18<04:05,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6898
loss_neg: 0.6951
total loss: 0.6925

Probs positive (first 5): tensor([0.4996, 0.5012, 0.5093, 0.5076, 0.5080], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5014, 0.5210, 0.5032, 0.4900, 0.5158], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5017
probs_neg mean: 0.5009

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.4688
  7%|▋         | 99/1378 [00:18<04:05,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.692]  7%|▋         | 100/1378 [00:18<04:05,  5.20it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6912
loss_neg: 0.6976
total loss: 0.6944

Probs positive (first 5): tensor([0.5096, 0.5028, 0.4948, 0.4930, 0.4970], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4912, 0.4958, 0.4951, 0.5095, 0.5092], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5011
probs_neg mean: 0.5021

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.4219
  7%|▋         | 100/1378 [00:18<04:05,  5.20it/s, Stage=Training, Epoch=1/5, Loss=0.694]  7%|▋         | 101/1378 [00:18<04:05,  5.20it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6888
loss_neg: 0.6965
total loss: 0.6927

Probs positive (first 5): tensor([0.5140, 0.5008, 0.4990, 0.5098, 0.5043], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4952, 0.4860, 0.4941, 0.5082, 0.5060], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5023
probs_neg mean: 0.5016

Pred distribution: 0=60, 1=68
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.5000
  7%|▋         | 101/1378 [00:19<04:05,  5.20it/s, Stage=Training, Epoch=1/5, Loss=0.693]  7%|▋         | 102/1378 [00:19<04:05,  5.19it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6937
loss_neg: 0.6979
total loss: 0.6958

Probs positive (first 5): tensor([0.5113, 0.5027, 0.5013, 0.4935, 0.4911], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5124, 0.5012, 0.5031, 0.4778, 0.4999], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4998
probs_neg mean: 0.5023

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.3750
  7%|▋         | 102/1378 [00:19<04:05,  5.19it/s, Stage=Training, Epoch=1/5, Loss=0.696]  7%|▋         | 103/1378 [00:19<04:02,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6937
loss_neg: 0.6913
total loss: 0.6925

Probs positive (first 5): tensor([0.4856, 0.5159, 0.4944, 0.4951, 0.4948], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4873, 0.5092, 0.5050, 0.5001, 0.5091], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4998
probs_neg mean: 0.4990

Pred distribution: 0=68, 1=60
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.5156
  7%|▋         | 103/1378 [00:19<04:02,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.693]  8%|▊         | 104/1378 [00:19<04:01,  5.27it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6914
loss_neg: 0.6941
total loss: 0.6928

Probs positive (first 5): tensor([0.4884, 0.5153, 0.5021, 0.4948, 0.4932], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4733, 0.5016, 0.5110, 0.5040, 0.4922], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5010
probs_neg mean: 0.5004

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.5156
  8%|▊         | 104/1378 [00:19<04:01,  5.27it/s, Stage=Training, Epoch=1/5, Loss=0.693]  8%|▊         | 105/1378 [00:19<04:01,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6898
loss_neg: 0.6928
total loss: 0.6913

Probs positive (first 5): tensor([0.5014, 0.5093, 0.4962, 0.5165, 0.5128], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4879, 0.5019, 0.4926, 0.5365, 0.5195], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5018
probs_neg mean: 0.4997

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.6094
  8%|▊         | 105/1378 [00:19<04:01,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.691]  8%|▊         | 106/1378 [00:19<04:01,  5.27it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6913
loss_neg: 0.6959
total loss: 0.6936

Probs positive (first 5): tensor([0.5032, 0.4954, 0.5141, 0.4853, 0.5098], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4980, 0.5057, 0.4902, 0.4777, 0.5006], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5010
probs_neg mean: 0.5013

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.4219
  8%|▊         | 106/1378 [00:20<04:01,  5.27it/s, Stage=Training, Epoch=1/5, Loss=0.694]  8%|▊         | 107/1378 [00:20<04:01,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6943
loss_neg: 0.6927
total loss: 0.6935

Probs positive (first 5): tensor([0.5016, 0.5060, 0.5117, 0.5105, 0.5142], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4967, 0.5120, 0.4859, 0.4959, 0.4751], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4995
probs_neg mean: 0.4997

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.5000
  8%|▊         | 107/1378 [00:20<04:01,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.693]  8%|▊         | 108/1378 [00:20<04:02,  5.24it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6916
loss_neg: 0.6950
total loss: 0.6933

Probs positive (first 5): tensor([0.4818, 0.4990, 0.4980, 0.4966, 0.5003], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4956, 0.4966, 0.5031, 0.4948, 0.5001], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5009
probs_neg mean: 0.5008

Pred distribution: 0=60, 1=68
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.5000
  8%|▊         | 108/1378 [00:20<04:02,  5.24it/s, Stage=Training, Epoch=1/5, Loss=0.693]  8%|▊         | 109/1378 [00:20<04:00,  5.28it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6933
loss_neg: 0.6953
total loss: 0.6943

Probs positive (first 5): tensor([0.4988, 0.4874, 0.4923, 0.4995, 0.5064], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5025, 0.5103, 0.4944, 0.5122, 0.5024], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5000
probs_neg mean: 0.5010

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.4531
  8%|▊         | 109/1378 [00:20<04:00,  5.28it/s, Stage=Training, Epoch=1/5, Loss=0.694]  8%|▊         | 110/1378 [00:20<03:58,  5.32it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6920
loss_neg: 0.6940
total loss: 0.6930

Probs positive (first 5): tensor([0.5164, 0.4856, 0.4956, 0.5059, 0.5019], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5012, 0.5037, 0.4879, 0.4928, 0.4986], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5007
probs_neg mean: 0.5004

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.4531
  8%|▊         | 110/1378 [00:20<03:58,  5.32it/s, Stage=Training, Epoch=1/5, Loss=0.693]  8%|▊         | 111/1378 [00:20<03:58,  5.32it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6938
loss_neg: 0.6946
total loss: 0.6942

Probs positive (first 5): tensor([0.4915, 0.4883, 0.4860, 0.5007, 0.5094], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4977, 0.4974, 0.5089, 0.5142, 0.4979], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4998
probs_neg mean: 0.5006

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.5000
  8%|▊         | 111/1378 [00:21<03:58,  5.32it/s, Stage=Training, Epoch=1/5, Loss=0.694]  8%|▊         | 112/1378 [00:21<03:56,  5.34it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6932
loss_neg: 0.6951
total loss: 0.6941

Probs positive (first 5): tensor([0.5006, 0.4940, 0.5024, 0.4939, 0.5166], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5033, 0.5166, 0.5012, 0.5009, 0.5037], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5001
probs_neg mean: 0.5009

Pred distribution: 0=61, 1=67
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.4531
  8%|▊         | 112/1378 [00:21<03:56,  5.34it/s, Stage=Training, Epoch=1/5, Loss=0.694]  8%|▊         | 113/1378 [00:21<03:58,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6933
loss_neg: 0.6930
total loss: 0.6931

Probs positive (first 5): tensor([0.5182, 0.5067, 0.4850, 0.5046, 0.4798], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5104, 0.5080, 0.5069, 0.5059, 0.5090], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5000
probs_neg mean: 0.4999

Pred distribution: 0=60, 1=68
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.4688
  8%|▊         | 113/1378 [00:21<03:58,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.693]  8%|▊         | 114/1378 [00:21<03:58,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6894
loss_neg: 0.6952
total loss: 0.6923

Probs positive (first 5): tensor([0.5063, 0.5014, 0.5053, 0.4971, 0.4959], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4960, 0.4936, 0.4997, 0.4929, 0.4986], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5020
probs_neg mean: 0.5009

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.4531
  8%|▊         | 114/1378 [00:21<03:58,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.692]  8%|▊         | 115/1378 [00:21<03:58,  5.28it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6865
loss_neg: 0.6908
total loss: 0.6886

Probs positive (first 5): tensor([0.4945, 0.5090, 0.4918, 0.5113, 0.5058], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5065, 0.5025, 0.4886, 0.5104, 0.5012], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5034
probs_neg mean: 0.4987

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.5469
  8%|▊         | 115/1378 [00:21<03:58,  5.28it/s, Stage=Training, Epoch=1/5, Loss=0.689]  8%|▊         | 116/1378 [00:21<03:58,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.689]
=== LOSS & METRICS ===
loss_pos: 0.6908
loss_neg: 0.6955
total loss: 0.6932

Probs positive (first 5): tensor([0.5018, 0.4978, 0.4965, 0.4973, 0.4953], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5115, 0.5153, 0.5062, 0.4860, 0.4830], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5012
probs_neg mean: 0.5011

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.4531
  8%|▊         | 116/1378 [00:22<03:58,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.693]  8%|▊         | 117/1378 [00:22<04:01,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6903
loss_neg: 0.6982
total loss: 0.6943

Probs positive (first 5): tensor([0.5076, 0.5070, 0.4959, 0.4984, 0.4811], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5093, 0.5036, 0.5195, 0.4935, 0.5106], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5015
probs_neg mean: 0.5025

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.3594
  8%|▊         | 117/1378 [00:22<04:01,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.694]  9%|▊         | 118/1378 [00:22<04:01,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6917
loss_neg: 0.6948
total loss: 0.6933

Probs positive (first 5): tensor([0.4875, 0.5186, 0.5102, 0.4909, 0.4998], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5060, 0.4930, 0.4938, 0.4958, 0.4926], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5008
probs_neg mean: 0.5008

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.4219
  9%|▊         | 118/1378 [00:22<04:01,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.693]  9%|▊         | 119/1378 [00:22<03:59,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6872
loss_neg: 0.6972
total loss: 0.6922

Probs positive (first 5): tensor([0.4951, 0.4988, 0.5061, 0.4948, 0.5102], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4966, 0.5037, 0.4880, 0.5003, 0.5110], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5031
probs_neg mean: 0.5019

Pred distribution: 0=50, 1=78
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.3906
  9%|▊         | 119/1378 [00:22<03:59,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.692]  9%|▊         | 120/1378 [00:22<03:58,  5.27it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6882
loss_neg: 0.6974
total loss: 0.6928

Probs positive (first 5): tensor([0.4888, 0.4857, 0.4857, 0.5022, 0.5078], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5044, 0.5123, 0.4942, 0.5191, 0.4939], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5026
probs_neg mean: 0.5021

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.6562
Accuracy negative: 0.4688
  9%|▊         | 120/1378 [00:22<03:58,  5.27it/s, Stage=Training, Epoch=1/5, Loss=0.693]  9%|▉         | 121/1378 [00:22<03:56,  5.32it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6851
loss_neg: 0.6971
total loss: 0.6911

Probs positive (first 5): tensor([0.5092, 0.5030, 0.5100, 0.5101, 0.5037], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5217, 0.5109, 0.5113, 0.4865, 0.4988], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5041
probs_neg mean: 0.5019

Pred distribution: 0=44, 1=84
Label distribution: 0=64, 1=64
Accuracy positive: 0.7188
Accuracy negative: 0.4062
  9%|▉         | 121/1378 [00:22<03:56,  5.32it/s, Stage=Training, Epoch=1/5, Loss=0.691]  9%|▉         | 122/1378 [00:22<03:57,  5.29it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6870
loss_neg: 0.6935
total loss: 0.6902

Probs positive (first 5): tensor([0.5218, 0.5010, 0.5071, 0.5064, 0.4878], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5091, 0.4968, 0.5001, 0.4929, 0.5066], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5032
probs_neg mean: 0.5001

Pred distribution: 0=51, 1=77
Label distribution: 0=64, 1=64
Accuracy positive: 0.6562
Accuracy negative: 0.4531
  9%|▉         | 122/1378 [00:23<03:57,  5.29it/s, Stage=Training, Epoch=1/5, Loss=0.69]   9%|▉         | 123/1378 [00:23<03:58,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6832
loss_neg: 0.6964
total loss: 0.6898

Probs positive (first 5): tensor([0.4908, 0.5124, 0.5181, 0.5114, 0.4951], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5034, 0.4937, 0.4895, 0.5199, 0.5030], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5051
probs_neg mean: 0.5015

Pred distribution: 0=44, 1=84
Label distribution: 0=64, 1=64
Accuracy positive: 0.7188
Accuracy negative: 0.4062
  9%|▉         | 123/1378 [00:23<03:58,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.69]  9%|▉         | 124/1378 [00:23<03:59,  5.23it/s, Stage=Training, Epoch=1/5, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6868
loss_neg: 0.6956
total loss: 0.6912

Probs positive (first 5): tensor([0.4996, 0.4902, 0.4946, 0.5145, 0.5150], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4929, 0.4927, 0.4999, 0.5069, 0.4966], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5032
probs_neg mean: 0.5012

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.5000
  9%|▉         | 124/1378 [00:23<03:59,  5.23it/s, Stage=Training, Epoch=1/5, Loss=0.691]  9%|▉         | 125/1378 [00:23<03:58,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6887
loss_neg: 0.6965
total loss: 0.6926

Probs positive (first 5): tensor([0.5043, 0.5043, 0.4917, 0.5067, 0.5086], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4975, 0.4987, 0.5052, 0.4932, 0.5189], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5023
probs_neg mean: 0.5016

Pred distribution: 0=46, 1=82
Label distribution: 0=64, 1=64
Accuracy positive: 0.6250
Accuracy negative: 0.3438
  9%|▉         | 125/1378 [00:23<03:58,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.693]  9%|▉         | 126/1378 [00:23<04:00,  5.20it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6854
loss_neg: 0.6956
total loss: 0.6905

Probs positive (first 5): tensor([0.5034, 0.4976, 0.5027, 0.5072, 0.4970], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4951, 0.5031, 0.4983, 0.4945, 0.4983], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5040
probs_neg mean: 0.5012

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.5000
  9%|▉         | 126/1378 [00:23<04:00,  5.20it/s, Stage=Training, Epoch=1/5, Loss=0.691]  9%|▉         | 127/1378 [00:23<04:03,  5.15it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6904
loss_neg: 0.6986
total loss: 0.6945

Probs positive (first 5): tensor([0.5081, 0.5129, 0.4855, 0.4891, 0.5037], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5083, 0.5044, 0.4953, 0.4947, 0.5005], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5015
probs_neg mean: 0.5026

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.4062
  9%|▉         | 127/1378 [00:24<04:03,  5.15it/s, Stage=Training, Epoch=1/5, Loss=0.694]  9%|▉         | 128/1378 [00:24<04:01,  5.18it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6857
loss_neg: 0.6972
total loss: 0.6915

Probs positive (first 5): tensor([0.4921, 0.4984, 0.5022, 0.5029, 0.5076], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4929, 0.5032, 0.4871, 0.5268, 0.4879], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5038
probs_neg mean: 0.5019

Pred distribution: 0=50, 1=78
Label distribution: 0=64, 1=64
Accuracy positive: 0.6250
Accuracy negative: 0.4062
  9%|▉         | 128/1378 [00:24<04:01,  5.18it/s, Stage=Training, Epoch=1/5, Loss=0.691]  9%|▉         | 129/1378 [00:24<04:00,  5.19it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6857
loss_neg: 0.6958
total loss: 0.6907

Probs positive (first 5): tensor([0.5074, 0.4921, 0.5161, 0.5029, 0.5110], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5165, 0.5164, 0.5198, 0.4969, 0.4906], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5038
probs_neg mean: 0.5012

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.6250
Accuracy negative: 0.4375
  9%|▉         | 129/1378 [00:24<04:00,  5.19it/s, Stage=Training, Epoch=1/5, Loss=0.691]  9%|▉         | 130/1378 [00:24<03:58,  5.23it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6920
loss_neg: 0.6973
total loss: 0.6947

Probs positive (first 5): tensor([0.5013, 0.4915, 0.5038, 0.4832, 0.4946], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4847, 0.5103, 0.5155, 0.5023, 0.5125], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.5020

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.4219
  9%|▉         | 130/1378 [00:24<03:58,  5.23it/s, Stage=Training, Epoch=1/5, Loss=0.695] 10%|▉         | 131/1378 [00:24<03:59,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6871
loss_neg: 0.6951
total loss: 0.6911

Probs positive (first 5): tensor([0.5119, 0.5064, 0.5013, 0.5066, 0.5012], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5012, 0.5019, 0.5031, 0.4987, 0.4929], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5031
probs_neg mean: 0.5009

Pred distribution: 0=53, 1=75
Label distribution: 0=64, 1=64
Accuracy positive: 0.6875
Accuracy negative: 0.5156
 10%|▉         | 131/1378 [00:24<03:59,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.691] 10%|▉         | 132/1378 [00:24<03:56,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6879
loss_neg: 0.6953
total loss: 0.6916

Probs positive (first 5): tensor([0.5138, 0.5143, 0.5105, 0.5114, 0.5037], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5081, 0.4947, 0.5000, 0.5073, 0.5118], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5027
probs_neg mean: 0.5010

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.4844
 10%|▉         | 132/1378 [00:25<03:56,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.692] 10%|▉         | 133/1378 [00:25<03:55,  5.28it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6866
loss_neg: 0.6989
total loss: 0.6928

Probs positive (first 5): tensor([0.4819, 0.5162, 0.5020, 0.5058, 0.4939], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4989, 0.4930, 0.5296, 0.5018, 0.4999], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5034
probs_neg mean: 0.5028

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4219
 10%|▉         | 133/1378 [00:25<03:55,  5.28it/s, Stage=Training, Epoch=1/5, Loss=0.693] 10%|▉         | 134/1378 [00:25<03:56,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6826
loss_neg: 0.6994
total loss: 0.6910

Probs positive (first 5): tensor([0.5066, 0.4955, 0.5203, 0.4993, 0.5115], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5000, 0.5068, 0.5073, 0.4978, 0.5144], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5054
probs_neg mean: 0.5030

Pred distribution: 0=42, 1=86
Label distribution: 0=64, 1=64
Accuracy positive: 0.7031
Accuracy negative: 0.3594
 10%|▉         | 134/1378 [00:25<03:56,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.691] 10%|▉         | 135/1378 [00:25<03:57,  5.23it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6879
loss_neg: 0.6962
total loss: 0.6920

Probs positive (first 5): tensor([0.5062, 0.4972, 0.5121, 0.5005, 0.4999], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5015, 0.4880, 0.4847, 0.5191, 0.4958], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5027
probs_neg mean: 0.5014

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4219
 10%|▉         | 135/1378 [00:25<03:57,  5.23it/s, Stage=Training, Epoch=1/5, Loss=0.692] 10%|▉         | 136/1378 [00:25<03:59,  5.18it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6907
loss_neg: 0.6978
total loss: 0.6942

Probs positive (first 5): tensor([0.5227, 0.4899, 0.5012, 0.5032, 0.4966], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5091, 0.4947, 0.5059, 0.5121, 0.4894], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5013
probs_neg mean: 0.5022

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.4219
 10%|▉         | 136/1378 [00:25<03:59,  5.18it/s, Stage=Training, Epoch=1/5, Loss=0.694] 10%|▉         | 137/1378 [00:25<03:56,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6872
loss_neg: 0.6979
total loss: 0.6926

Probs positive (first 5): tensor([0.5206, 0.5054, 0.5044, 0.4918, 0.4916], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5120, 0.5080, 0.5113, 0.5027, 0.5066], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5031
probs_neg mean: 0.5023

Pred distribution: 0=48, 1=80
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.3594
 10%|▉         | 137/1378 [00:26<03:56,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.693] 10%|█         | 138/1378 [00:26<03:54,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6883
loss_neg: 0.6987
total loss: 0.6935

Probs positive (first 5): tensor([0.4925, 0.5055, 0.5060, 0.5167, 0.5003], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5097, 0.5190, 0.5060, 0.4984, 0.4819], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5025
probs_neg mean: 0.5027

Pred distribution: 0=49, 1=79
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.4062
 10%|█         | 138/1378 [00:26<03:54,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.694] 10%|█         | 139/1378 [00:26<03:54,  5.29it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6879
loss_neg: 0.6978
total loss: 0.6929

Probs positive (first 5): tensor([0.4966, 0.4932, 0.4958, 0.4868, 0.5178], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4974, 0.4898, 0.4940, 0.4951, 0.5011], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5027
probs_neg mean: 0.5022

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.4062
 10%|█         | 139/1378 [00:26<03:54,  5.29it/s, Stage=Training, Epoch=1/5, Loss=0.693] 10%|█         | 140/1378 [00:26<03:52,  5.33it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6906
loss_neg: 0.6990
total loss: 0.6948

Probs positive (first 5): tensor([0.5151, 0.5008, 0.5001, 0.5196, 0.4898], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5085, 0.5000, 0.5047, 0.5051, 0.4952], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5014
probs_neg mean: 0.5029

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.4062
 10%|█         | 140/1378 [00:26<03:52,  5.33it/s, Stage=Training, Epoch=1/5, Loss=0.695] 10%|█         | 141/1378 [00:26<03:49,  5.39it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6877
loss_neg: 0.6989
total loss: 0.6933

Probs positive (first 5): tensor([0.4958, 0.5004, 0.5057, 0.5190, 0.4937], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4947, 0.5006, 0.5028, 0.4854, 0.4963], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5028
probs_neg mean: 0.5028

Pred distribution: 0=45, 1=83
Label distribution: 0=64, 1=64
Accuracy positive: 0.6250
Accuracy negative: 0.3281
 10%|█         | 141/1378 [00:26<03:49,  5.39it/s, Stage=Training, Epoch=1/5, Loss=0.693] 10%|█         | 142/1378 [00:26<03:50,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6919
loss_neg: 0.6984
total loss: 0.6951

Probs positive (first 5): tensor([0.4901, 0.5083, 0.5128, 0.4945, 0.5126], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4896, 0.5162, 0.5195, 0.5098, 0.4934], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5007
probs_neg mean: 0.5025

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.4062
 10%|█         | 142/1378 [00:26<03:50,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.695] 10%|█         | 143/1378 [00:26<03:50,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6943
loss_neg: 0.6957
total loss: 0.6950

Probs positive (first 5): tensor([0.4967, 0.4976, 0.5048, 0.5116, 0.5066], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4991, 0.5075, 0.5049, 0.4839, 0.5110], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4995
probs_neg mean: 0.5011

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.4531
 10%|█         | 143/1378 [00:27<03:50,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.695] 10%|█         | 144/1378 [00:27<03:50,  5.34it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6891
loss_neg: 0.6982
total loss: 0.6937

Probs positive (first 5): tensor([0.5159, 0.5067, 0.4852, 0.4984, 0.4921], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5006, 0.4990, 0.4974, 0.4913, 0.5190], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5021
probs_neg mean: 0.5024

Pred distribution: 0=50, 1=78
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.3594
 10%|█         | 144/1378 [00:27<03:50,  5.34it/s, Stage=Training, Epoch=1/5, Loss=0.694] 11%|█         | 145/1378 [00:27<03:52,  5.31it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6960
loss_neg: 0.6940
total loss: 0.6950

Probs positive (first 5): tensor([0.5032, 0.5020, 0.4792, 0.5044, 0.4973], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4932, 0.4974, 0.4957, 0.5144, 0.4782], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4986
probs_neg mean: 0.5003

Pred distribution: 0=71, 1=57
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.5469
 11%|█         | 145/1378 [00:27<03:52,  5.31it/s, Stage=Training, Epoch=1/5, Loss=0.695] 11%|█         | 146/1378 [00:27<03:55,  5.24it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6944
loss_neg: 0.6952
total loss: 0.6948

Probs positive (first 5): tensor([0.5032, 0.5133, 0.4729, 0.4988, 0.4896], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5089, 0.5151, 0.5190, 0.4970, 0.4983], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4995
probs_neg mean: 0.5009

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.4531
 11%|█         | 146/1378 [00:27<03:55,  5.24it/s, Stage=Training, Epoch=1/5, Loss=0.695] 11%|█         | 147/1378 [00:27<03:56,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6908
loss_neg: 0.6927
total loss: 0.6918

Probs positive (first 5): tensor([0.5043, 0.4887, 0.4947, 0.4932, 0.5050], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4994, 0.4842, 0.4983, 0.4853, 0.5203], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5013
probs_neg mean: 0.4997

Pred distribution: 0=68, 1=60
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.5938
 11%|█         | 147/1378 [00:27<03:56,  5.21it/s, Stage=Training, Epoch=1/5, Loss=0.692] 11%|█         | 148/1378 [00:27<03:48,  5.38it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6920
loss_neg: 0.6973
total loss: 0.6947

Probs positive (first 5): tensor([0.5151, 0.4704, 0.5120, 0.5012, 0.5141], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4937, 0.4950, 0.4976, 0.4994, 0.5206], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.5020

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.3906
 11%|█         | 148/1378 [00:28<03:48,  5.38it/s, Stage=Training, Epoch=1/5, Loss=0.695] 11%|█         | 149/1378 [00:28<03:47,  5.40it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6953
loss_neg: 0.6928
total loss: 0.6940

Probs positive (first 5): tensor([0.4988, 0.4951, 0.5007, 0.5044, 0.5060], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5013, 0.4990, 0.4952, 0.4918, 0.4837], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4990
probs_neg mean: 0.4997

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.5000
 11%|█         | 149/1378 [00:28<03:47,  5.40it/s, Stage=Training, Epoch=1/5, Loss=0.694] 11%|█         | 150/1378 [00:28<03:48,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6982
loss_neg: 0.6930
total loss: 0.6956

Probs positive (first 5): tensor([0.5165, 0.5135, 0.4920, 0.4880, 0.4895], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5090, 0.5117, 0.4907, 0.4901, 0.4816], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4976
probs_neg mean: 0.4999

Pred distribution: 0=70, 1=58
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.5156
 11%|█         | 150/1378 [00:28<03:48,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.696] 11%|█         | 151/1378 [00:28<03:48,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6953
loss_neg: 0.6954
total loss: 0.6953

Probs positive (first 5): tensor([0.4889, 0.4975, 0.4949, 0.4878, 0.4895], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5044, 0.5042, 0.5166, 0.5013, 0.5052], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4990
probs_neg mean: 0.5010

Pred distribution: 0=59, 1=69
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.3906
 11%|█         | 151/1378 [00:28<03:48,  5.36it/s, Stage=Training, Epoch=1/5, Loss=0.695] 11%|█         | 152/1378 [00:28<03:49,  5.35it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6951
loss_neg: 0.6903
total loss: 0.6927

Probs positive (first 5): tensor([0.4780, 0.4953, 0.5074, 0.4992, 0.5120], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4947, 0.4986, 0.5185, 0.5051, 0.4993], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4991
probs_neg mean: 0.4985

Pred distribution: 0=71, 1=57
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.5781
 11%|█         | 152/1378 [00:28<03:49,  5.35it/s, Stage=Training, Epoch=1/5, Loss=0.693] 11%|█         | 153/1378 [00:28<03:50,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6966
loss_neg: 0.6901
total loss: 0.6933

Probs positive (first 5): tensor([0.5025, 0.5153, 0.5051, 0.4956, 0.5022], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5005, 0.4930, 0.4989, 0.5072, 0.4850], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4984
probs_neg mean: 0.4984

Pred distribution: 0=71, 1=57
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.5469
 11%|█         | 153/1378 [00:29<03:50,  5.30it/s, Stage=Training, Epoch=1/5, Loss=0.693] 11%|█         | 154/1378 [00:29<03:51,  5.28it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6968
loss_neg: 0.6911
total loss: 0.6940

Probs positive (first 5): tensor([0.5035, 0.4931, 0.4869, 0.4842, 0.4939], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4908, 0.4982, 0.5150, 0.4957, 0.5102], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4983
probs_neg mean: 0.4989

Pred distribution: 0=76, 1=52
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.6406
 11%|█         | 154/1378 [00:29<03:51,  5.28it/s, Stage=Training, Epoch=1/5, Loss=0.694] 11%|█         | 155/1378 [00:29<03:51,  5.29it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6948
loss_neg: 0.6912
total loss: 0.6930

Probs positive (first 5): tensor([0.5002, 0.4951, 0.5009, 0.4892, 0.4834], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5024, 0.5022, 0.5017, 0.4963, 0.5117], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4993
probs_neg mean: 0.4989

Pred distribution: 0=66, 1=62
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.5156
 11%|█         | 155/1378 [00:29<03:51,  5.29it/s, Stage=Training, Epoch=1/5, Loss=0.693] 11%|█▏        | 156/1378 [00:29<03:50,  5.29it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6945
loss_neg: 0.6905
total loss: 0.6925

Probs positive (first 5): tensor([0.4905, 0.4841, 0.5097, 0.5088, 0.4936], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5023, 0.4898, 0.5135, 0.4994, 0.4872], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4994
probs_neg mean: 0.4986

Pred distribution: 0=72, 1=56
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.5781
 11%|█▏        | 156/1378 [00:29<03:50,  5.29it/s, Stage=Training, Epoch=1/5, Loss=0.693] 11%|█▏        | 157/1378 [00:29<03:51,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6972
loss_neg: 0.6894
total loss: 0.6933

Probs positive (first 5): tensor([0.4891, 0.4843, 0.5016, 0.4846, 0.5018], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4794, 0.4877, 0.5119, 0.5110, 0.4823], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4980
probs_neg mean: 0.4980

Pred distribution: 0=73, 1=55
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.5625
 11%|█▏        | 157/1378 [00:29<03:51,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.693] 11%|█▏        | 158/1378 [00:29<03:51,  5.27it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6965
loss_neg: 0.6895
total loss: 0.6930

Probs positive (first 5): tensor([0.5197, 0.5039, 0.4873, 0.4935, 0.5029], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4901, 0.4993, 0.4989, 0.4961, 0.4956], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4984
probs_neg mean: 0.4981

Pred distribution: 0=73, 1=55
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.5781
 11%|█▏        | 158/1378 [00:29<03:51,  5.27it/s, Stage=Training, Epoch=1/5, Loss=0.693] 12%|█▏        | 159/1378 [00:29<03:49,  5.31it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6962
loss_neg: 0.6875
total loss: 0.6919

Probs positive (first 5): tensor([0.4882, 0.4987, 0.5048, 0.4966, 0.5136], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4961, 0.5211, 0.4948, 0.4926, 0.4928], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4985
probs_neg mean: 0.4971

Pred distribution: 0=82, 1=46
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.6719
 12%|█▏        | 159/1378 [00:30<03:49,  5.31it/s, Stage=Training, Epoch=1/5, Loss=0.692] 12%|█▏        | 160/1378 [00:30<03:51,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6956
loss_neg: 0.6932
total loss: 0.6944

Probs positive (first 5): tensor([0.5081, 0.4972, 0.5003, 0.5067, 0.4913], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4949, 0.5055, 0.4946, 0.4969, 0.5071], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4988
probs_neg mean: 0.5000

Pred distribution: 0=66, 1=62
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.4688
 12%|█▏        | 160/1378 [00:30<03:51,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.694] 12%|█▏        | 161/1378 [00:30<03:51,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6966
loss_neg: 0.6894
total loss: 0.6930

Probs positive (first 5): tensor([0.5104, 0.4928, 0.4989, 0.5020, 0.5056], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5134, 0.4932, 0.4914, 0.5029, 0.4976], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4984
probs_neg mean: 0.4981

Pred distribution: 0=77, 1=51
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.5938
 12%|█▏        | 161/1378 [00:30<03:51,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.693] 12%|█▏        | 162/1378 [00:30<03:49,  5.31it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6950
loss_neg: 0.6881
total loss: 0.6916

Probs positive (first 5): tensor([0.4969, 0.4947, 0.4965, 0.5081, 0.5033], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4973, 0.4903, 0.4828, 0.4971, 0.4956], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4992
probs_neg mean: 0.4974

Pred distribution: 0=74, 1=54
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.6562
 12%|█▏        | 162/1378 [00:30<03:49,  5.31it/s, Stage=Training, Epoch=1/5, Loss=0.692] 12%|█▏        | 163/1378 [00:30<03:48,  5.33it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6978
loss_neg: 0.6874
total loss: 0.6926

Probs positive (first 5): tensor([0.5023, 0.4938, 0.4991, 0.5091, 0.4800], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5067, 0.4846, 0.4922, 0.4932, 0.4923], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4977
probs_neg mean: 0.4970

Pred distribution: 0=78, 1=50
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.6094
 12%|█▏        | 163/1378 [00:30<03:48,  5.33it/s, Stage=Training, Epoch=1/5, Loss=0.693] 12%|█▏        | 164/1378 [00:30<03:48,  5.32it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6959
loss_neg: 0.6881
total loss: 0.6920

Probs positive (first 5): tensor([0.4821, 0.4997, 0.4962, 0.5072, 0.5135], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4922, 0.5047, 0.4960, 0.4919, 0.4962], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4987
probs_neg mean: 0.4974

Pred distribution: 0=81, 1=47
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.6562
 12%|█▏        | 164/1378 [00:31<03:48,  5.32it/s, Stage=Training, Epoch=1/5, Loss=0.692] 12%|█▏        | 165/1378 [00:31<03:38,  5.55it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6957
loss_neg: 0.6876
total loss: 0.6917

Probs positive (first 5): tensor([0.4918, 0.4982, 0.5046, 0.4954, 0.4895], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5035, 0.5022, 0.4989, 0.4978, 0.4925], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4988
probs_neg mean: 0.4972

Pred distribution: 0=80, 1=48
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.6875
 12%|█▏        | 165/1378 [00:31<03:38,  5.55it/s, Stage=Training, Epoch=1/5, Loss=0.692] 12%|█▏        | 166/1378 [00:31<03:36,  5.59it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6915
loss_neg: 0.6910
total loss: 0.6912

Probs positive (first 5): tensor([0.5010, 0.4882, 0.4962, 0.4989, 0.5246], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4981, 0.5231, 0.5159, 0.5047, 0.5068], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5009
probs_neg mean: 0.4988

Pred distribution: 0=77, 1=51
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.6562
 12%|█▏        | 166/1378 [00:31<03:36,  5.59it/s, Stage=Training, Epoch=1/5, Loss=0.691] 12%|█▏        | 167/1378 [00:31<03:33,  5.68it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6955
loss_neg: 0.6974
total loss: 0.6964

Probs positive (first 5): tensor([0.4905, 0.5067, 0.5034, 0.4893, 0.4875], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5099, 0.5067, 0.5012, 0.4971, 0.4882], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.5020

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.4062
 12%|█▏        | 167/1378 [00:31<03:33,  5.68it/s, Stage=Training, Epoch=1/5, Loss=0.696] 12%|█▏        | 168/1378 [00:31<03:29,  5.78it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6955
loss_neg: 0.6940
total loss: 0.6947

Probs positive (first 5): tensor([0.4817, 0.5092, 0.5146, 0.4957, 0.4987], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5095, 0.5193, 0.5068, 0.5167, 0.5015], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.5003

Pred distribution: 0=60, 1=68
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.3750
 12%|█▏        | 168/1378 [00:31<03:29,  5.78it/s, Stage=Training, Epoch=1/5, Loss=0.695] 12%|█▏        | 169/1378 [00:31<03:30,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6925
loss_neg: 0.6947
total loss: 0.6936

Probs positive (first 5): tensor([0.5047, 0.5058, 0.5165, 0.5074, 0.5065], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4935, 0.4979, 0.5023, 0.5020, 0.4913], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5004
probs_neg mean: 0.5007

Pred distribution: 0=63, 1=65
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.5000
 12%|█▏        | 169/1378 [00:31<03:30,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.694] 12%|█▏        | 170/1378 [00:31<03:30,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6909
loss_neg: 0.6961
total loss: 0.6935

Probs positive (first 5): tensor([0.4985, 0.5094, 0.5020, 0.5067, 0.5053], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4997, 0.5064, 0.5031, 0.5066, 0.5045], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5012
probs_neg mean: 0.5014

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4219
 12%|█▏        | 170/1378 [00:32<03:30,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.694] 12%|█▏        | 171/1378 [00:32<03:26,  5.84it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6921
loss_neg: 0.6911
total loss: 0.6916

Probs positive (first 5): tensor([0.4927, 0.4879, 0.4904, 0.4994, 0.5045], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4884, 0.4884, 0.5036, 0.5131, 0.4993], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.4989

Pred distribution: 0=68, 1=60
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.5781
 12%|█▏        | 171/1378 [00:32<03:26,  5.84it/s, Stage=Training, Epoch=1/5, Loss=0.692] 12%|█▏        | 172/1378 [00:32<03:24,  5.89it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6938
loss_neg: 0.6980
total loss: 0.6959

Probs positive (first 5): tensor([0.5033, 0.5218, 0.5135, 0.5061, 0.5115], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5021, 0.5149, 0.4976, 0.5079, 0.5041], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4998
probs_neg mean: 0.5023

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.4375
 12%|█▏        | 172/1378 [00:32<03:24,  5.89it/s, Stage=Training, Epoch=1/5, Loss=0.696] 13%|█▎        | 173/1378 [00:32<03:21,  5.99it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6933
loss_neg: 0.6940
total loss: 0.6936

Probs positive (first 5): tensor([0.4971, 0.4993, 0.4813, 0.4987, 0.5066], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5075, 0.4999, 0.5037, 0.4970, 0.4928], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5000
probs_neg mean: 0.5003

Pred distribution: 0=66, 1=62
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.5156
 13%|█▎        | 173/1378 [00:32<03:21,  5.99it/s, Stage=Training, Epoch=1/5, Loss=0.694] 13%|█▎        | 174/1378 [00:32<03:29,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6934
loss_neg: 0.6951
total loss: 0.6942

Probs positive (first 5): tensor([0.5093, 0.4985, 0.5200, 0.5008, 0.4933], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5101, 0.5059, 0.4937, 0.5002, 0.5033], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5000
probs_neg mean: 0.5009

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.4375
 13%|█▎        | 174/1378 [00:32<03:29,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.694] 13%|█▎        | 175/1378 [00:32<03:29,  5.74it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6947
loss_neg: 0.6951
total loss: 0.6949

Probs positive (first 5): tensor([0.4966, 0.4873, 0.4996, 0.5080, 0.5045], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4825, 0.4961, 0.5051, 0.5128, 0.4961], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4993
probs_neg mean: 0.5009

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.4844
 13%|█▎        | 175/1378 [00:32<03:29,  5.74it/s, Stage=Training, Epoch=1/5, Loss=0.695] 13%|█▎        | 176/1378 [00:32<03:33,  5.64it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6940
loss_neg: 0.6946
total loss: 0.6943

Probs positive (first 5): tensor([0.4966, 0.4882, 0.4901, 0.5039, 0.4890], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4838, 0.5029, 0.4955, 0.4916, 0.4973], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4997
probs_neg mean: 0.5006

Pred distribution: 0=63, 1=65
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.4531
 13%|█▎        | 176/1378 [00:33<03:33,  5.64it/s, Stage=Training, Epoch=1/5, Loss=0.694] 13%|█▎        | 177/1378 [00:33<03:31,  5.68it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6907
loss_neg: 0.6904
total loss: 0.6905

Probs positive (first 5): tensor([0.4909, 0.5084, 0.5075, 0.5095, 0.5032], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4941, 0.5014, 0.4865, 0.5008, 0.4964], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5013
probs_neg mean: 0.4986

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.5938
 13%|█▎        | 177/1378 [00:33<03:31,  5.68it/s, Stage=Training, Epoch=1/5, Loss=0.691] 13%|█▎        | 178/1378 [00:33<03:28,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6879
loss_neg: 0.6951
total loss: 0.6915

Probs positive (first 5): tensor([0.5038, 0.4937, 0.4977, 0.4855, 0.4938], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4856, 0.4854, 0.5069, 0.5000, 0.4975], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5027
probs_neg mean: 0.5009

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.4844
 13%|█▎        | 178/1378 [00:33<03:28,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.692] 13%|█▎        | 179/1378 [00:33<03:30,  5.70it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6885
loss_neg: 0.6952
total loss: 0.6919

Probs positive (first 5): tensor([0.4821, 0.5050, 0.5042, 0.5098, 0.5011], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4997, 0.5073, 0.5064, 0.5180, 0.4977], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5024
probs_neg mean: 0.5009

Pred distribution: 0=48, 1=80
Label distribution: 0=64, 1=64
Accuracy positive: 0.7031
Accuracy negative: 0.4531
 13%|█▎        | 179/1378 [00:33<03:30,  5.70it/s, Stage=Training, Epoch=1/5, Loss=0.692] 13%|█▎        | 180/1378 [00:33<03:30,  5.69it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6875
loss_neg: 0.6923
total loss: 0.6899

Probs positive (first 5): tensor([0.5017, 0.5082, 0.4924, 0.5144, 0.5005], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4998, 0.4947, 0.4820, 0.5055, 0.5044], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5029
probs_neg mean: 0.4995

Pred distribution: 0=53, 1=75
Label distribution: 0=64, 1=64
Accuracy positive: 0.6875
Accuracy negative: 0.5156
 13%|█▎        | 180/1378 [00:33<03:30,  5.69it/s, Stage=Training, Epoch=1/5, Loss=0.69]  13%|█▎        | 181/1378 [00:33<03:30,  5.69it/s, Stage=Training, Epoch=1/5, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6899
loss_neg: 0.7031
total loss: 0.6965

Probs positive (first 5): tensor([0.5072, 0.4878, 0.4957, 0.5135, 0.5135], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5021, 0.5051, 0.5199, 0.5293, 0.5111], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5017
probs_neg mean: 0.5049

Pred distribution: 0=45, 1=83
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.2969
 13%|█▎        | 181/1378 [00:34<03:30,  5.69it/s, Stage=Training, Epoch=1/5, Loss=0.697] 13%|█▎        | 182/1378 [00:34<03:27,  5.76it/s, Stage=Training, Epoch=1/5, Loss=0.697]
=== LOSS & METRICS ===
loss_pos: 0.6868
loss_neg: 0.6932
total loss: 0.6900

Probs positive (first 5): tensor([0.4887, 0.5267, 0.5199, 0.5016, 0.4875], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4981, 0.4964, 0.5023, 0.4962, 0.5113], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5033
probs_neg mean: 0.4999

Pred distribution: 0=53, 1=75
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4375
 13%|█▎        | 182/1378 [00:34<03:27,  5.76it/s, Stage=Training, Epoch=1/5, Loss=0.69]  13%|█▎        | 183/1378 [00:34<03:24,  5.83it/s, Stage=Training, Epoch=1/5, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6941
loss_neg: 0.6992
total loss: 0.6967

Probs positive (first 5): tensor([0.4715, 0.4965, 0.4859, 0.5247, 0.4979], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5168, 0.5009, 0.5106, 0.5358, 0.5170], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4996
probs_neg mean: 0.5029

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.3594
 13%|█▎        | 183/1378 [00:34<03:24,  5.83it/s, Stage=Training, Epoch=1/5, Loss=0.697] 13%|█▎        | 184/1378 [00:34<03:25,  5.80it/s, Stage=Training, Epoch=1/5, Loss=0.697]
=== LOSS & METRICS ===
loss_pos: 0.6890
loss_neg: 0.6951
total loss: 0.6920

Probs positive (first 5): tensor([0.4927, 0.5017, 0.5025, 0.4957, 0.5176], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4997, 0.4957, 0.5061, 0.4932, 0.4747], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5022
probs_neg mean: 0.5009

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4531
 13%|█▎        | 184/1378 [00:34<03:25,  5.80it/s, Stage=Training, Epoch=1/5, Loss=0.692] 13%|█▎        | 185/1378 [00:34<03:28,  5.73it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6915
loss_neg: 0.6960
total loss: 0.6937

Probs positive (first 5): tensor([0.4907, 0.4989, 0.5047, 0.5038, 0.5005], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4983, 0.5101, 0.5074, 0.5030, 0.5008], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5009
probs_neg mean: 0.5014

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.4219
 13%|█▎        | 185/1378 [00:34<03:28,  5.73it/s, Stage=Training, Epoch=1/5, Loss=0.694] 13%|█▎        | 186/1378 [00:34<03:23,  5.85it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6901
loss_neg: 0.6951
total loss: 0.6926

Probs positive (first 5): tensor([0.5103, 0.5090, 0.4808, 0.4738, 0.5121], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5014, 0.5102, 0.4858, 0.4989, 0.5085], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5017
probs_neg mean: 0.5009

Pred distribution: 0=53, 1=75
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.4062
 13%|█▎        | 186/1378 [00:34<03:23,  5.85it/s, Stage=Training, Epoch=1/5, Loss=0.693] 14%|█▎        | 187/1378 [00:34<03:25,  5.78it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6901
loss_neg: 0.6951
total loss: 0.6926

Probs positive (first 5): tensor([0.4980, 0.4945, 0.4937, 0.5004, 0.5031], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4904, 0.5035, 0.5123, 0.5040, 0.5002], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5016
probs_neg mean: 0.5009

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.4062
 14%|█▎        | 187/1378 [00:35<03:25,  5.78it/s, Stage=Training, Epoch=1/5, Loss=0.693] 14%|█▎        | 188/1378 [00:35<03:31,  5.63it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6925
loss_neg: 0.6919
total loss: 0.6922

Probs positive (first 5): tensor([0.4961, 0.5014, 0.5046, 0.5052, 0.5144], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4924, 0.4827, 0.4936, 0.5028, 0.5132], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5004
probs_neg mean: 0.4993

Pred distribution: 0=66, 1=62
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.5469
 14%|█▎        | 188/1378 [00:35<03:31,  5.63it/s, Stage=Training, Epoch=1/5, Loss=0.692] 14%|█▎        | 189/1378 [00:35<03:31,  5.62it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6894
loss_neg: 0.6967
total loss: 0.6930

Probs positive (first 5): tensor([0.4963, 0.5071, 0.5126, 0.4888, 0.5059], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4799, 0.4913, 0.5097, 0.5015, 0.5059], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5020
probs_neg mean: 0.5017

Pred distribution: 0=50, 1=78
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.3750
 14%|█▎        | 189/1378 [00:35<03:31,  5.62it/s, Stage=Training, Epoch=1/5, Loss=0.693] 14%|█▍        | 190/1378 [00:35<03:32,  5.60it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6954
loss_neg: 0.6948
total loss: 0.6951

Probs positive (first 5): tensor([0.5062, 0.5068, 0.4850, 0.4898, 0.4794], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5269, 0.5104, 0.4988, 0.4976, 0.5049], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4990
probs_neg mean: 0.5007

Pred distribution: 0=68, 1=60
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.4844
 14%|█▍        | 190/1378 [00:35<03:32,  5.60it/s, Stage=Training, Epoch=1/5, Loss=0.695] 14%|█▍        | 191/1378 [00:35<03:31,  5.60it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6860
loss_neg: 0.6948
total loss: 0.6904

Probs positive (first 5): tensor([0.5035, 0.5197, 0.5070, 0.5150, 0.4968], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4949, 0.4992, 0.5092, 0.5027, 0.4971], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5036
probs_neg mean: 0.5008

Pred distribution: 0=49, 1=79
Label distribution: 0=64, 1=64
Accuracy positive: 0.6719
Accuracy negative: 0.4375
 14%|█▍        | 191/1378 [00:35<03:31,  5.60it/s, Stage=Training, Epoch=1/5, Loss=0.69]  14%|█▍        | 192/1378 [00:35<03:33,  5.56it/s, Stage=Training, Epoch=1/5, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6966
loss_neg: 0.6908
total loss: 0.6937

Probs positive (first 5): tensor([0.4761, 0.4925, 0.4987, 0.4872, 0.5115], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4947, 0.4955, 0.5011, 0.4941, 0.4971], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4984
probs_neg mean: 0.4987

Pred distribution: 0=73, 1=55
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.6094
 14%|█▍        | 192/1378 [00:35<03:33,  5.56it/s, Stage=Training, Epoch=1/5, Loss=0.694] 14%|█▍        | 193/1378 [00:35<03:30,  5.64it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6919
loss_neg: 0.6939
total loss: 0.6929

Probs positive (first 5): tensor([0.4975, 0.5084, 0.4986, 0.4903, 0.5004], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5179, 0.4976, 0.5029, 0.4962, 0.4996], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5007
probs_neg mean: 0.5003

Pred distribution: 0=59, 1=69
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.4688
 14%|█▍        | 193/1378 [00:36<03:30,  5.64it/s, Stage=Training, Epoch=1/5, Loss=0.693] 14%|█▍        | 194/1378 [00:36<03:29,  5.65it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6910
loss_neg: 0.6971
total loss: 0.6941

Probs positive (first 5): tensor([0.5088, 0.5031, 0.5038, 0.5127, 0.4990], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5067, 0.5143, 0.5077, 0.4972, 0.5024], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5011
probs_neg mean: 0.5019

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.4219
 14%|█▍        | 194/1378 [00:36<03:29,  5.65it/s, Stage=Training, Epoch=1/5, Loss=0.694] 14%|█▍        | 195/1378 [00:36<03:29,  5.64it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6920
loss_neg: 0.6945
total loss: 0.6933

Probs positive (first 5): tensor([0.5005, 0.4982, 0.5052, 0.4871, 0.4986], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5104, 0.5015, 0.5257, 0.5036, 0.4892], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.5006

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4531
 14%|█▍        | 195/1378 [00:36<03:29,  5.64it/s, Stage=Training, Epoch=1/5, Loss=0.693] 14%|█▍        | 196/1378 [00:36<03:26,  5.72it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6918
loss_neg: 0.6962
total loss: 0.6940

Probs positive (first 5): tensor([0.5103, 0.5093, 0.4997, 0.4950, 0.4884], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5116, 0.5111, 0.5002, 0.5167, 0.5035], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5008
probs_neg mean: 0.5014

Pred distribution: 0=51, 1=77
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.3750
 14%|█▍        | 196/1378 [00:36<03:26,  5.72it/s, Stage=Training, Epoch=1/5, Loss=0.694] 14%|█▍        | 197/1378 [00:36<03:24,  5.77it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6926
loss_neg: 0.6994
total loss: 0.6960

Probs positive (first 5): tensor([0.4970, 0.5017, 0.5016, 0.5074, 0.5159], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5016, 0.5000, 0.4985, 0.4964, 0.5151], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5004
probs_neg mean: 0.5031

Pred distribution: 0=51, 1=77
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.3750
 14%|█▍        | 197/1378 [00:36<03:24,  5.77it/s, Stage=Training, Epoch=1/5, Loss=0.696] 14%|█▍        | 198/1378 [00:36<03:23,  5.79it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6885
loss_neg: 0.6898
total loss: 0.6891

Probs positive (first 5): tensor([0.5214, 0.4916, 0.5126, 0.5001, 0.4967], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5034, 0.5038, 0.4859, 0.4831, 0.5032], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5024
probs_neg mean: 0.4982

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.5000
 14%|█▍        | 198/1378 [00:36<03:23,  5.79it/s, Stage=Training, Epoch=1/5, Loss=0.689] 14%|█▍        | 199/1378 [00:36<03:21,  5.85it/s, Stage=Training, Epoch=1/5, Loss=0.689]
=== LOSS & METRICS ===
loss_pos: 0.6923
loss_neg: 0.6983
total loss: 0.6953

Probs positive (first 5): tensor([0.4908, 0.5033, 0.5078, 0.4876, 0.5187], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4935, 0.4998, 0.4967, 0.5117, 0.5020], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5005
probs_neg mean: 0.5025

Pred distribution: 0=60, 1=68
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.4531
 14%|█▍        | 199/1378 [00:37<03:21,  5.85it/s, Stage=Training, Epoch=1/5, Loss=0.695] 15%|█▍        | 200/1378 [00:37<03:22,  5.82it/s, Stage=Training, Epoch=1/5, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6921
loss_neg: 0.6927
total loss: 0.6924

Probs positive (first 5): tensor([0.4872, 0.5211, 0.5132, 0.5165, 0.5063], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4918, 0.4877, 0.5050, 0.4981, 0.5024], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.4997

Pred distribution: 0=63, 1=65
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.4688
 15%|█▍        | 200/1378 [00:37<03:22,  5.82it/s, Stage=Training, Epoch=1/5, Loss=0.692] 15%|█▍        | 201/1378 [00:37<03:24,  5.74it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6886
loss_neg: 0.6946
total loss: 0.6916

Probs positive (first 5): tensor([0.4987, 0.4885, 0.4942, 0.4995, 0.5187], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4938, 0.4936, 0.5002, 0.4847, 0.4994], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5024
probs_neg mean: 0.5006

Pred distribution: 0=59, 1=69
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.5312
 15%|█▍        | 201/1378 [00:37<03:24,  5.74it/s, Stage=Training, Epoch=1/5, Loss=0.692] 15%|█▍        | 202/1378 [00:37<03:25,  5.72it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6929
loss_neg: 0.6916
total loss: 0.6923

Probs positive (first 5): tensor([0.5082, 0.4989, 0.5159, 0.4811, 0.4947], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4802, 0.5065, 0.4965, 0.4988, 0.5076], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5002
probs_neg mean: 0.4991

Pred distribution: 0=71, 1=57
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.5938
 15%|█▍        | 202/1378 [00:37<03:25,  5.72it/s, Stage=Training, Epoch=1/5, Loss=0.692] 15%|█▍        | 203/1378 [00:37<03:28,  5.64it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6987
loss_neg: 0.6925
total loss: 0.6956

Probs positive (first 5): tensor([0.4764, 0.5101, 0.5041, 0.5014, 0.4909], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4914, 0.4890, 0.5015, 0.5062, 0.4993], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4973
probs_neg mean: 0.4996

Pred distribution: 0=69, 1=59
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.5625
 15%|█▍        | 203/1378 [00:37<03:28,  5.64it/s, Stage=Training, Epoch=1/5, Loss=0.696] 15%|█▍        | 204/1378 [00:37<03:33,  5.50it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6984
loss_neg: 0.6863
total loss: 0.6924

Probs positive (first 5): tensor([0.5103, 0.4875, 0.4893, 0.4791, 0.4869], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4910, 0.5008, 0.4918, 0.5002, 0.5140], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4975
probs_neg mean: 0.4965

Pred distribution: 0=81, 1=47
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.6562
 15%|█▍        | 204/1378 [00:38<03:33,  5.50it/s, Stage=Training, Epoch=1/5, Loss=0.692] 15%|█▍        | 205/1378 [00:38<03:34,  5.47it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6947
loss_neg: 0.6828
total loss: 0.6887

Probs positive (first 5): tensor([0.4872, 0.5103, 0.4978, 0.4879, 0.5392], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4745, 0.5097, 0.5129, 0.4991, 0.4837], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4994
probs_neg mean: 0.4947

Pred distribution: 0=83, 1=45
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.7031
 15%|█▍        | 205/1378 [00:38<03:34,  5.47it/s, Stage=Training, Epoch=1/5, Loss=0.689] 15%|█▍        | 206/1378 [00:38<03:23,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.689]
=== LOSS & METRICS ===
loss_pos: 0.6990
loss_neg: 0.6824
total loss: 0.6907

Probs positive (first 5): tensor([0.4806, 0.4967, 0.4975, 0.4979, 0.4961], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4830, 0.5019, 0.4824, 0.4851, 0.5007], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4972
probs_neg mean: 0.4945

Pred distribution: 0=87, 1=41
Label distribution: 0=64, 1=64
Accuracy positive: 0.3594
Accuracy negative: 0.7188
 15%|█▍        | 206/1378 [00:38<03:23,  5.75it/s, Stage=Training, Epoch=1/5, Loss=0.691] 15%|█▌        | 207/1378 [00:38<03:18,  5.89it/s, Stage=Training, Epoch=1/5, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.7058
loss_neg: 0.6819
total loss: 0.6939

Probs positive (first 5): tensor([0.5056, 0.4826, 0.5021, 0.4955, 0.5061], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4995, 0.5018, 0.4963, 0.4860, 0.4710], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4938
probs_neg mean: 0.4943

Pred distribution: 0=95, 1=33
Label distribution: 0=64, 1=64
Accuracy positive: 0.2812
Accuracy negative: 0.7656
 15%|█▌        | 207/1378 [00:38<03:18,  5.89it/s, Stage=Training, Epoch=1/5, Loss=0.694] 15%|█▌        | 208/1378 [00:38<03:25,  5.70it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7043
loss_neg: 0.6840
total loss: 0.6942

Probs positive (first 5): tensor([0.5007, 0.4908, 0.4745, 0.4835, 0.4875], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4923, 0.4897, 0.5077, 0.4935, 0.5030], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4945
probs_neg mean: 0.4953

Pred distribution: 0=96, 1=32
Label distribution: 0=64, 1=64
Accuracy positive: 0.2656
Accuracy negative: 0.7656
 15%|█▌        | 208/1378 [00:38<03:25,  5.70it/s, Stage=Training, Epoch=1/5, Loss=0.694] 15%|█▌        | 209/1378 [00:38<03:30,  5.56it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7069
loss_neg: 0.6857
total loss: 0.6963

Probs positive (first 5): tensor([0.4918, 0.5057, 0.4784, 0.4898, 0.4895], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4931, 0.5019, 0.5014, 0.4940, 0.4876], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4933
probs_neg mean: 0.4961

Pred distribution: 0=86, 1=42
Label distribution: 0=64, 1=64
Accuracy positive: 0.2500
Accuracy negative: 0.5938
 15%|█▌        | 209/1378 [00:38<03:30,  5.56it/s, Stage=Training, Epoch=1/5, Loss=0.696] 15%|█▌        | 210/1378 [00:38<03:35,  5.42it/s, Stage=Training, Epoch=1/5, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.7030
loss_neg: 0.6830
total loss: 0.6930

Probs positive (first 5): tensor([0.4871, 0.4762, 0.4921, 0.5107, 0.4879], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4923, 0.5001, 0.4955, 0.4948, 0.4764], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4952
probs_neg mean: 0.4948

Pred distribution: 0=91, 1=37
Label distribution: 0=64, 1=64
Accuracy positive: 0.2812
Accuracy negative: 0.7031
 15%|█▌        | 210/1378 [00:39<03:35,  5.42it/s, Stage=Training, Epoch=1/5, Loss=0.693] 15%|█▌        | 211/1378 [00:39<03:37,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.7057
loss_neg: 0.6830
total loss: 0.6944

Probs positive (first 5): tensor([0.4926, 0.4994, 0.4852, 0.5001, 0.4872], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4808, 0.5032, 0.5009, 0.4899, 0.4910], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4938
probs_neg mean: 0.4948

Pred distribution: 0=92, 1=36
Label distribution: 0=64, 1=64
Accuracy positive: 0.2031
Accuracy negative: 0.6406
 15%|█▌        | 211/1378 [00:39<03:37,  5.37it/s, Stage=Training, Epoch=1/5, Loss=0.694] 15%|█▌        | 212/1378 [00:39<03:39,  5.31it/s, Stage=Training, Epoch=1/5, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7092
loss_neg: 0.6749
total loss: 0.6920

Probs positive (first 5): tensor([0.4849, 0.5015, 0.5057, 0.4964, 0.4893], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4825, 0.4902, 0.5026, 0.5029, 0.4839], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4921
probs_neg mean: 0.4907

Pred distribution: 0=102, 1=26
Label distribution: 0=64, 1=64
Accuracy positive: 0.2500
Accuracy negative: 0.8438
 15%|█▌        | 212/1378 [00:39<03:39,  5.31it/s, Stage=Training, Epoch=1/5, Loss=0.692] 15%|█▌        | 213/1378 [00:39<03:41,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7089
loss_neg: 0.6741
total loss: 0.6915

Probs positive (first 5): tensor([0.4869, 0.4914, 0.4995, 0.4862, 0.4942], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4878, 0.4811, 0.4796, 0.4918, 0.4786], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4923
probs_neg mean: 0.4903

Pred distribution: 0=110, 1=18
Label distribution: 0=64, 1=64
Accuracy positive: 0.1719
Accuracy negative: 0.8906
 15%|█▌        | 213/1378 [00:39<03:41,  5.25it/s, Stage=Training, Epoch=1/5, Loss=0.692] 16%|█▌        | 214/1378 [00:39<03:42,  5.24it/s, Stage=Training, Epoch=1/5, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7111
loss_neg: 0.6836
total loss: 0.6973

Probs positive (first 5): tensor([0.4875, 0.4708, 0.4971, 0.4904, 0.4963], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4913, 0.4929, 0.4915, 0.5024, 0.5001], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4912
probs_neg mean: 0.4951

Pred distribution: 0=101, 1=27
Label distribution: 0=64, 1=64
Accuracy positive: 0.1094
Accuracy negative: 0.6875
 16%|█▌        | 214/1378 [00:39<03:42,  5.24it/s, Stage=Training, Epoch=1/5, Loss=0.697] 16%|█▌        | 215/1378 [00:39<03:41,  5.26it/s, Stage=Training, Epoch=1/5, Loss=0.697]slurmstepd: error: *** JOB 3503494 ON cn-007 CANCELLED AT 2025-12-23T15:33:37 ***

=== LOSS & METRICS ===
loss_pos: 0.7078
loss_neg: 0.6721
total loss: 0.6899

Probs positive (first 5): tensor([0.4963, 0.5043, 0.4847, 0.4774, 0.4860], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4816, 0.4790, 0.4903, 0.4897, 0.4956], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4929
probs_neg mean: 0.4893

Pred distribution: 0=107, 1=21
Label distribution: 0=64, 1=64
Accuracy positive: 0.2344
Accuracy negative: 0.9062

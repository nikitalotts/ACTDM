/home/nklotts/.conda/envs/pgwtd/lib/python3.9/site-packages/wandb/apis/public.py:3109: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import parse_version
/home/nklotts/tencdm/model/enc_normalizer.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(enc_mean_path, map_location=location)[None, None, :],
/home/nklotts/tencdm/model/enc_normalizer.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(enc_std_path, map_location=location)[None, None, :],
/home/nklotts/.conda/envs/pgwtd/lib/python3.9/site-packages/wandb/apis/public.py:3109: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import parse_version
wandb: Tracking run with wandb version 0.15.0
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Dataset preprocessing (num_proc=30):   0%|          | 0/88161 [00:00<?, ? examples/s]Dataset preprocessing (num_proc=30):   3%|▎         | 2939/88161 [00:00<00:14, 5983.58 examples/s]Dataset preprocessing (num_proc=30):   7%|▋         | 5878/88161 [00:00<00:09, 8556.97 examples/s]Dataset preprocessing (num_proc=30):  10%|█         | 8817/88161 [00:00<00:06, 12584.33 examples/s]Dataset preprocessing (num_proc=30):  13%|█▎        | 11756/88161 [00:01<00:05, 12982.68 examples/s]Dataset preprocessing (num_proc=30):  16%|█▌        | 13756/88161 [00:01<00:06, 12327.62 examples/s]Dataset preprocessing (num_proc=30):  20%|██        | 17634/88161 [00:01<00:04, 17047.53 examples/s]Dataset preprocessing (num_proc=30):  23%|██▎       | 20573/88161 [00:01<00:04, 15252.09 examples/s]Dataset preprocessing (num_proc=30):  27%|██▋       | 23512/88161 [00:01<00:03, 16653.81 examples/s]Dataset preprocessing (num_proc=30):  30%|███       | 26451/88161 [00:01<00:03, 16596.97 examples/s]Dataset preprocessing (num_proc=30):  33%|███▎      | 29390/88161 [00:02<00:03, 18055.85 examples/s]Dataset preprocessing (num_proc=30):  37%|███▋      | 32329/88161 [00:02<00:03, 16146.03 examples/s]Dataset preprocessing (num_proc=30):  40%|████      | 35268/88161 [00:02<00:03, 15885.60 examples/s]Dataset preprocessing (num_proc=30):  43%|████▎     | 38207/88161 [00:02<00:03, 16400.02 examples/s]Dataset preprocessing (num_proc=30):  47%|████▋     | 41146/88161 [00:02<00:02, 16803.50 examples/s]Dataset preprocessing (num_proc=30):  50%|█████     | 44085/88161 [00:03<00:02, 15613.03 examples/s]Dataset preprocessing (num_proc=30):  53%|█████▎    | 47024/88161 [00:03<00:02, 15521.66 examples/s]Dataset preprocessing (num_proc=30):  57%|█████▋    | 49963/88161 [00:03<00:02, 13768.59 examples/s]Dataset preprocessing (num_proc=30):  60%|██████    | 52902/88161 [00:03<00:02, 14629.18 examples/s]Dataset preprocessing (num_proc=30):  63%|██████▎   | 55841/88161 [00:03<00:02, 13584.02 examples/s]Dataset preprocessing (num_proc=30):  67%|██████▋   | 58780/88161 [00:04<00:02, 14023.07 examples/s]Dataset preprocessing (num_proc=30):  70%|███████   | 61719/88161 [00:04<00:01, 15271.74 examples/s]Dataset preprocessing (num_proc=30):  73%|███████▎  | 64657/88161 [00:04<00:01, 16546.57 examples/s]Dataset preprocessing (num_proc=30):  77%|███████▋  | 67595/88161 [00:04<00:01, 16799.94 examples/s]Dataset preprocessing (num_proc=30):  80%|████████  | 70533/88161 [00:04<00:01, 17102.56 examples/s]Dataset preprocessing (num_proc=30):  83%|████████▎ | 73471/88161 [00:04<00:00, 16365.58 examples/s]Dataset preprocessing (num_proc=30):  87%|████████▋ | 76409/88161 [00:05<00:00, 13636.05 examples/s]Dataset preprocessing (num_proc=30):  93%|█████████▎| 82285/88161 [00:05<00:00, 16244.28 examples/s]Dataset preprocessing (num_proc=30):  97%|█████████▋| 85223/88161 [00:05<00:00, 15664.63 examples/s]Dataset preprocessing (num_proc=30): 100%|██████████| 88161/88161 [00:05<00:00, 16522.20 examples/s]Dataset preprocessing (num_proc=30): 100%|██████████| 88161/88161 [00:06<00:00, 14622.82 examples/s]
Dataset preprocessing (num_proc=30):   0%|          | 0/10000 [00:00<?, ? examples/s]Dataset preprocessing (num_proc=30):   3%|▎         | 334/10000 [00:00<00:06, 1445.61 examples/s]Dataset preprocessing (num_proc=30):  20%|██        | 2004/10000 [00:00<00:01, 6197.74 examples/s]Dataset preprocessing (num_proc=30):  30%|███       | 3006/10000 [00:00<00:00, 7103.07 examples/s]Dataset preprocessing (num_proc=30):  47%|████▋     | 4672/10000 [00:00<00:00, 9526.48 examples/s]Dataset preprocessing (num_proc=30):  63%|██████▎   | 6337/10000 [00:00<00:00, 10977.05 examples/s]Dataset preprocessing (num_proc=30):  80%|████████  | 8002/10000 [00:00<00:00, 11977.66 examples/s]Dataset preprocessing (num_proc=30):  93%|█████████▎| 9334/10000 [00:00<00:00, 12034.84 examples/s]Dataset preprocessing (num_proc=30): 100%|██████████| 10000/10000 [00:01<00:00, 9195.58 examples/s]
  0%|          | 0/1378 [00:00<?, ?it/s]
=== RAW TEXT CHECK ===
text_src[0]: 'Maggie was a pregnant lady. One morning she was trying to brush her teeth. No matter what she did, the toothbrush made her gag.'
text_trg[0]: 'The more she tried the more nausea she felt. She eventually gave up and just used mouthwash.'
Are texts identical? False

=== TOKENIZATION CHECK ===
src input_ids[0]: tensor([  101,  8153,  1108,   170,  6391,  5141,   119,  1448,  2106,  1131,
         1108,  1774,  1106,  8415,  1123,  3307,   119,  1302,  2187,  1184,
         1131,  1225,   117,  1103, 14051, 20248,  1189,  1123, 21102,   119,
          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0],
       device='cuda:0')
trg input_ids[0]: tensor([  101,  1109,  1167,  1131,  1793,  1103,  1167, 22882,  1131,  1464,
          119,  1153,  2028,  1522,  1146,  1105,  1198,  1215,  1779, 24745,
          119,   102,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0], device='cuda:0')
Are input_ids identical? False

=== EMBEDDINGS ===
cls_src shape: torch.Size([64, 768])
cls_trg shape: torch.Size([64, 768])
src mean: -0.0074, std: 0.5917
trg mean: -0.0074, std: 0.5934
Pos src: Maggie was a pregnant lady. One morning she was tr...
Pos trg: The more she tried the more nausea she felt. She e...
Neg trg: She paced herself as she took the test, and checke...
---
Pos src: I got one of those new drones. It is a lot of fun....
Pos trg: It takes some really cool videos. You will have to...
Neg trg: But when she walked in, she got shocked. Her famil...
---
Pos src: Davis constantly threw things in his trash can. On...
Pos trg: Now, he throws away less as he knows it's harmful ...
Neg trg: Regardless, he decided to try driving down a busy ...
---
/home/nklotts/tencdm/train_conditional_encoder.py:227: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  t = torch.cuda.FloatTensor(total_batch_size).uniform_() * (

=== LOSS & METRICS ===
loss_pos: 0.7334
loss_neg: 0.6607
total loss: 0.6970

Probs positive (first 5): tensor([0.4779, 0.4955, 0.4781, 0.4931, 0.4865], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4600, 0.4830, 0.4953, 0.4902, 0.4762], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4804
probs_neg mean: 0.4834

Pred distribution: 0=126, 1=2
Label distribution: 0=64, 1=64
Accuracy positive: 0.0000
Accuracy negative: 0.9688
  0%|          | 0/1378 [00:02<?, ?it/s, Stage=Training, Epoch=1/3, Loss=0.697]  0%|          | 1/1378 [00:02<1:04:31,  2.81s/it, Stage=Training, Epoch=1/3, Loss=0.697]Pos src: My Dad and I went to an amusement park. We rode al...
Pos trg: It went upside down and our feet dangled out the b...
Neg trg: They always wore helmets and used flashing lights....
---
Pos src: The boy wanted to play baseball. His parents signe...
Pos trg: He was scared. He made a lot of friends at practic...
Neg trg: The counselor offered her to move in so she could ...
---
Pos src: Calvin was so excited! His friends were coming ove...
Pos trg: They came over and brought him gifts. He had a gre...
Neg trg: The pizza man had seen his face before. He noticed...
---

=== LOSS & METRICS ===
loss_pos: 0.7319
loss_neg: 0.6580
total loss: 0.6949

Probs positive (first 5): tensor([0.4836, 0.4749, 0.4870, 0.4642, 0.4820], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4837, 0.4720, 0.4670, 0.4971, 0.4867], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4811
probs_neg mean: 0.4820

Pred distribution: 0=121, 1=7
Label distribution: 0=64, 1=64
Accuracy positive: 0.0469
Accuracy negative: 0.9375
  0%|          | 1/1378 [00:03<1:04:31,  2.81s/it, Stage=Training, Epoch=1/3, Loss=0.695]  0%|          | 2/1378 [00:03<29:23,  1.28s/it, Stage=Training, Epoch=1/3, Loss=0.695]  Pos src: Rachel's boyfriend had given her a locket. She was...
Pos trg: She insinuated that it was like a dog collar. Rach...
Neg trg: A government accountant alerted officials that mon...
---
Pos src: Walter paid for a bouquet to be delivered to his w...
Pos trg: A different woman got the flowers. Walter's wife t...
Neg trg: Soon, the bugs were flocking to her jar. She was a...
---
Pos src: My parents smoke tobacco. I never liked the smell ...
Pos trg: Avoiding my parents was extremely hard. I ended up...
Neg trg: They spent a whole week at their summer home. They...
---

=== LOSS & METRICS ===
loss_pos: 0.7306
loss_neg: 0.6581
total loss: 0.6944

Probs positive (first 5): tensor([0.4803, 0.4788, 0.4789, 0.4834, 0.4689], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4775, 0.4591, 0.4734, 0.4712, 0.4664], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4817
probs_neg mean: 0.4821

Pred distribution: 0=125, 1=3
Label distribution: 0=64, 1=64
Accuracy positive: 0.0312
Accuracy negative: 0.9844
  0%|          | 2/1378 [00:03<29:23,  1.28s/it, Stage=Training, Epoch=1/3, Loss=0.694]  0%|          | 3/1378 [00:03<18:03,  1.27it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7276
loss_neg: 0.6583
total loss: 0.6929

Probs positive (first 5): tensor([0.4746, 0.4798, 0.4899, 0.4914, 0.4799], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4739, 0.4820, 0.4709, 0.4659, 0.4857], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4832
probs_neg mean: 0.4822

Pred distribution: 0=126, 1=2
Label distribution: 0=64, 1=64
Accuracy positive: 0.0312
Accuracy negative: 1.0000
  0%|          | 3/1378 [00:03<18:03,  1.27it/s, Stage=Training, Epoch=1/3, Loss=0.693]  0%|          | 4/1378 [00:03<12:37,  1.81it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.7268
loss_neg: 0.6542
total loss: 0.6905

Probs positive (first 5): tensor([0.4774, 0.4737, 0.4728, 0.4783, 0.4845], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4815, 0.4810, 0.4742, 0.4967, 0.4783], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4836
probs_neg mean: 0.4801

Pred distribution: 0=125, 1=3
Label distribution: 0=64, 1=64
Accuracy positive: 0.0469
Accuracy negative: 1.0000
  0%|          | 4/1378 [00:03<12:37,  1.81it/s, Stage=Training, Epoch=1/3, Loss=0.69]   0%|          | 5/1378 [00:03<09:43,  2.35it/s, Stage=Training, Epoch=1/3, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.7263
loss_neg: 0.6577
total loss: 0.6920

Probs positive (first 5): tensor([0.4936, 0.4929, 0.4801, 0.4803, 0.4822], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4710, 0.4619, 0.4787, 0.4870, 0.4801], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4838
probs_neg mean: 0.4819

Pred distribution: 0=125, 1=3
Label distribution: 0=64, 1=64
Accuracy positive: 0.0312
Accuracy negative: 0.9844
  0%|          | 5/1378 [00:03<09:43,  2.35it/s, Stage=Training, Epoch=1/3, Loss=0.692]  0%|          | 6/1378 [00:03<07:56,  2.88it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7321
loss_neg: 0.6598
total loss: 0.6960

Probs positive (first 5): tensor([0.4706, 0.4996, 0.4843, 0.4698, 0.4939], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4680, 0.4700, 0.4823, 0.4891, 0.4788], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4810
probs_neg mean: 0.4830

Pred distribution: 0=126, 1=2
Label distribution: 0=64, 1=64
Accuracy positive: 0.0000
Accuracy negative: 0.9688
  0%|          | 6/1378 [00:03<07:56,  2.88it/s, Stage=Training, Epoch=1/3, Loss=0.696]  1%|          | 7/1378 [00:03<06:45,  3.38it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.7300
loss_neg: 0.6521
total loss: 0.6911

Probs positive (first 5): tensor([0.4852, 0.4868, 0.4853, 0.4964, 0.4944], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4745, 0.4770, 0.4797, 0.4660, 0.5011], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4820
probs_neg mean: 0.4790

Pred distribution: 0=127, 1=1
Label distribution: 0=64, 1=64
Accuracy positive: 0.0000
Accuracy negative: 0.9844
  1%|          | 7/1378 [00:04<06:45,  3.38it/s, Stage=Training, Epoch=1/3, Loss=0.691]  1%|          | 8/1378 [00:04<06:00,  3.80it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.7297
loss_neg: 0.6624
total loss: 0.6960

Probs positive (first 5): tensor([0.4859, 0.4830, 0.4771, 0.4898, 0.4762], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5080, 0.4664, 0.4745, 0.4842, 0.4793], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4821
probs_neg mean: 0.4843

Pred distribution: 0=127, 1=1
Label distribution: 0=64, 1=64
Accuracy positive: 0.0000
Accuracy negative: 0.9844
  1%|          | 8/1378 [00:04<06:00,  3.80it/s, Stage=Training, Epoch=1/3, Loss=0.696]  1%|          | 9/1378 [00:04<05:29,  4.16it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.7296
loss_neg: 0.6575
total loss: 0.6935

Probs positive (first 5): tensor([0.4648, 0.4860, 0.5010, 0.4758, 0.4829], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4648, 0.4841, 0.4730, 0.4669, 0.4741], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4822
probs_neg mean: 0.4818

Pred distribution: 0=125, 1=3
Label distribution: 0=64, 1=64
Accuracy positive: 0.0469
Accuracy negative: 1.0000
  1%|          | 9/1378 [00:04<05:29,  4.16it/s, Stage=Training, Epoch=1/3, Loss=0.694]  1%|          | 10/1378 [00:04<05:09,  4.42it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7282
loss_neg: 0.6614
total loss: 0.6948

Probs positive (first 5): tensor([0.4914, 0.4915, 0.4862, 0.4926, 0.4794], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4755, 0.4704, 0.4533, 0.4889, 0.4962], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4829
probs_neg mean: 0.4838

Pred distribution: 0=125, 1=3
Label distribution: 0=64, 1=64
Accuracy positive: 0.0000
Accuracy negative: 0.9531
  1%|          | 10/1378 [00:04<05:09,  4.42it/s, Stage=Training, Epoch=1/3, Loss=0.695]  1%|          | 11/1378 [00:04<04:57,  4.60it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7246
loss_neg: 0.6598
total loss: 0.6922

Probs positive (first 5): tensor([0.4798, 0.4926, 0.4799, 0.4906, 0.4895], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4857, 0.4801, 0.4881, 0.4895, 0.4930], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4846
probs_neg mean: 0.4830

Pred distribution: 0=124, 1=4
Label distribution: 0=64, 1=64
Accuracy positive: 0.0156
Accuracy negative: 0.9531
  1%|          | 11/1378 [00:04<04:57,  4.60it/s, Stage=Training, Epoch=1/3, Loss=0.692]  1%|          | 12/1378 [00:04<04:41,  4.85it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7287
loss_neg: 0.6654
total loss: 0.6970

Probs positive (first 5): tensor([0.4840, 0.4862, 0.4923, 0.4743, 0.4843], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4795, 0.4764, 0.4807, 0.4806, 0.4717], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4826
probs_neg mean: 0.4859

Pred distribution: 0=125, 1=3
Label distribution: 0=64, 1=64
Accuracy positive: 0.0156
Accuracy negative: 0.9688
  1%|          | 12/1378 [00:05<04:41,  4.85it/s, Stage=Training, Epoch=1/3, Loss=0.697]  1%|          | 13/1378 [00:05<04:33,  4.99it/s, Stage=Training, Epoch=1/3, Loss=0.697]
=== LOSS & METRICS ===
loss_pos: 0.7266
loss_neg: 0.6644
total loss: 0.6955

Probs positive (first 5): tensor([0.4976, 0.4853, 0.4792, 0.4891, 0.4815], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4967, 0.4746, 0.4985, 0.4893, 0.4817], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4836
probs_neg mean: 0.4853

Pred distribution: 0=125, 1=3
Label distribution: 0=64, 1=64
Accuracy positive: 0.0312
Accuracy negative: 0.9844
  1%|          | 13/1378 [00:05<04:33,  4.99it/s, Stage=Training, Epoch=1/3, Loss=0.695]  1%|          | 14/1378 [00:05<04:30,  5.04it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7306
loss_neg: 0.6634
total loss: 0.6970

Probs positive (first 5): tensor([0.4952, 0.4906, 0.4852, 0.4905, 0.4795], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4790, 0.4681, 0.4801, 0.4865, 0.4788], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4817
probs_neg mean: 0.4848

Pred distribution: 0=125, 1=3
Label distribution: 0=64, 1=64
Accuracy positive: 0.0000
Accuracy negative: 0.9531
  1%|          | 14/1378 [00:05<04:30,  5.04it/s, Stage=Training, Epoch=1/3, Loss=0.697]  1%|          | 15/1378 [00:05<04:32,  5.01it/s, Stage=Training, Epoch=1/3, Loss=0.697]
=== LOSS & METRICS ===
loss_pos: 0.7245
loss_neg: 0.6634
total loss: 0.6939

Probs positive (first 5): tensor([0.4853, 0.4835, 0.4842, 0.4761, 0.4807], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4953, 0.4906, 0.4913, 0.4780, 0.4874], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4846
probs_neg mean: 0.4848

Pred distribution: 0=128, 1=0
Label distribution: 0=64, 1=64
Accuracy positive: 0.0000
Accuracy negative: 1.0000
  1%|          | 15/1378 [00:05<04:32,  5.01it/s, Stage=Training, Epoch=1/3, Loss=0.694]  1%|          | 16/1378 [00:05<04:32,  5.00it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7239
loss_neg: 0.6597
total loss: 0.6918

Probs positive (first 5): tensor([0.4910, 0.4822, 0.4774, 0.4969, 0.4861], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4737, 0.4792, 0.4692, 0.4966, 0.4721], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4849
probs_neg mean: 0.4829

Pred distribution: 0=124, 1=4
Label distribution: 0=64, 1=64
Accuracy positive: 0.0156
Accuracy negative: 0.9531
  1%|          | 16/1378 [00:05<04:32,  5.00it/s, Stage=Training, Epoch=1/3, Loss=0.692]  1%|          | 17/1378 [00:05<04:31,  5.01it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7238
loss_neg: 0.6629
total loss: 0.6934

Probs positive (first 5): tensor([0.4847, 0.5023, 0.4946, 0.5031, 0.4886], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4732, 0.4704, 0.4847, 0.4919, 0.4900], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4850
probs_neg mean: 0.4846

Pred distribution: 0=124, 1=4
Label distribution: 0=64, 1=64
Accuracy positive: 0.0469
Accuracy negative: 0.9844
  1%|          | 17/1378 [00:06<04:31,  5.01it/s, Stage=Training, Epoch=1/3, Loss=0.693]  1%|▏         | 18/1378 [00:06<04:32,  4.99it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.7235
loss_neg: 0.6629
total loss: 0.6932

Probs positive (first 5): tensor([0.4898, 0.4879, 0.4805, 0.4832, 0.4913], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4981, 0.4950, 0.4959, 0.4804, 0.4804], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4851
probs_neg mean: 0.4846

Pred distribution: 0=122, 1=6
Label distribution: 0=64, 1=64
Accuracy positive: 0.0625
Accuracy negative: 0.9688
  1%|▏         | 18/1378 [00:06<04:32,  4.99it/s, Stage=Training, Epoch=1/3, Loss=0.693]  1%|▏         | 19/1378 [00:06<04:30,  5.03it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.7219
loss_neg: 0.6625
total loss: 0.6922

Probs positive (first 5): tensor([0.4786, 0.4873, 0.4788, 0.4877, 0.4869], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4874, 0.4864, 0.4775, 0.4743, 0.4957], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4859
probs_neg mean: 0.4844

Pred distribution: 0=123, 1=5
Label distribution: 0=64, 1=64
Accuracy positive: 0.0469
Accuracy negative: 0.9688
  1%|▏         | 19/1378 [00:06<04:30,  5.03it/s, Stage=Training, Epoch=1/3, Loss=0.692]  1%|▏         | 20/1378 [00:06<04:22,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7255
loss_neg: 0.6696
total loss: 0.6975

Probs positive (first 5): tensor([0.4829, 0.4680, 0.4927, 0.4665, 0.4945], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4830, 0.4881, 0.4875, 0.4889, 0.4818], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4842
probs_neg mean: 0.4880

Pred distribution: 0=119, 1=9
Label distribution: 0=64, 1=64
Accuracy positive: 0.0312
Accuracy negative: 0.8906
  1%|▏         | 20/1378 [00:06<04:22,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.698]  2%|▏         | 21/1378 [00:06<04:20,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.698]
=== LOSS & METRICS ===
loss_pos: 0.7214
loss_neg: 0.6683
total loss: 0.6949

Probs positive (first 5): tensor([0.4796, 0.4785, 0.4756, 0.4933, 0.4811], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4983, 0.4820, 0.4796, 0.4784, 0.4964], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4861
probs_neg mean: 0.4873

Pred distribution: 0=121, 1=7
Label distribution: 0=64, 1=64
Accuracy positive: 0.0312
Accuracy negative: 0.9219
  2%|▏         | 21/1378 [00:06<04:20,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.695]  2%|▏         | 22/1378 [00:06<04:26,  5.09it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7209
loss_neg: 0.6674
total loss: 0.6941

Probs positive (first 5): tensor([0.4828, 0.4841, 0.4987, 0.4943, 0.4905], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4890, 0.4938, 0.4947, 0.4862, 0.4785], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4864
probs_neg mean: 0.4869

Pred distribution: 0=118, 1=10
Label distribution: 0=64, 1=64
Accuracy positive: 0.0938
Accuracy negative: 0.9375
  2%|▏         | 22/1378 [00:07<04:26,  5.09it/s, Stage=Training, Epoch=1/3, Loss=0.694]  2%|▏         | 23/1378 [00:07<04:23,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7202
loss_neg: 0.6677
total loss: 0.6940

Probs positive (first 5): tensor([0.4715, 0.4889, 0.4947, 0.4911, 0.4782], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4786, 0.4775, 0.4850, 0.4940, 0.4877], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4867
probs_neg mean: 0.4871

Pred distribution: 0=122, 1=6
Label distribution: 0=64, 1=64
Accuracy positive: 0.0469
Accuracy negative: 0.9531
  2%|▏         | 23/1378 [00:07<04:23,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.694]  2%|▏         | 24/1378 [00:07<04:24,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7179
loss_neg: 0.6720
total loss: 0.6950

Probs positive (first 5): tensor([0.4840, 0.4961, 0.5022, 0.4925, 0.4841], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4905, 0.4859, 0.4851, 0.4910, 0.5013], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4878
probs_neg mean: 0.4893

Pred distribution: 0=119, 1=9
Label distribution: 0=64, 1=64
Accuracy positive: 0.0625
Accuracy negative: 0.9219
  2%|▏         | 24/1378 [00:07<04:24,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.695]  2%|▏         | 25/1378 [00:07<04:29,  5.01it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7195
loss_neg: 0.6685
total loss: 0.6940

Probs positive (first 5): tensor([0.4761, 0.4934, 0.4809, 0.4846, 0.4887], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4906, 0.4875, 0.5058, 0.4916, 0.4820], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4871
probs_neg mean: 0.4875

Pred distribution: 0=119, 1=9
Label distribution: 0=64, 1=64
Accuracy positive: 0.0938
Accuracy negative: 0.9531
  2%|▏         | 25/1378 [00:07<04:29,  5.01it/s, Stage=Training, Epoch=1/3, Loss=0.694]  2%|▏         | 26/1378 [00:07<04:29,  5.02it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7181
loss_neg: 0.6722
total loss: 0.6951

Probs positive (first 5): tensor([0.4964, 0.4926, 0.4835, 0.4785, 0.5087], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4882, 0.4848, 0.4887, 0.4869, 0.4917], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4877
probs_neg mean: 0.4893

Pred distribution: 0=116, 1=12
Label distribution: 0=64, 1=64
Accuracy positive: 0.0938
Accuracy negative: 0.9062
  2%|▏         | 26/1378 [00:07<04:29,  5.02it/s, Stage=Training, Epoch=1/3, Loss=0.695]  2%|▏         | 27/1378 [00:07<04:28,  5.04it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7130
loss_neg: 0.6689
total loss: 0.6909

Probs positive (first 5): tensor([0.4870, 0.4929, 0.4862, 0.4871, 0.4934], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4714, 0.4851, 0.4908, 0.4964, 0.4911], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4903
probs_neg mean: 0.4876

Pred distribution: 0=115, 1=13
Label distribution: 0=64, 1=64
Accuracy positive: 0.0938
Accuracy negative: 0.8906
  2%|▏         | 27/1378 [00:08<04:28,  5.04it/s, Stage=Training, Epoch=1/3, Loss=0.691]  2%|▏         | 28/1378 [00:08<04:28,  5.02it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.7123
loss_neg: 0.6717
total loss: 0.6920

Probs positive (first 5): tensor([0.4863, 0.4948, 0.5004, 0.4956, 0.4834], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5013, 0.4937, 0.4861, 0.4783, 0.4987], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4906
probs_neg mean: 0.4891

Pred distribution: 0=114, 1=14
Label distribution: 0=64, 1=64
Accuracy positive: 0.1094
Accuracy negative: 0.8906
  2%|▏         | 28/1378 [00:08<04:28,  5.02it/s, Stage=Training, Epoch=1/3, Loss=0.692]  2%|▏         | 29/1378 [00:08<04:25,  5.08it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7140
loss_neg: 0.6736
total loss: 0.6938

Probs positive (first 5): tensor([0.4915, 0.4904, 0.4876, 0.5016, 0.4796], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4947, 0.4969, 0.4985, 0.4888, 0.4904], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4897
probs_neg mean: 0.4901

Pred distribution: 0=120, 1=8
Label distribution: 0=64, 1=64
Accuracy positive: 0.1094
Accuracy negative: 0.9844
  2%|▏         | 29/1378 [00:08<04:25,  5.08it/s, Stage=Training, Epoch=1/3, Loss=0.694]  2%|▏         | 30/1378 [00:08<04:26,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7133
loss_neg: 0.6748
total loss: 0.6941

Probs positive (first 5): tensor([0.4828, 0.4932, 0.4922, 0.4987, 0.4785], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5025, 0.4912, 0.4877, 0.4880, 0.5000], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4901
probs_neg mean: 0.4907

Pred distribution: 0=115, 1=13
Label distribution: 0=64, 1=64
Accuracy positive: 0.0781
Accuracy negative: 0.8750
  2%|▏         | 30/1378 [00:08<04:26,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.694]  2%|▏         | 31/1378 [00:08<04:27,  5.04it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7106
loss_neg: 0.6731
total loss: 0.6919

Probs positive (first 5): tensor([0.4868, 0.5050, 0.4915, 0.5007, 0.5046], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4884, 0.4883, 0.4693, 0.5066, 0.4809], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4914
probs_neg mean: 0.4898

Pred distribution: 0=114, 1=14
Label distribution: 0=64, 1=64
Accuracy positive: 0.1250
Accuracy negative: 0.9062
  2%|▏         | 31/1378 [00:08<04:27,  5.04it/s, Stage=Training, Epoch=1/3, Loss=0.692]  2%|▏         | 32/1378 [00:08<04:27,  5.03it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7150
loss_neg: 0.6789
total loss: 0.6969

Probs positive (first 5): tensor([0.4919, 0.5010, 0.4867, 0.4896, 0.4924], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4889, 0.4974, 0.4920, 0.4948, 0.4959], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4893
probs_neg mean: 0.4928

Pred distribution: 0=102, 1=26
Label distribution: 0=64, 1=64
Accuracy positive: 0.1719
Accuracy negative: 0.7656
  2%|▏         | 32/1378 [00:09<04:27,  5.03it/s, Stage=Training, Epoch=1/3, Loss=0.697]  2%|▏         | 33/1378 [00:09<04:23,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.697]
=== LOSS & METRICS ===
loss_pos: 0.7073
loss_neg: 0.6783
total loss: 0.6928

Probs positive (first 5): tensor([0.4888, 0.5014, 0.5094, 0.4996, 0.4860], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4930, 0.4900, 0.5085, 0.5064, 0.4875], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4930
probs_neg mean: 0.4925

Pred distribution: 0=101, 1=27
Label distribution: 0=64, 1=64
Accuracy positive: 0.2031
Accuracy negative: 0.7812
  2%|▏         | 33/1378 [00:09<04:23,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.693]  2%|▏         | 34/1378 [00:09<04:20,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.7108
loss_neg: 0.6766
total loss: 0.6937

Probs positive (first 5): tensor([0.4909, 0.4916, 0.4847, 0.4932, 0.4835], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4824, 0.4893, 0.4891, 0.4833, 0.4974], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4913
probs_neg mean: 0.4916

Pred distribution: 0=109, 1=19
Label distribution: 0=64, 1=64
Accuracy positive: 0.1875
Accuracy negative: 0.8906
  2%|▏         | 34/1378 [00:09<04:20,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.694]  3%|▎         | 35/1378 [00:09<04:19,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7079
loss_neg: 0.6838
total loss: 0.6958

Probs positive (first 5): tensor([0.4960, 0.4945, 0.5096, 0.4855, 0.4947], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4806, 0.4773, 0.5006, 0.5109, 0.4857], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4928
probs_neg mean: 0.4952

Pred distribution: 0=92, 1=36
Label distribution: 0=64, 1=64
Accuracy positive: 0.1875
Accuracy negative: 0.6250
  3%|▎         | 35/1378 [00:09<04:19,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.696]  3%|▎         | 36/1378 [00:09<04:24,  5.08it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.7085
loss_neg: 0.6745
total loss: 0.6915

Probs positive (first 5): tensor([0.4932, 0.4898, 0.4984, 0.4902, 0.5053], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4921, 0.4746, 0.4966, 0.4841, 0.4958], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4924
probs_neg mean: 0.4905

Pred distribution: 0=109, 1=19
Label distribution: 0=64, 1=64
Accuracy positive: 0.1562
Accuracy negative: 0.8594
  3%|▎         | 36/1378 [00:09<04:24,  5.08it/s, Stage=Training, Epoch=1/3, Loss=0.692]  3%|▎         | 37/1378 [00:09<04:26,  5.03it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7075
loss_neg: 0.6838
total loss: 0.6957

Probs positive (first 5): tensor([0.4813, 0.4934, 0.4994, 0.5068, 0.5075], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4775, 0.5034, 0.5108, 0.5057, 0.5022], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4929
probs_neg mean: 0.4952

Pred distribution: 0=96, 1=32
Label distribution: 0=64, 1=64
Accuracy positive: 0.1719
Accuracy negative: 0.6719
  3%|▎         | 37/1378 [00:10<04:26,  5.03it/s, Stage=Training, Epoch=1/3, Loss=0.696]  3%|▎         | 38/1378 [00:10<04:25,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.7049
loss_neg: 0.6796
total loss: 0.6923

Probs positive (first 5): tensor([0.4832, 0.5009, 0.4878, 0.4908, 0.4804], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4786, 0.4863, 0.4771, 0.5000, 0.4933], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4942
probs_neg mean: 0.4931

Pred distribution: 0=94, 1=34
Label distribution: 0=64, 1=64
Accuracy positive: 0.2812
Accuracy negative: 0.7500
  3%|▎         | 38/1378 [00:10<04:25,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.692]  3%|▎         | 39/1378 [00:10<04:24,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7066
loss_neg: 0.6838
total loss: 0.6952

Probs positive (first 5): tensor([0.4906, 0.4962, 0.5001, 0.5012, 0.4969], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4822, 0.4814, 0.4858, 0.4894, 0.4956], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4934
probs_neg mean: 0.4952

Pred distribution: 0=97, 1=31
Label distribution: 0=64, 1=64
Accuracy positive: 0.2188
Accuracy negative: 0.7344
  3%|▎         | 39/1378 [00:10<04:24,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.695]  3%|▎         | 40/1378 [00:10<04:24,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7080
loss_neg: 0.6819
total loss: 0.6949

Probs positive (first 5): tensor([0.5035, 0.4886, 0.4818, 0.4887, 0.5064], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4925, 0.5123, 0.5018, 0.4815, 0.5033], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4927
probs_neg mean: 0.4942

Pred distribution: 0=100, 1=28
Label distribution: 0=64, 1=64
Accuracy positive: 0.1719
Accuracy negative: 0.7344
  3%|▎         | 40/1378 [00:10<04:24,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.695]  3%|▎         | 41/1378 [00:10<04:24,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7007
loss_neg: 0.6843
total loss: 0.6925

Probs positive (first 5): tensor([0.5007, 0.4975, 0.4862, 0.5162, 0.5023], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4794, 0.5084, 0.4806, 0.4962, 0.4819], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4963
probs_neg mean: 0.4955

Pred distribution: 0=86, 1=42
Label distribution: 0=64, 1=64
Accuracy positive: 0.3438
Accuracy negative: 0.6875
  3%|▎         | 41/1378 [00:10<04:24,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.692]  3%|▎         | 42/1378 [00:10<04:26,  5.02it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7005
loss_neg: 0.6876
total loss: 0.6940

Probs positive (first 5): tensor([0.4888, 0.4930, 0.4803, 0.5074, 0.5029], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4961, 0.5209, 0.4975, 0.4848, 0.4927], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4964
probs_neg mean: 0.4971

Pred distribution: 0=78, 1=50
Label distribution: 0=64, 1=64
Accuracy positive: 0.3438
Accuracy negative: 0.5625
  3%|▎         | 42/1378 [00:11<04:26,  5.02it/s, Stage=Training, Epoch=1/3, Loss=0.694]  3%|▎         | 43/1378 [00:11<04:25,  5.03it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7029
loss_neg: 0.6875
total loss: 0.6952

Probs positive (first 5): tensor([0.5022, 0.4943, 0.4959, 0.4735, 0.4965], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4928, 0.4957, 0.5111, 0.5123, 0.4770], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4952
probs_neg mean: 0.4971

Pred distribution: 0=87, 1=41
Label distribution: 0=64, 1=64
Accuracy positive: 0.2656
Accuracy negative: 0.6250
  3%|▎         | 43/1378 [00:11<04:25,  5.03it/s, Stage=Training, Epoch=1/3, Loss=0.695]  3%|▎         | 44/1378 [00:11<04:26,  5.01it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7025
loss_neg: 0.6857
total loss: 0.6941

Probs positive (first 5): tensor([0.4793, 0.4773, 0.4973, 0.4864, 0.4871], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5109, 0.4929, 0.4893, 0.5054, 0.4876], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4954
probs_neg mean: 0.4962

Pred distribution: 0=88, 1=40
Label distribution: 0=64, 1=64
Accuracy positive: 0.3281
Accuracy negative: 0.7031
  3%|▎         | 44/1378 [00:11<04:26,  5.01it/s, Stage=Training, Epoch=1/3, Loss=0.694]  3%|▎         | 45/1378 [00:11<04:25,  5.02it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6997
loss_neg: 0.6886
total loss: 0.6942

Probs positive (first 5): tensor([0.5041, 0.4923, 0.4910, 0.4975, 0.4936], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4960, 0.5001, 0.4865, 0.4964, 0.4959], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4968
probs_neg mean: 0.4976

Pred distribution: 0=83, 1=45
Label distribution: 0=64, 1=64
Accuracy positive: 0.3281
Accuracy negative: 0.6250
  3%|▎         | 45/1378 [00:11<04:25,  5.02it/s, Stage=Training, Epoch=1/3, Loss=0.694]  3%|▎         | 46/1378 [00:11<04:24,  5.04it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6975
loss_neg: 0.6900
total loss: 0.6938

Probs positive (first 5): tensor([0.4928, 0.5020, 0.4985, 0.5010, 0.4978], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5067, 0.5080, 0.4880, 0.5124, 0.5044], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4979
probs_neg mean: 0.4984

Pred distribution: 0=74, 1=54
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.5469
  3%|▎         | 46/1378 [00:11<04:24,  5.04it/s, Stage=Training, Epoch=1/3, Loss=0.694]  3%|▎         | 47/1378 [00:11<04:23,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6991
loss_neg: 0.6860
total loss: 0.6926

Probs positive (first 5): tensor([0.4950, 0.4939, 0.4870, 0.4984, 0.4881], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4830, 0.4936, 0.5009, 0.4892, 0.5062], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4971
probs_neg mean: 0.4963

Pred distribution: 0=80, 1=48
Label distribution: 0=64, 1=64
Accuracy positive: 0.3594
Accuracy negative: 0.6094
  3%|▎         | 47/1378 [00:12<04:23,  5.05it/s, Stage=Training, Epoch=1/3, Loss=0.693]  3%|▎         | 48/1378 [00:12<04:23,  5.04it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.7000
loss_neg: 0.6839
total loss: 0.6919

Probs positive (first 5): tensor([0.4927, 0.4887, 0.5096, 0.4922, 0.4968], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4965, 0.5005, 0.4977, 0.4963, 0.5065], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4967
probs_neg mean: 0.4953

Pred distribution: 0=90, 1=38
Label distribution: 0=64, 1=64
Accuracy positive: 0.2812
Accuracy negative: 0.6875
  3%|▎         | 48/1378 [00:12<04:23,  5.04it/s, Stage=Training, Epoch=1/3, Loss=0.692]  4%|▎         | 49/1378 [00:12<04:22,  5.07it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6963
loss_neg: 0.6899
total loss: 0.6931

Probs positive (first 5): tensor([0.4969, 0.4958, 0.5068, 0.4935, 0.4938], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5201, 0.4973, 0.4884, 0.4910, 0.5022], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4985
probs_neg mean: 0.4983

Pred distribution: 0=72, 1=56
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.5469
  4%|▎         | 49/1378 [00:12<04:22,  5.07it/s, Stage=Training, Epoch=1/3, Loss=0.693]  4%|▎         | 50/1378 [00:12<04:22,  5.07it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6971
loss_neg: 0.6889
total loss: 0.6930

Probs positive (first 5): tensor([0.5053, 0.4928, 0.4956, 0.4932, 0.5015], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4975, 0.5018, 0.5056, 0.4893, 0.4996], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4981
probs_neg mean: 0.4978

Pred distribution: 0=75, 1=53
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.5625
  4%|▎         | 50/1378 [00:12<04:22,  5.07it/s, Stage=Training, Epoch=1/3, Loss=0.693]  4%|▎         | 51/1378 [00:12<04:19,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.7001
loss_neg: 0.6928
total loss: 0.6965

Probs positive (first 5): tensor([0.5021, 0.4960, 0.5050, 0.5091, 0.4902], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5016, 0.5087, 0.5089, 0.4925, 0.5096], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4966
probs_neg mean: 0.4998

Pred distribution: 0=77, 1=51
Label distribution: 0=64, 1=64
Accuracy positive: 0.3438
Accuracy negative: 0.5469
  4%|▎         | 51/1378 [00:12<04:19,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.696]  4%|▍         | 52/1378 [00:12<04:20,  5.08it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6964
loss_neg: 0.6902
total loss: 0.6933

Probs positive (first 5): tensor([0.5009, 0.5080, 0.4965, 0.5110, 0.4904], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4950, 0.4992, 0.5123, 0.4981, 0.5015], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4984
probs_neg mean: 0.4985

Pred distribution: 0=70, 1=58
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.5625
  4%|▍         | 52/1378 [00:13<04:20,  5.08it/s, Stage=Training, Epoch=1/3, Loss=0.693]  4%|▍         | 53/1378 [00:13<04:18,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6971
loss_neg: 0.6929
total loss: 0.6950

Probs positive (first 5): tensor([0.4972, 0.5090, 0.5014, 0.4916, 0.5035], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4947, 0.5103, 0.5073, 0.5039, 0.4884], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4981
probs_neg mean: 0.4998

Pred distribution: 0=71, 1=57
Label distribution: 0=64, 1=64
Accuracy positive: 0.3750
Accuracy negative: 0.4844
  4%|▍         | 53/1378 [00:13<04:18,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.695]  4%|▍         | 54/1378 [00:13<04:06,  5.37it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6967
loss_neg: 0.6929
total loss: 0.6948

Probs positive (first 5): tensor([0.5098, 0.5049, 0.5075, 0.5121, 0.5037], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4996, 0.4952, 0.5089, 0.5103, 0.5113], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4983
probs_neg mean: 0.4998

Pred distribution: 0=68, 1=60
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.5938
  4%|▍         | 54/1378 [00:13<04:06,  5.37it/s, Stage=Training, Epoch=1/3, Loss=0.695]  4%|▍         | 55/1378 [00:13<04:13,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6951
loss_neg: 0.6861
total loss: 0.6906

Probs positive (first 5): tensor([0.4970, 0.5007, 0.5026, 0.5014, 0.5018], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5114, 0.4929, 0.5099, 0.4954, 0.4919], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4991
probs_neg mean: 0.4964

Pred distribution: 0=82, 1=46
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.6875
  4%|▍         | 55/1378 [00:13<04:13,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.691]  4%|▍         | 56/1378 [00:13<04:14,  5.19it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6960
loss_neg: 0.6877
total loss: 0.6919

Probs positive (first 5): tensor([0.4964, 0.4894, 0.5060, 0.4991, 0.4943], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5002, 0.4985, 0.5068, 0.4743, 0.4942], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4987
probs_neg mean: 0.4972

Pred distribution: 0=79, 1=49
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.6406
  4%|▍         | 56/1378 [00:13<04:14,  5.19it/s, Stage=Training, Epoch=1/3, Loss=0.692]  4%|▍         | 57/1378 [00:13<04:19,  5.09it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6968
loss_neg: 0.6909
total loss: 0.6938

Probs positive (first 5): tensor([0.4973, 0.4945, 0.5066, 0.5131, 0.4956], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5045, 0.4907, 0.5052, 0.4997, 0.5048], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4982
probs_neg mean: 0.4988

Pred distribution: 0=72, 1=56
Label distribution: 0=64, 1=64
Accuracy positive: 0.3750
Accuracy negative: 0.5000
  4%|▍         | 57/1378 [00:13<04:19,  5.09it/s, Stage=Training, Epoch=1/3, Loss=0.694]  4%|▍         | 58/1378 [00:13<04:18,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6947
loss_neg: 0.6880
total loss: 0.6913

Probs positive (first 5): tensor([0.5122, 0.5012, 0.4944, 0.5071, 0.5120], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5065, 0.4931, 0.4889, 0.5022, 0.5004], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4993
probs_neg mean: 0.4973

Pred distribution: 0=77, 1=51
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.6094
  4%|▍         | 58/1378 [00:14<04:18,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.691]  4%|▍         | 59/1378 [00:14<04:14,  5.19it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6967
loss_neg: 0.6925
total loss: 0.6946

Probs positive (first 5): tensor([0.4880, 0.5019, 0.5074, 0.5043, 0.5100], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5124, 0.4980, 0.5080, 0.4744, 0.5131], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4983
probs_neg mean: 0.4996

Pred distribution: 0=71, 1=57
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.5156
  4%|▍         | 59/1378 [00:14<04:14,  5.19it/s, Stage=Training, Epoch=1/3, Loss=0.695]  4%|▍         | 60/1378 [00:14<04:12,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6963
loss_neg: 0.6887
total loss: 0.6925

Probs positive (first 5): tensor([0.5090, 0.4911, 0.5067, 0.4885, 0.4981], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5015, 0.5179, 0.5041, 0.5074, 0.4992], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4985
probs_neg mean: 0.4977

Pred distribution: 0=71, 1=57
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.5938
  4%|▍         | 60/1378 [00:14<04:12,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.692]  4%|▍         | 61/1378 [00:14<04:11,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6959
loss_neg: 0.6898
total loss: 0.6929

Probs positive (first 5): tensor([0.5035, 0.4888, 0.4950, 0.4952, 0.5121], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5112, 0.4990, 0.4843, 0.4956, 0.5055], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4987
probs_neg mean: 0.4983

Pred distribution: 0=73, 1=55
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.6094
  4%|▍         | 61/1378 [00:14<04:11,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.693]  4%|▍         | 62/1378 [00:14<04:15,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6941
loss_neg: 0.6882
total loss: 0.6912

Probs positive (first 5): tensor([0.4969, 0.4965, 0.4911, 0.4959, 0.5089], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4948, 0.5192, 0.5028, 0.5076, 0.5008], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4996
probs_neg mean: 0.4974

Pred distribution: 0=71, 1=57
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.6094
  4%|▍         | 62/1378 [00:14<04:15,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.691]  5%|▍         | 63/1378 [00:14<04:12,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6982
loss_neg: 0.6888
total loss: 0.6935

Probs positive (first 5): tensor([0.4959, 0.5016, 0.5008, 0.4987, 0.4989], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4995, 0.4937, 0.5179, 0.5028, 0.5042], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4975
probs_neg mean: 0.4978

Pred distribution: 0=75, 1=53
Label distribution: 0=64, 1=64
Accuracy positive: 0.3750
Accuracy negative: 0.5469
  5%|▍         | 63/1378 [00:15<04:12,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.694]  5%|▍         | 64/1378 [00:15<04:13,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6944
loss_neg: 0.6918
total loss: 0.6931

Probs positive (first 5): tensor([0.4739, 0.4905, 0.4899, 0.4895, 0.5064], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4931, 0.4885, 0.5009, 0.5005, 0.4972], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4995
probs_neg mean: 0.4993

Pred distribution: 0=66, 1=62
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.5625
  5%|▍         | 64/1378 [00:15<04:13,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.693]  5%|▍         | 65/1378 [00:15<04:13,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6962
loss_neg: 0.6898
total loss: 0.6930

Probs positive (first 5): tensor([0.5073, 0.5084, 0.5017, 0.5104, 0.4978], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5036, 0.4996, 0.5092, 0.4868, 0.4850], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4985
probs_neg mean: 0.4982

Pred distribution: 0=75, 1=53
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.6094
  5%|▍         | 65/1378 [00:15<04:13,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.693]  5%|▍         | 66/1378 [00:15<04:14,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6985
loss_neg: 0.6942
total loss: 0.6964

Probs positive (first 5): tensor([0.4950, 0.4470, 0.5046, 0.5023, 0.5088], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5094, 0.4909, 0.4945, 0.5003, 0.4990], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4975
probs_neg mean: 0.5005

Pred distribution: 0=60, 1=68
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.4375
  5%|▍         | 66/1378 [00:15<04:14,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.696]  5%|▍         | 67/1378 [00:15<04:16,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6945
loss_neg: 0.6931
total loss: 0.6938

Probs positive (first 5): tensor([0.4904, 0.5093, 0.4982, 0.5070, 0.4968], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5018, 0.5049, 0.5022, 0.5040, 0.4954], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4994
probs_neg mean: 0.4999

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.4844
  5%|▍         | 67/1378 [00:15<04:16,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.694]  5%|▍         | 68/1378 [00:15<04:12,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6924
loss_neg: 0.6905
total loss: 0.6915

Probs positive (first 5): tensor([0.5157, 0.5059, 0.4835, 0.4866, 0.5013], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4948, 0.4774, 0.4997, 0.5130, 0.4788], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5004
probs_neg mean: 0.4986

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.5781
  5%|▍         | 68/1378 [00:16<04:12,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.691]  5%|▌         | 69/1378 [00:16<04:15,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6933
loss_neg: 0.6926
total loss: 0.6929

Probs positive (first 5): tensor([0.5072, 0.5022, 0.5024, 0.4951, 0.4992], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5110, 0.5001, 0.5083, 0.5060, 0.5154], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5000
probs_neg mean: 0.4996

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.5312
  5%|▌         | 69/1378 [00:16<04:15,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.693]  5%|▌         | 70/1378 [00:16<04:20,  5.03it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6942
loss_neg: 0.6920
total loss: 0.6931

Probs positive (first 5): tensor([0.4952, 0.4830, 0.4888, 0.4910, 0.4759], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4997, 0.5018, 0.5001, 0.5019, 0.4917], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4995
probs_neg mean: 0.4993

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.5156
  5%|▌         | 70/1378 [00:16<04:20,  5.03it/s, Stage=Training, Epoch=1/3, Loss=0.693]  5%|▌         | 71/1378 [00:16<04:14,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6916
loss_neg: 0.6926
total loss: 0.6921

Probs positive (first 5): tensor([0.4957, 0.5097, 0.5113, 0.5052, 0.4892], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4908, 0.5045, 0.4884, 0.5060, 0.5006], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5009
probs_neg mean: 0.4997

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.4688
  5%|▌         | 71/1378 [00:16<04:14,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.692]  5%|▌         | 72/1378 [00:16<04:11,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6910
loss_neg: 0.6947
total loss: 0.6928

Probs positive (first 5): tensor([0.5093, 0.4906, 0.5121, 0.4945, 0.4908], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5170, 0.5130, 0.4870, 0.5085, 0.4975], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5011
probs_neg mean: 0.5007

Pred distribution: 0=59, 1=69
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.4844
  5%|▌         | 72/1378 [00:16<04:11,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.693]  5%|▌         | 73/1378 [00:16<04:11,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6890
loss_neg: 0.6929
total loss: 0.6910

Probs positive (first 5): tensor([0.5066, 0.5111, 0.4850, 0.4913, 0.4945], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5022, 0.4984, 0.5072, 0.4962, 0.4898], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5021
probs_neg mean: 0.4998

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.5625
  5%|▌         | 73/1378 [00:17<04:11,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.691]  5%|▌         | 74/1378 [00:17<04:10,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6946
loss_neg: 0.6900
total loss: 0.6923

Probs positive (first 5): tensor([0.5036, 0.5112, 0.4955, 0.5065, 0.5150], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5009, 0.4962, 0.5164, 0.4994, 0.5003], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4993
probs_neg mean: 0.4983

Pred distribution: 0=72, 1=56
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.5469
  5%|▌         | 74/1378 [00:17<04:10,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.692]  5%|▌         | 75/1378 [00:17<04:10,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6892
loss_neg: 0.6935
total loss: 0.6913

Probs positive (first 5): tensor([0.4846, 0.5018, 0.5223, 0.5216, 0.5072], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5048, 0.5004, 0.4937, 0.5056, 0.5144], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5021
probs_neg mean: 0.5001

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.6250
Accuracy negative: 0.5000
  5%|▌         | 75/1378 [00:17<04:10,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.691]  6%|▌         | 76/1378 [00:17<04:08,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6922
loss_neg: 0.6913
total loss: 0.6918

Probs positive (first 5): tensor([0.4967, 0.5124, 0.5057, 0.4711, 0.4952], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4991, 0.5028, 0.4988, 0.5100, 0.5087], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5005
probs_neg mean: 0.4990

Pred distribution: 0=59, 1=69
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.5312
  6%|▌         | 76/1378 [00:17<04:08,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.692]  6%|▌         | 77/1378 [00:17<04:07,  5.25it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6920
loss_neg: 0.6991
total loss: 0.6955

Probs positive (first 5): tensor([0.4960, 0.5107, 0.5091, 0.4984, 0.5035], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5031, 0.5129, 0.5005, 0.4974, 0.5085], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.5029

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.3594
  6%|▌         | 77/1378 [00:17<04:07,  5.25it/s, Stage=Training, Epoch=1/3, Loss=0.696]  6%|▌         | 78/1378 [00:17<04:05,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6892
loss_neg: 0.6954
total loss: 0.6923

Probs positive (first 5): tensor([0.5025, 0.5063, 0.5053, 0.5129, 0.5082], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5007, 0.5051, 0.5021, 0.5152, 0.5143], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5020
probs_neg mean: 0.5011

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.4219
  6%|▌         | 78/1378 [00:18<04:05,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.692]  6%|▌         | 79/1378 [00:18<04:02,  5.35it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6898
loss_neg: 0.6948
total loss: 0.6923

Probs positive (first 5): tensor([0.4945, 0.4935, 0.5029, 0.4875, 0.4960], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5097, 0.5102, 0.4951, 0.4958, 0.5133], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5018
probs_neg mean: 0.5008

Pred distribution: 0=55, 1=73
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4688
  6%|▌         | 79/1378 [00:18<04:02,  5.35it/s, Stage=Training, Epoch=1/3, Loss=0.692]  6%|▌         | 80/1378 [00:18<04:02,  5.34it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6916
loss_neg: 0.6922
total loss: 0.6919

Probs positive (first 5): tensor([0.5081, 0.4994, 0.4917, 0.5119, 0.4994], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5008, 0.4880, 0.4987, 0.5049, 0.5092], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5009
probs_neg mean: 0.4994

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.4688
  6%|▌         | 80/1378 [00:18<04:02,  5.34it/s, Stage=Training, Epoch=1/3, Loss=0.692]  6%|▌         | 81/1378 [00:18<04:03,  5.33it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6916
loss_neg: 0.6954
total loss: 0.6935

Probs positive (first 5): tensor([0.4977, 0.4998, 0.5259, 0.4806, 0.5149], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5035, 0.5017, 0.4960, 0.4972, 0.4986], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5009
probs_neg mean: 0.5010

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.4688
  6%|▌         | 81/1378 [00:18<04:03,  5.33it/s, Stage=Training, Epoch=1/3, Loss=0.693]  6%|▌         | 82/1378 [00:18<04:07,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6909
loss_neg: 0.6940
total loss: 0.6925

Probs positive (first 5): tensor([0.4943, 0.4963, 0.4982, 0.4922, 0.4786], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4997, 0.5138, 0.5025, 0.4925, 0.5092], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5012
probs_neg mean: 0.5004

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.4531
  6%|▌         | 82/1378 [00:18<04:07,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.692]  6%|▌         | 83/1378 [00:18<04:10,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6914
loss_neg: 0.6939
total loss: 0.6926

Probs positive (first 5): tensor([0.5019, 0.5026, 0.5115, 0.4939, 0.4888], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4871, 0.4952, 0.4930, 0.5055, 0.4924], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5010
probs_neg mean: 0.5003

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.3906
  6%|▌         | 83/1378 [00:18<04:10,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.693]  6%|▌         | 84/1378 [00:18<04:10,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6859
loss_neg: 0.6984
total loss: 0.6921

Probs positive (first 5): tensor([0.4919, 0.5064, 0.5130, 0.5006, 0.5051], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4918, 0.5184, 0.5198, 0.4973, 0.4746], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5037
probs_neg mean: 0.5025

Pred distribution: 0=46, 1=82
Label distribution: 0=64, 1=64
Accuracy positive: 0.6875
Accuracy negative: 0.4062
  6%|▌         | 84/1378 [00:19<04:10,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.692]  6%|▌         | 85/1378 [00:19<04:14,  5.08it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6940
loss_neg: 0.6964
total loss: 0.6952

Probs positive (first 5): tensor([0.5163, 0.4863, 0.5116, 0.5039, 0.4678], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4952, 0.5076, 0.5009, 0.4996, 0.4964], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4997
probs_neg mean: 0.5016

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.4219
  6%|▌         | 85/1378 [00:19<04:14,  5.08it/s, Stage=Training, Epoch=1/3, Loss=0.695]  6%|▌         | 86/1378 [00:19<04:12,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6893
loss_neg: 0.6987
total loss: 0.6940

Probs positive (first 5): tensor([0.5070, 0.5030, 0.5128, 0.5200, 0.4822], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4979, 0.5019, 0.5116, 0.5021, 0.4962], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5021
probs_neg mean: 0.5027

Pred distribution: 0=51, 1=77
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4062
  6%|▌         | 86/1378 [00:19<04:12,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.694]  6%|▋         | 87/1378 [00:19<04:11,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6926
loss_neg: 0.6978
total loss: 0.6952

Probs positive (first 5): tensor([0.5044, 0.4779, 0.5176, 0.5137, 0.5020], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5066, 0.5034, 0.5023, 0.5076, 0.4998], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5004
probs_neg mean: 0.5022

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.4062
  6%|▋         | 87/1378 [00:19<04:11,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.695]  6%|▋         | 88/1378 [00:19<04:13,  5.09it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6913
loss_neg: 0.6940
total loss: 0.6927

Probs positive (first 5): tensor([0.4884, 0.4958, 0.5013, 0.5212, 0.5051], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5013, 0.5060, 0.4976, 0.4923, 0.4887], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5010
probs_neg mean: 0.5003

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.4531
  6%|▋         | 88/1378 [00:19<04:13,  5.09it/s, Stage=Training, Epoch=1/3, Loss=0.693]  6%|▋         | 89/1378 [00:19<04:11,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6911
loss_neg: 0.7009
total loss: 0.6960

Probs positive (first 5): tensor([0.4946, 0.5002, 0.5060, 0.4990, 0.5152], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4888, 0.4911, 0.5058, 0.5144, 0.5125], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5011
probs_neg mean: 0.5038

Pred distribution: 0=51, 1=77
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.3594
  6%|▋         | 89/1378 [00:20<04:11,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.696]  7%|▋         | 90/1378 [00:20<04:14,  5.06it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6920
loss_neg: 0.6973
total loss: 0.6947

Probs positive (first 5): tensor([0.4871, 0.5052, 0.5153, 0.4859, 0.5024], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4982, 0.4934, 0.5069, 0.5078, 0.4964], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.5020

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.4219
  7%|▋         | 90/1378 [00:20<04:14,  5.06it/s, Stage=Training, Epoch=1/3, Loss=0.695]  7%|▋         | 91/1378 [00:20<04:08,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6886
loss_neg: 0.6953
total loss: 0.6920

Probs positive (first 5): tensor([0.5019, 0.5104, 0.5127, 0.4968, 0.5002], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5031, 0.5192, 0.5020, 0.4865, 0.5134], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5023
probs_neg mean: 0.5010

Pred distribution: 0=47, 1=81
Label distribution: 0=64, 1=64
Accuracy positive: 0.6562
Accuracy negative: 0.3906
  7%|▋         | 91/1378 [00:20<04:08,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.692]  7%|▋         | 92/1378 [00:20<04:04,  5.26it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6928
loss_neg: 0.6947
total loss: 0.6938

Probs positive (first 5): tensor([0.5064, 0.4891, 0.5066, 0.4938, 0.5092], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5114, 0.5119, 0.4945, 0.4905, 0.5094], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5002
probs_neg mean: 0.5007

Pred distribution: 0=60, 1=68
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.4688
  7%|▋         | 92/1378 [00:20<04:04,  5.26it/s, Stage=Training, Epoch=1/3, Loss=0.694]  7%|▋         | 93/1378 [00:20<04:05,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6906
loss_neg: 0.6922
total loss: 0.6914

Probs positive (first 5): tensor([0.4907, 0.5078, 0.5145, 0.5147, 0.5185], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5044, 0.4978, 0.4907, 0.4886, 0.4924], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5014
probs_neg mean: 0.4994

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.6250
Accuracy negative: 0.5000
  7%|▋         | 93/1378 [00:20<04:05,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.691]  7%|▋         | 94/1378 [00:20<04:05,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6959
loss_neg: 0.6967
total loss: 0.6963

Probs positive (first 5): tensor([0.5130, 0.4732, 0.4977, 0.4905, 0.4994], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4977, 0.5077, 0.5101, 0.4960, 0.5065], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4987
probs_neg mean: 0.5017

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.4531
  7%|▋         | 94/1378 [00:21<04:05,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.696]  7%|▋         | 95/1378 [00:21<04:05,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6886
loss_neg: 0.6893
total loss: 0.6889

Probs positive (first 5): tensor([0.4932, 0.4946, 0.5041, 0.5027, 0.5125], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4925, 0.4975, 0.5037, 0.4941, 0.5059], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5024
probs_neg mean: 0.4980

Pred distribution: 0=61, 1=67
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.5625
  7%|▋         | 95/1378 [00:21<04:05,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.689]  7%|▋         | 96/1378 [00:21<04:02,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.689]
=== LOSS & METRICS ===
loss_pos: 0.6916
loss_neg: 0.6914
total loss: 0.6915

Probs positive (first 5): tensor([0.5093, 0.5015, 0.4894, 0.4998, 0.4859], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5083, 0.4913, 0.5070, 0.4999, 0.5042], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5009
probs_neg mean: 0.4990

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.5469
  7%|▋         | 96/1378 [00:21<04:02,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.691]  7%|▋         | 97/1378 [00:21<04:07,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6963
loss_neg: 0.6986
total loss: 0.6975

Probs positive (first 5): tensor([0.4909, 0.5076, 0.5041, 0.4911, 0.4978], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5086, 0.5116, 0.5021, 0.5071, 0.5107], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4985
probs_neg mean: 0.5026

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.4062
  7%|▋         | 97/1378 [00:21<04:07,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.697]  7%|▋         | 98/1378 [00:21<04:02,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.697]
=== LOSS & METRICS ===
loss_pos: 0.6951
loss_neg: 0.6899
total loss: 0.6925

Probs positive (first 5): tensor([0.5006, 0.5026, 0.5041, 0.4856, 0.5041], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4951, 0.5016, 0.5027, 0.5122, 0.5038], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4991
probs_neg mean: 0.4983

Pred distribution: 0=72, 1=56
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.6094
  7%|▋         | 98/1378 [00:21<04:02,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.693]  7%|▋         | 99/1378 [00:21<04:01,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6968
loss_neg: 0.6871
total loss: 0.6919

Probs positive (first 5): tensor([0.4956, 0.4908, 0.5060, 0.4924, 0.5009], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5022, 0.4698, 0.4954, 0.4946, 0.4938], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4983
probs_neg mean: 0.4969

Pred distribution: 0=74, 1=54
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.6250
  7%|▋         | 99/1378 [00:22<04:01,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.692]  7%|▋         | 100/1378 [00:22<04:02,  5.26it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6919
loss_neg: 0.6903
total loss: 0.6911

Probs positive (first 5): tensor([0.5110, 0.4964, 0.5083, 0.4917, 0.5162], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5005, 0.4976, 0.4913, 0.5036, 0.5022], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5007
probs_neg mean: 0.4985

Pred distribution: 0=59, 1=69
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.5312
  7%|▋         | 100/1378 [00:22<04:02,  5.26it/s, Stage=Training, Epoch=1/3, Loss=0.691]  7%|▋         | 101/1378 [00:22<04:04,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6974
loss_neg: 0.6871
total loss: 0.6922

Probs positive (first 5): tensor([0.4994, 0.4887, 0.5095, 0.5004, 0.5052], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4982, 0.4838, 0.5040, 0.5196, 0.4620], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4980
probs_neg mean: 0.4969

Pred distribution: 0=73, 1=55
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.5938
  7%|▋         | 101/1378 [00:22<04:04,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.692]  7%|▋         | 102/1378 [00:22<04:07,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6945
loss_neg: 0.6918
total loss: 0.6932

Probs positive (first 5): tensor([0.4901, 0.4992, 0.5002, 0.5030, 0.5097], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4993, 0.5093, 0.4990, 0.5008, 0.5049], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4994
probs_neg mean: 0.4993

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.5625
  7%|▋         | 102/1378 [00:22<04:07,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.693]  7%|▋         | 103/1378 [00:22<04:07,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6978
loss_neg: 0.6902
total loss: 0.6940

Probs positive (first 5): tensor([0.4904, 0.4885, 0.4828, 0.5136, 0.5120], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4944, 0.4900, 0.5167, 0.4802, 0.4974], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4978
probs_neg mean: 0.4984

Pred distribution: 0=70, 1=58
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.5000
  7%|▋         | 103/1378 [00:22<04:07,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.694]  8%|▊         | 104/1378 [00:22<04:09,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6962
loss_neg: 0.6890
total loss: 0.6926

Probs positive (first 5): tensor([0.4799, 0.4785, 0.4873, 0.5012, 0.4832], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5036, 0.4968, 0.5027, 0.4906, 0.5128], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4986
probs_neg mean: 0.4979

Pred distribution: 0=68, 1=60
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.6406
  8%|▊         | 104/1378 [00:23<04:09,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.693]  8%|▊         | 105/1378 [00:23<04:07,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6970
loss_neg: 0.6923
total loss: 0.6947

Probs positive (first 5): tensor([0.5085, 0.4967, 0.4892, 0.5160, 0.4923], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4992, 0.4934, 0.4904, 0.4962, 0.5103], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4982
probs_neg mean: 0.4995

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.4844
  8%|▊         | 105/1378 [00:23<04:07,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.695]  8%|▊         | 106/1378 [00:23<04:00,  5.29it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6995
loss_neg: 0.6904
total loss: 0.6949

Probs positive (first 5): tensor([0.4970, 0.4944, 0.5033, 0.4978, 0.5089], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5194, 0.4958, 0.5154, 0.5058, 0.4990], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4969
probs_neg mean: 0.4985

Pred distribution: 0=79, 1=49
Label distribution: 0=64, 1=64
Accuracy positive: 0.3594
Accuracy negative: 0.5938
  8%|▊         | 106/1378 [00:23<04:00,  5.29it/s, Stage=Training, Epoch=1/3, Loss=0.695]  8%|▊         | 107/1378 [00:23<03:59,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6960
loss_neg: 0.6921
total loss: 0.6941

Probs positive (first 5): tensor([0.4997, 0.4956, 0.4960, 0.5033, 0.5196], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4941, 0.4973, 0.5039, 0.5117, 0.5024], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4986
probs_neg mean: 0.4994

Pred distribution: 0=69, 1=59
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.5312
  8%|▊         | 107/1378 [00:23<03:59,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.694]  8%|▊         | 108/1378 [00:23<03:59,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6966
loss_neg: 0.6871
total loss: 0.6919

Probs positive (first 5): tensor([0.4747, 0.5009, 0.4892, 0.4930, 0.4989], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4995, 0.5050, 0.5055, 0.5123, 0.5241], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4984
probs_neg mean: 0.4969

Pred distribution: 0=73, 1=55
Label distribution: 0=64, 1=64
Accuracy positive: 0.4531
Accuracy negative: 0.5938
  8%|▊         | 108/1378 [00:23<03:59,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.692]  8%|▊         | 109/1378 [00:23<03:59,  5.31it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6923
loss_neg: 0.6928
total loss: 0.6925

Probs positive (first 5): tensor([0.4717, 0.4972, 0.4941, 0.5023, 0.5198], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5052, 0.4947, 0.4986, 0.4867, 0.5009], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5006
probs_neg mean: 0.4997

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.4531
  8%|▊         | 109/1378 [00:23<03:59,  5.31it/s, Stage=Training, Epoch=1/3, Loss=0.693]  8%|▊         | 110/1378 [00:23<03:52,  5.45it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6952
loss_neg: 0.6903
total loss: 0.6928

Probs positive (first 5): tensor([0.5040, 0.5079, 0.5149, 0.5109, 0.4970], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4906, 0.5002, 0.5042, 0.5059, 0.5064], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4990
probs_neg mean: 0.4985

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.5469
  8%|▊         | 110/1378 [00:24<03:52,  5.45it/s, Stage=Training, Epoch=1/3, Loss=0.693]  8%|▊         | 111/1378 [00:24<03:47,  5.57it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6926
loss_neg: 0.6914
total loss: 0.6920

Probs positive (first 5): tensor([0.5038, 0.4942, 0.5075, 0.5092, 0.4992], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5058, 0.5043, 0.5034, 0.5019, 0.4888], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5003
probs_neg mean: 0.4990

Pred distribution: 0=62, 1=66
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.5312
  8%|▊         | 111/1378 [00:24<03:47,  5.57it/s, Stage=Training, Epoch=1/3, Loss=0.692]  8%|▊         | 112/1378 [00:24<03:49,  5.51it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6978
loss_neg: 0.6879
total loss: 0.6929

Probs positive (first 5): tensor([0.5103, 0.4956, 0.5117, 0.5051, 0.4916], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4864, 0.4993, 0.4914, 0.5026, 0.4964], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4978
probs_neg mean: 0.4973

Pred distribution: 0=78, 1=50
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.6406
  8%|▊         | 112/1378 [00:24<03:49,  5.51it/s, Stage=Training, Epoch=1/3, Loss=0.693]  8%|▊         | 113/1378 [00:24<03:50,  5.48it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6961
loss_neg: 0.6930
total loss: 0.6945

Probs positive (first 5): tensor([0.5046, 0.5004, 0.4917, 0.5017, 0.4878], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4971, 0.4926, 0.5107, 0.5034, 0.4986], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4986
probs_neg mean: 0.4999

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.4688
  8%|▊         | 113/1378 [00:24<03:50,  5.48it/s, Stage=Training, Epoch=1/3, Loss=0.695]  8%|▊         | 114/1378 [00:24<03:52,  5.43it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6952
loss_neg: 0.6889
total loss: 0.6921

Probs positive (first 5): tensor([0.5037, 0.5211, 0.4937, 0.5023, 0.5076], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5005, 0.5055, 0.5027, 0.4840, 0.5030], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4990
probs_neg mean: 0.4978

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.4375
  8%|▊         | 114/1378 [00:24<03:52,  5.43it/s, Stage=Training, Epoch=1/3, Loss=0.692]  8%|▊         | 115/1378 [00:24<03:51,  5.46it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6990
loss_neg: 0.6906
total loss: 0.6948

Probs positive (first 5): tensor([0.4962, 0.4982, 0.5104, 0.4879, 0.4995], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4876, 0.5209, 0.4906, 0.5012, 0.5109], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4972
probs_neg mean: 0.4986

Pred distribution: 0=75, 1=53
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.5938
  8%|▊         | 115/1378 [00:25<03:51,  5.46it/s, Stage=Training, Epoch=1/3, Loss=0.695]  8%|▊         | 116/1378 [00:25<03:49,  5.50it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6956
loss_neg: 0.6886
total loss: 0.6921

Probs positive (first 5): tensor([0.5056, 0.4917, 0.5212, 0.5088, 0.4838], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4847, 0.5012, 0.5028, 0.4839, 0.4914], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.4976

Pred distribution: 0=78, 1=50
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.6406
  8%|▊         | 116/1378 [00:25<03:49,  5.50it/s, Stage=Training, Epoch=1/3, Loss=0.692]  8%|▊         | 117/1378 [00:25<03:47,  5.55it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6928
loss_neg: 0.6850
total loss: 0.6889

Probs positive (first 5): tensor([0.5064, 0.5041, 0.5031, 0.5111, 0.4734], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5114, 0.5013, 0.5069, 0.5056, 0.4940], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5003
probs_neg mean: 0.4958

Pred distribution: 0=68, 1=60
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.6250
  8%|▊         | 117/1378 [00:25<03:47,  5.55it/s, Stage=Training, Epoch=1/3, Loss=0.689]  9%|▊         | 118/1378 [00:25<03:51,  5.45it/s, Stage=Training, Epoch=1/3, Loss=0.689]
=== LOSS & METRICS ===
loss_pos: 0.6997
loss_neg: 0.6900
total loss: 0.6948

Probs positive (first 5): tensor([0.4683, 0.5044, 0.4891, 0.5056, 0.4939], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4973, 0.4936, 0.5131, 0.5042, 0.4928], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4968
probs_neg mean: 0.4984

Pred distribution: 0=77, 1=51
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.5938
  9%|▊         | 118/1378 [00:25<03:51,  5.45it/s, Stage=Training, Epoch=1/3, Loss=0.695]  9%|▊         | 119/1378 [00:25<03:53,  5.40it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6992
loss_neg: 0.6924
total loss: 0.6958

Probs positive (first 5): tensor([0.4929, 0.4892, 0.4919, 0.4984, 0.5112], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4903, 0.4963, 0.5087, 0.4992, 0.5072], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4971
probs_neg mean: 0.4995

Pred distribution: 0=72, 1=56
Label distribution: 0=64, 1=64
Accuracy positive: 0.3750
Accuracy negative: 0.5000
  9%|▊         | 119/1378 [00:25<03:53,  5.40it/s, Stage=Training, Epoch=1/3, Loss=0.696]  9%|▊         | 120/1378 [00:25<03:55,  5.34it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.7000
loss_neg: 0.6872
total loss: 0.6936

Probs positive (first 5): tensor([0.4836, 0.5159, 0.5114, 0.5047, 0.5116], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4904, 0.4908, 0.4892, 0.5067, 0.4883], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4967
probs_neg mean: 0.4969

Pred distribution: 0=80, 1=48
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.6562
  9%|▊         | 120/1378 [00:25<03:55,  5.34it/s, Stage=Training, Epoch=1/3, Loss=0.694]  9%|▉         | 121/1378 [00:25<03:58,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6996
loss_neg: 0.6843
total loss: 0.6919

Probs positive (first 5): tensor([0.4983, 0.4948, 0.4870, 0.5076, 0.5168], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4742, 0.5072, 0.4908, 0.5100, 0.5015], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4969
probs_neg mean: 0.4954

Pred distribution: 0=73, 1=55
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.5625
  9%|▉         | 121/1378 [00:26<03:58,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.692]  9%|▉         | 122/1378 [00:26<03:59,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6999
loss_neg: 0.6899
total loss: 0.6949

Probs positive (first 5): tensor([0.5006, 0.5161, 0.4980, 0.4984, 0.5100], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5082, 0.4981, 0.4957, 0.5081, 0.4917], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4967
probs_neg mean: 0.4982

Pred distribution: 0=72, 1=56
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.5156
  9%|▉         | 122/1378 [00:26<03:59,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.695]  9%|▉         | 123/1378 [00:26<04:00,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7021
loss_neg: 0.6795
total loss: 0.6908

Probs positive (first 5): tensor([0.4999, 0.5094, 0.5065, 0.5065, 0.5053], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4987, 0.5023, 0.4926, 0.4934, 0.4806], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4957
probs_neg mean: 0.4930

Pred distribution: 0=88, 1=40
Label distribution: 0=64, 1=64
Accuracy positive: 0.3438
Accuracy negative: 0.7188
  9%|▉         | 123/1378 [00:26<04:00,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.691]  9%|▉         | 124/1378 [00:26<04:00,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.7023
loss_neg: 0.6869
total loss: 0.6946

Probs positive (first 5): tensor([0.5017, 0.4848, 0.4731, 0.4915, 0.5059], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4894, 0.4959, 0.4741, 0.5045, 0.4937], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4955
probs_neg mean: 0.4968

Pred distribution: 0=78, 1=50
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.6250
  9%|▉         | 124/1378 [00:26<04:00,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.695]  9%|▉         | 125/1378 [00:26<04:00,  5.21it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7010
loss_neg: 0.6845
total loss: 0.6927

Probs positive (first 5): tensor([0.4890, 0.4739, 0.4952, 0.5180, 0.5051], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4920, 0.4928, 0.5062, 0.4859, 0.4982], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4962
probs_neg mean: 0.4956

Pred distribution: 0=86, 1=42
Label distribution: 0=64, 1=64
Accuracy positive: 0.3594
Accuracy negative: 0.7031
  9%|▉         | 125/1378 [00:26<04:00,  5.21it/s, Stage=Training, Epoch=1/3, Loss=0.693]  9%|▉         | 126/1378 [00:26<04:00,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.7012
loss_neg: 0.6848
total loss: 0.6930

Probs positive (first 5): tensor([0.4957, 0.5023, 0.4988, 0.5014, 0.5065], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4992, 0.5042, 0.5001, 0.5182, 0.5054], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4961
probs_neg mean: 0.4956

Pred distribution: 0=80, 1=48
Label distribution: 0=64, 1=64
Accuracy positive: 0.3438
Accuracy negative: 0.5938
  9%|▉         | 126/1378 [00:27<04:00,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.693]  9%|▉         | 127/1378 [00:27<04:02,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.7037
loss_neg: 0.6849
total loss: 0.6943

Probs positive (first 5): tensor([0.5026, 0.4996, 0.5103, 0.4921, 0.4921], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4918, 0.5095, 0.4964, 0.4823, 0.4881], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4949
probs_neg mean: 0.4958

Pred distribution: 0=80, 1=48
Label distribution: 0=64, 1=64
Accuracy positive: 0.3750
Accuracy negative: 0.6250
  9%|▉         | 127/1378 [00:27<04:02,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.694]  9%|▉         | 128/1378 [00:27<04:02,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6957
loss_neg: 0.6851
total loss: 0.6904

Probs positive (first 5): tensor([0.4918, 0.4865, 0.4953, 0.4801, 0.4899], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4975, 0.5034, 0.4888, 0.4906, 0.4997], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.4958

Pred distribution: 0=74, 1=54
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.6406
  9%|▉         | 128/1378 [00:27<04:02,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.69]   9%|▉         | 129/1378 [00:27<04:02,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.7017
loss_neg: 0.6861
total loss: 0.6939

Probs positive (first 5): tensor([0.4699, 0.5075, 0.4924, 0.4877, 0.4948], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4742, 0.4920, 0.4743, 0.5046, 0.5020], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4958
probs_neg mean: 0.4963

Pred distribution: 0=77, 1=51
Label distribution: 0=64, 1=64
Accuracy positive: 0.3594
Accuracy negative: 0.5625
  9%|▉         | 129/1378 [00:27<04:02,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.694]  9%|▉         | 130/1378 [00:27<04:02,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7007
loss_neg: 0.6918
total loss: 0.6963

Probs positive (first 5): tensor([0.5084, 0.5063, 0.4978, 0.4758, 0.5051], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4955, 0.5070, 0.5141, 0.4926, 0.4845], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4964
probs_neg mean: 0.4992

Pred distribution: 0=70, 1=58
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.5312
  9%|▉         | 130/1378 [00:27<04:02,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.696] 10%|▉         | 131/1378 [00:27<04:03,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6954
loss_neg: 0.6870
total loss: 0.6912

Probs positive (first 5): tensor([0.5157, 0.5030, 0.5081, 0.4877, 0.5034], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5091, 0.5003, 0.4949, 0.4972, 0.4921], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.4968

Pred distribution: 0=81, 1=47
Label distribution: 0=64, 1=64
Accuracy positive: 0.3750
Accuracy negative: 0.6406
 10%|▉         | 131/1378 [00:28<04:03,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.691] 10%|▉         | 132/1378 [00:28<04:01,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6924
loss_neg: 0.6939
total loss: 0.6932

Probs positive (first 5): tensor([0.4832, 0.5071, 0.4880, 0.4966, 0.4873], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4839, 0.4869, 0.5043, 0.5097, 0.5029], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5004
probs_neg mean: 0.5003

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.4844
 10%|▉         | 132/1378 [00:28<04:01,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.693] 10%|▉         | 133/1378 [00:28<04:01,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6962
loss_neg: 0.6941
total loss: 0.6951

Probs positive (first 5): tensor([0.4891, 0.5144, 0.4995, 0.5000, 0.4957], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4967, 0.5026, 0.4811, 0.4901, 0.5004], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4986
probs_neg mean: 0.5004

Pred distribution: 0=69, 1=59
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.4844
 10%|▉         | 133/1378 [00:28<04:01,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.695] 10%|▉         | 134/1378 [00:28<04:01,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6954
loss_neg: 0.6952
total loss: 0.6953

Probs positive (first 5): tensor([0.5057, 0.4964, 0.4820, 0.4916, 0.5064], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5061, 0.5101, 0.5048, 0.4945, 0.4933], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4990
probs_neg mean: 0.5009

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.4375
 10%|▉         | 134/1378 [00:28<04:01,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.695] 10%|▉         | 135/1378 [00:28<04:02,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6936
loss_neg: 0.6965
total loss: 0.6950

Probs positive (first 5): tensor([0.4880, 0.5160, 0.5020, 0.4876, 0.4889], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4886, 0.5110, 0.4972, 0.5009, 0.4938], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4999
probs_neg mean: 0.5016

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.4531
 10%|▉         | 135/1378 [00:28<04:02,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.695] 10%|▉         | 136/1378 [00:28<04:02,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6889
loss_neg: 0.6954
total loss: 0.6921

Probs positive (first 5): tensor([0.5142, 0.4887, 0.4776, 0.5140, 0.5052], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4988, 0.5206, 0.4936, 0.4881, 0.4836], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5022
probs_neg mean: 0.5010

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.4531
 10%|▉         | 136/1378 [00:29<04:02,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.692] 10%|▉         | 137/1378 [00:29<04:02,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6883
loss_neg: 0.6957
total loss: 0.6920

Probs positive (first 5): tensor([0.4972, 0.5016, 0.4884, 0.4965, 0.4980], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5152, 0.4961, 0.5197, 0.4882, 0.4871], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5025
probs_neg mean: 0.5012

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.4688
 10%|▉         | 137/1378 [00:29<04:02,  5.12it/s, Stage=Training, Epoch=1/3, Loss=0.692] 10%|█         | 138/1378 [00:29<04:02,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6871
loss_neg: 0.6939
total loss: 0.6905

Probs positive (first 5): tensor([0.4913, 0.5083, 0.5082, 0.4941, 0.4978], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5195, 0.4974, 0.5145, 0.5031, 0.5074], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5032
probs_neg mean: 0.5003

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.5000
 10%|█         | 138/1378 [00:29<04:02,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.691] 10%|█         | 139/1378 [00:29<03:54,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6907
loss_neg: 0.6925
total loss: 0.6916

Probs positive (first 5): tensor([0.5012, 0.5018, 0.5085, 0.4851, 0.4956], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5083, 0.4917, 0.4991, 0.5125, 0.4969], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5013
probs_neg mean: 0.4996

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.4844
 10%|█         | 139/1378 [00:29<03:54,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.692] 10%|█         | 140/1378 [00:29<03:50,  5.36it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6879
loss_neg: 0.6968
total loss: 0.6924

Probs positive (first 5): tensor([0.4987, 0.5049, 0.4991, 0.5071, 0.5064], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4973, 0.5032, 0.4965, 0.5174, 0.4945], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5027
probs_neg mean: 0.5017

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4219
 10%|█         | 140/1378 [00:29<03:50,  5.36it/s, Stage=Training, Epoch=1/3, Loss=0.692] 10%|█         | 141/1378 [00:29<03:51,  5.35it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6976
loss_neg: 0.6944
total loss: 0.6960

Probs positive (first 5): tensor([0.4883, 0.4778, 0.4990, 0.4883, 0.4867], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5100, 0.4928, 0.5085, 0.5065, 0.4905], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4979
probs_neg mean: 0.5006

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.4688
 10%|█         | 141/1378 [00:30<03:51,  5.35it/s, Stage=Training, Epoch=1/3, Loss=0.696] 10%|█         | 142/1378 [00:30<03:50,  5.37it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6906
loss_neg: 0.6976
total loss: 0.6941

Probs positive (first 5): tensor([0.5058, 0.5008, 0.4895, 0.4950, 0.4894], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5036, 0.5139, 0.4877, 0.4886, 0.4938], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5014
probs_neg mean: 0.5021

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.4062
 10%|█         | 142/1378 [00:30<03:50,  5.37it/s, Stage=Training, Epoch=1/3, Loss=0.694] 10%|█         | 143/1378 [00:30<03:49,  5.38it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6949
loss_neg: 0.6916
total loss: 0.6932

Probs positive (first 5): tensor([0.4927, 0.4967, 0.4996, 0.4982, 0.4912], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4900, 0.5183, 0.5049, 0.5003, 0.4876], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4992
probs_neg mean: 0.4991

Pred distribution: 0=72, 1=56
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.5469
 10%|█         | 143/1378 [00:30<03:49,  5.38it/s, Stage=Training, Epoch=1/3, Loss=0.693] 10%|█         | 144/1378 [00:30<03:49,  5.37it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6909
loss_neg: 0.6967
total loss: 0.6938

Probs positive (first 5): tensor([0.4967, 0.5139, 0.4906, 0.4747, 0.4995], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4800, 0.4972, 0.5056, 0.5089, 0.4950], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5012
probs_neg mean: 0.5017

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.5781
Accuracy negative: 0.4219
 10%|█         | 144/1378 [00:30<03:49,  5.37it/s, Stage=Training, Epoch=1/3, Loss=0.694] 11%|█         | 145/1378 [00:30<03:51,  5.33it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6927
loss_neg: 0.6949
total loss: 0.6938

Probs positive (first 5): tensor([0.5158, 0.5046, 0.5018, 0.5064, 0.4934], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4932, 0.5082, 0.4784, 0.5070, 0.5135], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5004
probs_neg mean: 0.5008

Pred distribution: 0=59, 1=69
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.4219
 11%|█         | 145/1378 [00:30<03:51,  5.33it/s, Stage=Training, Epoch=1/3, Loss=0.694] 11%|█         | 146/1378 [00:30<03:52,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6960
loss_neg: 0.6898
total loss: 0.6929

Probs positive (first 5): tensor([0.4985, 0.4890, 0.4809, 0.5001, 0.4973], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4976, 0.4992, 0.4984, 0.5007, 0.4852], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4987
probs_neg mean: 0.4982

Pred distribution: 0=75, 1=53
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.5781
 11%|█         | 146/1378 [00:30<03:52,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.693] 11%|█         | 147/1378 [00:30<03:52,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6896
loss_neg: 0.6936
total loss: 0.6916

Probs positive (first 5): tensor([0.4964, 0.5055, 0.5169, 0.5026, 0.5260], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5037, 0.4894, 0.4892, 0.5006, 0.4958], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5019
probs_neg mean: 0.5001

Pred distribution: 0=64, 1=64
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.5156
 11%|█         | 147/1378 [00:31<03:52,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.692] 11%|█         | 148/1378 [00:31<03:53,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6957
loss_neg: 0.6883
total loss: 0.6920

Probs positive (first 5): tensor([0.4928, 0.5043, 0.5125, 0.5297, 0.4873], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5036, 0.4750, 0.5053, 0.5075, 0.4970], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.4974

Pred distribution: 0=69, 1=59
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.5625
 11%|█         | 148/1378 [00:31<03:53,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.692] 11%|█         | 149/1378 [00:31<03:54,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6911
loss_neg: 0.6915
total loss: 0.6913

Probs positive (first 5): tensor([0.5047, 0.5057, 0.5261, 0.5064, 0.5087], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4953, 0.4864, 0.5089, 0.5080, 0.4902], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5012
probs_neg mean: 0.4991

Pred distribution: 0=61, 1=67
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.5000
 11%|█         | 149/1378 [00:31<03:54,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.691] 11%|█         | 150/1378 [00:31<03:55,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6982
loss_neg: 0.6868
total loss: 0.6925

Probs positive (first 5): tensor([0.5063, 0.4662, 0.5011, 0.5077, 0.4733], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4889, 0.5023, 0.4769, 0.5074, 0.4939], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4976
probs_neg mean: 0.4967

Pred distribution: 0=75, 1=53
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.5938
 11%|█         | 150/1378 [00:31<03:55,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.693] 11%|█         | 151/1378 [00:31<03:53,  5.25it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6982
loss_neg: 0.6866
total loss: 0.6924

Probs positive (first 5): tensor([0.4874, 0.4719, 0.5130, 0.5109, 0.4903], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5026, 0.4995, 0.4843, 0.4949, 0.4887], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4976
probs_neg mean: 0.4966

Pred distribution: 0=79, 1=49
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.6406
 11%|█         | 151/1378 [00:31<03:53,  5.25it/s, Stage=Training, Epoch=1/3, Loss=0.692] 11%|█         | 152/1378 [00:31<03:52,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7023
loss_neg: 0.6821
total loss: 0.6922

Probs positive (first 5): tensor([0.5076, 0.4978, 0.5010, 0.4795, 0.5006], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5102, 0.4957, 0.4805, 0.5037, 0.5099], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4956
probs_neg mean: 0.4943

Pred distribution: 0=78, 1=50
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.6406
 11%|█         | 152/1378 [00:32<03:52,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.692] 11%|█         | 153/1378 [00:32<03:51,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7075
loss_neg: 0.6815
total loss: 0.6945

Probs positive (first 5): tensor([0.4930, 0.4721, 0.4937, 0.5113, 0.4894], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5067, 0.5164, 0.4966, 0.4941, 0.5033], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4930
probs_neg mean: 0.4940

Pred distribution: 0=96, 1=32
Label distribution: 0=64, 1=64
Accuracy positive: 0.2500
Accuracy negative: 0.7500
 11%|█         | 153/1378 [00:32<03:51,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.695] 11%|█         | 154/1378 [00:32<03:58,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7013
loss_neg: 0.6861
total loss: 0.6937

Probs positive (first 5): tensor([0.4990, 0.4963, 0.4947, 0.4910, 0.4750], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4864, 0.4952, 0.5100, 0.4898, 0.4882], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4960
probs_neg mean: 0.4963

Pred distribution: 0=83, 1=45
Label distribution: 0=64, 1=64
Accuracy positive: 0.3594
Accuracy negative: 0.6562
 11%|█         | 154/1378 [00:32<03:58,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.694] 11%|█         | 155/1378 [00:32<03:52,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7014
loss_neg: 0.6812
total loss: 0.6913

Probs positive (first 5): tensor([0.5023, 0.4846, 0.5058, 0.4986, 0.4759], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4874, 0.4934, 0.4889, 0.4993, 0.4904], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4960
probs_neg mean: 0.4939

Pred distribution: 0=94, 1=34
Label distribution: 0=64, 1=64
Accuracy positive: 0.3125
Accuracy negative: 0.7812
 11%|█         | 155/1378 [00:32<03:52,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.691] 11%|█▏        | 156/1378 [00:32<03:49,  5.32it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.7081
loss_neg: 0.6810
total loss: 0.6946

Probs positive (first 5): tensor([0.5008, 0.4912, 0.4979, 0.4971, 0.4747], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5098, 0.4932, 0.4962, 0.4897, 0.4986], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4927
probs_neg mean: 0.4938

Pred distribution: 0=93, 1=35
Label distribution: 0=64, 1=64
Accuracy positive: 0.2188
Accuracy negative: 0.6719
 11%|█▏        | 156/1378 [00:32<03:49,  5.32it/s, Stage=Training, Epoch=1/3, Loss=0.695] 11%|█▏        | 157/1378 [00:32<03:50,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7063
loss_neg: 0.6822
total loss: 0.6942

Probs positive (first 5): tensor([0.5008, 0.4981, 0.4958, 0.5173, 0.5029], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4858, 0.4723, 0.5032, 0.4927, 0.4888], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4937
probs_neg mean: 0.4944

Pred distribution: 0=89, 1=39
Label distribution: 0=64, 1=64
Accuracy positive: 0.2812
Accuracy negative: 0.6719
 11%|█▏        | 157/1378 [00:33<03:50,  5.30it/s, Stage=Training, Epoch=1/3, Loss=0.694] 11%|█▏        | 158/1378 [00:33<03:49,  5.32it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7095
loss_neg: 0.6813
total loss: 0.6954

Probs positive (first 5): tensor([0.5093, 0.4938, 0.4931, 0.5112, 0.4820], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4862, 0.5025, 0.4866, 0.4914, 0.5089], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4920
probs_neg mean: 0.4939

Pred distribution: 0=95, 1=33
Label distribution: 0=64, 1=64
Accuracy positive: 0.2344
Accuracy negative: 0.7188
 11%|█▏        | 158/1378 [00:33<03:49,  5.32it/s, Stage=Training, Epoch=1/3, Loss=0.695] 12%|█▏        | 159/1378 [00:33<03:48,  5.35it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.7033
loss_neg: 0.6830
total loss: 0.6931

Probs positive (first 5): tensor([0.4997, 0.4963, 0.4862, 0.4953, 0.4950], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5027, 0.4829, 0.5086, 0.5183, 0.4851], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4951
probs_neg mean: 0.4947

Pred distribution: 0=86, 1=42
Label distribution: 0=64, 1=64
Accuracy positive: 0.3281
Accuracy negative: 0.6719
 12%|█▏        | 159/1378 [00:33<03:48,  5.35it/s, Stage=Training, Epoch=1/3, Loss=0.693] 12%|█▏        | 160/1378 [00:33<03:48,  5.33it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.7036
loss_neg: 0.6837
total loss: 0.6936

Probs positive (first 5): tensor([0.4792, 0.5085, 0.4971, 0.4910, 0.5124], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4936, 0.4925, 0.4843, 0.5016, 0.5026], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4950
probs_neg mean: 0.4952

Pred distribution: 0=84, 1=44
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.7031
 12%|█▏        | 160/1378 [00:33<03:48,  5.33it/s, Stage=Training, Epoch=1/3, Loss=0.694] 12%|█▏        | 161/1378 [00:33<03:52,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7022
loss_neg: 0.6865
total loss: 0.6943

Probs positive (first 5): tensor([0.5117, 0.5099, 0.4884, 0.4860, 0.5012], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4966, 0.4944, 0.5057, 0.4965, 0.4932], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4957
probs_neg mean: 0.4965

Pred distribution: 0=79, 1=49
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.6406
 12%|█▏        | 161/1378 [00:33<03:52,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.694] 12%|█▏        | 162/1378 [00:33<03:54,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7057
loss_neg: 0.6915
total loss: 0.6986

Probs positive (first 5): tensor([0.4964, 0.5020, 0.4709, 0.4915, 0.4740], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5039, 0.4856, 0.5135, 0.5041, 0.4941], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4939
probs_neg mean: 0.4991

Pred distribution: 0=79, 1=49
Label distribution: 0=64, 1=64
Accuracy positive: 0.2969
Accuracy negative: 0.5312
 12%|█▏        | 162/1378 [00:34<03:54,  5.18it/s, Stage=Training, Epoch=1/3, Loss=0.699] 12%|█▏        | 163/1378 [00:34<03:55,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.699]
=== LOSS & METRICS ===
loss_pos: 0.6983
loss_neg: 0.6875
total loss: 0.6929

Probs positive (first 5): tensor([0.4851, 0.5089, 0.4971, 0.5051, 0.5149], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5171, 0.4971, 0.4871, 0.4982, 0.5102], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4976
probs_neg mean: 0.4970

Pred distribution: 0=79, 1=49
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.6562
 12%|█▏        | 163/1378 [00:34<03:55,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.693] 12%|█▏        | 164/1378 [00:34<03:52,  5.21it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6995
loss_neg: 0.6885
total loss: 0.6940

Probs positive (first 5): tensor([0.5097, 0.5271, 0.5034, 0.5055, 0.5040], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4853, 0.4908, 0.4902, 0.4964, 0.4977], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4970
probs_neg mean: 0.4976

Pred distribution: 0=75, 1=53
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.5781
 12%|█▏        | 164/1378 [00:34<03:52,  5.21it/s, Stage=Training, Epoch=1/3, Loss=0.694] 12%|█▏        | 165/1378 [00:34<03:52,  5.21it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6927
loss_neg: 0.6922
total loss: 0.6924

Probs positive (first 5): tensor([0.5052, 0.5107, 0.4878, 0.5176, 0.4938], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4824, 0.4992, 0.5101, 0.4896, 0.5094], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5003
probs_neg mean: 0.4994

Pred distribution: 0=63, 1=65
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.4531
 12%|█▏        | 165/1378 [00:34<03:52,  5.21it/s, Stage=Training, Epoch=1/3, Loss=0.692] 12%|█▏        | 166/1378 [00:34<03:51,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6956
loss_neg: 0.6928
total loss: 0.6942

Probs positive (first 5): tensor([0.4982, 0.5050, 0.5054, 0.5200, 0.5060], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5087, 0.4750, 0.5153, 0.4948, 0.4984], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.4996

Pred distribution: 0=70, 1=58
Label distribution: 0=64, 1=64
Accuracy positive: 0.4219
Accuracy negative: 0.5156
 12%|█▏        | 166/1378 [00:34<03:51,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.694] 12%|█▏        | 167/1378 [00:34<03:49,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6942
loss_neg: 0.6877
total loss: 0.6910

Probs positive (first 5): tensor([0.4929, 0.4899, 0.5160, 0.5057, 0.4814], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5003, 0.5142, 0.5154, 0.5169, 0.4950], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4996
probs_neg mean: 0.4972

Pred distribution: 0=74, 1=54
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.6250
 12%|█▏        | 167/1378 [00:34<03:49,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.691] 12%|█▏        | 168/1378 [00:34<03:49,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6903
loss_neg: 0.6936
total loss: 0.6920

Probs positive (first 5): tensor([0.5030, 0.4972, 0.5043, 0.5098, 0.4982], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4963, 0.5052, 0.5019, 0.5027, 0.4869], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5015
probs_neg mean: 0.5001

Pred distribution: 0=56, 1=72
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.4688
 12%|█▏        | 168/1378 [00:35<03:49,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.692] 12%|█▏        | 169/1378 [00:35<03:49,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6923
loss_neg: 0.6943
total loss: 0.6933

Probs positive (first 5): tensor([0.4784, 0.4845, 0.5035, 0.5052, 0.4996], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4989, 0.5079, 0.5308, 0.5051, 0.5011], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5005
probs_neg mean: 0.5005

Pred distribution: 0=60, 1=68
Label distribution: 0=64, 1=64
Accuracy positive: 0.5156
Accuracy negative: 0.4531
 12%|█▏        | 169/1378 [00:35<03:49,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.693] 12%|█▏        | 170/1378 [00:35<03:48,  5.29it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6932
loss_neg: 0.6983
total loss: 0.6957

Probs positive (first 5): tensor([0.4749, 0.4884, 0.4850, 0.4944, 0.5067], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4925, 0.4939, 0.5185, 0.5153, 0.5006], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5001
probs_neg mean: 0.5024

Pred distribution: 0=57, 1=71
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.3750
 12%|█▏        | 170/1378 [00:35<03:48,  5.29it/s, Stage=Training, Epoch=1/3, Loss=0.696] 12%|█▏        | 171/1378 [00:35<03:49,  5.26it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6875
loss_neg: 0.6896
total loss: 0.6886

Probs positive (first 5): tensor([0.5010, 0.4966, 0.5176, 0.4884, 0.5013], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5020, 0.5138, 0.4976, 0.5032, 0.4980], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5029
probs_neg mean: 0.4981

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.6250
Accuracy negative: 0.5312
 12%|█▏        | 171/1378 [00:35<03:49,  5.26it/s, Stage=Training, Epoch=1/3, Loss=0.689] 12%|█▏        | 172/1378 [00:35<03:51,  5.21it/s, Stage=Training, Epoch=1/3, Loss=0.689]
=== LOSS & METRICS ===
loss_pos: 0.6943
loss_neg: 0.6941
total loss: 0.6942

Probs positive (first 5): tensor([0.4962, 0.5058, 0.5202, 0.4924, 0.4947], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5031, 0.5083, 0.5026, 0.4927, 0.5068], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4995
probs_neg mean: 0.5004

Pred distribution: 0=58, 1=70
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.4062
 12%|█▏        | 172/1378 [00:35<03:51,  5.21it/s, Stage=Training, Epoch=1/3, Loss=0.694] 13%|█▎        | 173/1378 [00:35<03:53,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6908
loss_neg: 0.6913
total loss: 0.6911

Probs positive (first 5): tensor([0.5076, 0.4832, 0.5013, 0.5014, 0.5063], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4911, 0.4998, 0.4949, 0.5310, 0.5058], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5013
probs_neg mean: 0.4990

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.5312
Accuracy negative: 0.5781
 13%|█▎        | 173/1378 [00:36<03:53,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.691] 13%|█▎        | 174/1378 [00:36<03:54,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6904
loss_neg: 0.6925
total loss: 0.6915

Probs positive (first 5): tensor([0.5182, 0.5068, 0.4995, 0.4826, 0.5031], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4961, 0.5038, 0.5220, 0.4985, 0.5146], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5015
probs_neg mean: 0.4996

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.5156
 13%|█▎        | 174/1378 [00:36<03:54,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.691] 13%|█▎        | 175/1378 [00:36<03:53,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6955
loss_neg: 0.6934
total loss: 0.6945

Probs positive (first 5): tensor([0.4891, 0.5155, 0.5103, 0.5006, 0.4718], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4915, 0.4844, 0.4970, 0.4969, 0.4861], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.5000

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.5469
 13%|█▎        | 175/1378 [00:36<03:53,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.694] 13%|█▎        | 176/1378 [00:36<03:55,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6925
loss_neg: 0.6955
total loss: 0.6940

Probs positive (first 5): tensor([0.5124, 0.4966, 0.4897, 0.5109, 0.5086], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4942, 0.5019, 0.4872, 0.5118, 0.5011], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5005
probs_neg mean: 0.5010

Pred distribution: 0=65, 1=63
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.5000
 13%|█▎        | 176/1378 [00:36<03:55,  5.11it/s, Stage=Training, Epoch=1/3, Loss=0.694] 13%|█▎        | 177/1378 [00:36<03:55,  5.10it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6885
loss_neg: 0.6990
total loss: 0.6937

Probs positive (first 5): tensor([0.5140, 0.4898, 0.5135, 0.5052, 0.4998], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5223, 0.5099, 0.4969, 0.4834, 0.5011], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5025
probs_neg mean: 0.5028

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.4062
 13%|█▎        | 177/1378 [00:36<03:55,  5.10it/s, Stage=Training, Epoch=1/3, Loss=0.694] 13%|█▎        | 178/1378 [00:36<03:53,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6884
loss_neg: 0.6911
total loss: 0.6898

Probs positive (first 5): tensor([0.4992, 0.5061, 0.4984, 0.4908, 0.5051], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4947, 0.5043, 0.4950, 0.4951, 0.4918], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5025
probs_neg mean: 0.4989

Pred distribution: 0=63, 1=65
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.5312
 13%|█▎        | 178/1378 [00:37<03:53,  5.14it/s, Stage=Training, Epoch=1/3, Loss=0.69]  13%|█▎        | 179/1378 [00:37<03:50,  5.19it/s, Stage=Training, Epoch=1/3, Loss=0.69]
=== LOSS & METRICS ===
loss_pos: 0.6880
loss_neg: 0.6964
total loss: 0.6922

Probs positive (first 5): tensor([0.5037, 0.4909, 0.5032, 0.5106, 0.4955], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5011, 0.4917, 0.5043, 0.5125, 0.5193], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5027
probs_neg mean: 0.5016

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4531
 13%|█▎        | 179/1378 [00:37<03:50,  5.19it/s, Stage=Training, Epoch=1/3, Loss=0.692] 13%|█▎        | 180/1378 [00:37<03:49,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6849
loss_neg: 0.6999
total loss: 0.6924

Probs positive (first 5): tensor([0.5091, 0.4990, 0.4975, 0.4987, 0.5235], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5057, 0.4932, 0.5195, 0.5093, 0.5182], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5043
probs_neg mean: 0.5032

Pred distribution: 0=54, 1=74
Label distribution: 0=64, 1=64
Accuracy positive: 0.5469
Accuracy negative: 0.3906
 13%|█▎        | 180/1378 [00:37<03:49,  5.22it/s, Stage=Training, Epoch=1/3, Loss=0.692] 13%|█▎        | 181/1378 [00:37<03:47,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6871
loss_neg: 0.7007
total loss: 0.6939

Probs positive (first 5): tensor([0.5029, 0.5371, 0.4998, 0.4893, 0.5154], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5011, 0.5050, 0.4971, 0.4976, 0.4900], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5032
probs_neg mean: 0.5036

Pred distribution: 0=49, 1=79
Label distribution: 0=64, 1=64
Accuracy positive: 0.5625
Accuracy negative: 0.3281
 13%|█▎        | 181/1378 [00:37<03:47,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.694] 13%|█▎        | 182/1378 [00:37<03:41,  5.41it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6866
loss_neg: 0.7029
total loss: 0.6948

Probs positive (first 5): tensor([0.4864, 0.5296, 0.5035, 0.5083, 0.4791], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5049, 0.4886, 0.4981, 0.4980, 0.5127], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5034
probs_neg mean: 0.5048

Pred distribution: 0=44, 1=84
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.2812
 13%|█▎        | 182/1378 [00:37<03:41,  5.41it/s, Stage=Training, Epoch=1/3, Loss=0.695] 13%|█▎        | 183/1378 [00:37<03:35,  5.54it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6831
loss_neg: 0.7005
total loss: 0.6918

Probs positive (first 5): tensor([0.4836, 0.5217, 0.5001, 0.5104, 0.4853], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5166, 0.5022, 0.4926, 0.4980, 0.5162], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5052
probs_neg mean: 0.5035

Pred distribution: 0=48, 1=80
Label distribution: 0=64, 1=64
Accuracy positive: 0.6562
Accuracy negative: 0.4062
 13%|█▎        | 183/1378 [00:37<03:35,  5.54it/s, Stage=Training, Epoch=1/3, Loss=0.692] 13%|█▎        | 184/1378 [00:37<03:36,  5.51it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6868
loss_neg: 0.7028
total loss: 0.6948

Probs positive (first 5): tensor([0.4943, 0.5168, 0.4918, 0.5231, 0.5071], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5225, 0.5088, 0.5096, 0.5081, 0.5165], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5033
probs_neg mean: 0.5047

Pred distribution: 0=49, 1=79
Label distribution: 0=64, 1=64
Accuracy positive: 0.5938
Accuracy negative: 0.3594
 13%|█▎        | 184/1378 [00:38<03:36,  5.51it/s, Stage=Training, Epoch=1/3, Loss=0.695] 13%|█▎        | 185/1378 [00:38<03:38,  5.46it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6820
loss_neg: 0.7069
total loss: 0.6945

Probs positive (first 5): tensor([0.4946, 0.5067, 0.5057, 0.5201, 0.5181], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5234, 0.5169, 0.5077, 0.5157, 0.5102], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5057
probs_neg mean: 0.5067

Pred distribution: 0=34, 1=94
Label distribution: 0=64, 1=64
Accuracy positive: 0.7188
Accuracy negative: 0.2500
 13%|█▎        | 185/1378 [00:38<03:38,  5.46it/s, Stage=Training, Epoch=1/3, Loss=0.694] 13%|█▎        | 186/1378 [00:38<03:40,  5.41it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6809
loss_neg: 0.7027
total loss: 0.6918

Probs positive (first 5): tensor([0.5291, 0.5064, 0.4900, 0.5045, 0.4962], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4974, 0.5018, 0.4846, 0.5022, 0.5230], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5062
probs_neg mean: 0.5047

Pred distribution: 0=40, 1=88
Label distribution: 0=64, 1=64
Accuracy positive: 0.7031
Accuracy negative: 0.3281
 13%|█▎        | 186/1378 [00:38<03:40,  5.41it/s, Stage=Training, Epoch=1/3, Loss=0.692] 14%|█▎        | 187/1378 [00:38<03:41,  5.39it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6748
loss_neg: 0.7089
total loss: 0.6918

Probs positive (first 5): tensor([0.5083, 0.5120, 0.5105, 0.5132, 0.5182], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5048, 0.5032, 0.5237, 0.4999, 0.5018], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5094
probs_neg mean: 0.5077

Pred distribution: 0=26, 1=102
Label distribution: 0=64, 1=64
Accuracy positive: 0.8281
Accuracy negative: 0.2344
 14%|█▎        | 187/1378 [00:38<03:41,  5.39it/s, Stage=Training, Epoch=1/3, Loss=0.692] 14%|█▎        | 188/1378 [00:38<03:46,  5.25it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6826
loss_neg: 0.7065
total loss: 0.6946

Probs positive (first 5): tensor([0.4996, 0.5157, 0.5014, 0.4929, 0.5244], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5114, 0.5163, 0.5106, 0.5043, 0.5161], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5054
probs_neg mean: 0.5065

Pred distribution: 0=37, 1=91
Label distribution: 0=64, 1=64
Accuracy positive: 0.7031
Accuracy negative: 0.2812
 14%|█▎        | 188/1378 [00:38<03:46,  5.25it/s, Stage=Training, Epoch=1/3, Loss=0.695] 14%|█▎        | 189/1378 [00:38<03:45,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6774
loss_neg: 0.7060
total loss: 0.6917

Probs positive (first 5): tensor([0.5224, 0.4960, 0.5265, 0.4971, 0.5165], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5100, 0.5029, 0.5334, 0.5049, 0.5120], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5081
probs_neg mean: 0.5063

Pred distribution: 0=30, 1=98
Label distribution: 0=64, 1=64
Accuracy positive: 0.7656
Accuracy negative: 0.2344
 14%|█▎        | 189/1378 [00:39<03:45,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.692] 14%|█▍        | 190/1378 [00:39<03:46,  5.25it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6847
loss_neg: 0.7052
total loss: 0.6949

Probs positive (first 5): tensor([0.5007, 0.5127, 0.4963, 0.5000, 0.5248], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5406, 0.5081, 0.4983, 0.5121, 0.4965], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5044
probs_neg mean: 0.5059

Pred distribution: 0=37, 1=91
Label distribution: 0=64, 1=64
Accuracy positive: 0.6719
Accuracy negative: 0.2500
 14%|█▍        | 190/1378 [00:39<03:46,  5.25it/s, Stage=Training, Epoch=1/3, Loss=0.695] 14%|█▍        | 191/1378 [00:39<03:46,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6803
loss_neg: 0.7120
total loss: 0.6962

Probs positive (first 5): tensor([0.5171, 0.5188, 0.5137, 0.5137, 0.5211], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5206, 0.5058, 0.5028, 0.5069, 0.5062], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5066
probs_neg mean: 0.5092

Pred distribution: 0=26, 1=102
Label distribution: 0=64, 1=64
Accuracy positive: 0.7969
Accuracy negative: 0.2031
 14%|█▍        | 191/1378 [00:39<03:46,  5.24it/s, Stage=Training, Epoch=1/3, Loss=0.696] 14%|█▍        | 192/1378 [00:39<03:50,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6758
loss_neg: 0.7122
total loss: 0.6940

Probs positive (first 5): tensor([0.5446, 0.5297, 0.4816, 0.5047, 0.5009], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4962, 0.4967, 0.4963, 0.5187, 0.5013], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5088
probs_neg mean: 0.5093

Pred distribution: 0=24, 1=104
Label distribution: 0=64, 1=64
Accuracy positive: 0.7969
Accuracy negative: 0.1719
 14%|█▍        | 192/1378 [00:39<03:50,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.694] 14%|█▍        | 193/1378 [00:39<03:48,  5.19it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6751
loss_neg: 0.7120
total loss: 0.6935

Probs positive (first 5): tensor([0.5181, 0.5288, 0.5149, 0.5122, 0.5031], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5053, 0.4967, 0.5283, 0.5153, 0.4985], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5092
probs_neg mean: 0.5092

Pred distribution: 0=21, 1=107
Label distribution: 0=64, 1=64
Accuracy positive: 0.8438
Accuracy negative: 0.1719
 14%|█▍        | 193/1378 [00:39<03:48,  5.19it/s, Stage=Training, Epoch=1/3, Loss=0.694] 14%|█▍        | 194/1378 [00:39<03:50,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6767
loss_neg: 0.7087
total loss: 0.6927

Probs positive (first 5): tensor([0.5094, 0.5274, 0.5055, 0.5117, 0.4906], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4922, 0.5219, 0.5077, 0.5104, 0.5020], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5084
probs_neg mean: 0.5076

Pred distribution: 0=30, 1=98
Label distribution: 0=64, 1=64
Accuracy positive: 0.7344
Accuracy negative: 0.2031
 14%|█▍        | 194/1378 [00:40<03:50,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.693] 14%|█▍        | 195/1378 [00:40<03:49,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6757
loss_neg: 0.7076
total loss: 0.6917

Probs positive (first 5): tensor([0.5172, 0.4837, 0.4890, 0.5033, 0.5098], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5101, 0.4960, 0.5135, 0.5022, 0.5209], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5089
probs_neg mean: 0.5070

Pred distribution: 0=31, 1=97
Label distribution: 0=64, 1=64
Accuracy positive: 0.7344
Accuracy negative: 0.2188
 14%|█▍        | 195/1378 [00:40<03:49,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.692] 14%|█▍        | 196/1378 [00:40<03:47,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6807
loss_neg: 0.7109
total loss: 0.6958

Probs positive (first 5): tensor([0.5148, 0.5258, 0.5247, 0.5171, 0.5011], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5026, 0.5323, 0.5275, 0.5158, 0.5046], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5064
probs_neg mean: 0.5086

Pred distribution: 0=33, 1=95
Label distribution: 0=64, 1=64
Accuracy positive: 0.7344
Accuracy negative: 0.2500
 14%|█▍        | 196/1378 [00:40<03:47,  5.20it/s, Stage=Training, Epoch=1/3, Loss=0.696] 14%|█▍        | 197/1378 [00:40<03:47,  5.19it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6780
loss_neg: 0.7040
total loss: 0.6910

Probs positive (first 5): tensor([0.5014, 0.5010, 0.5125, 0.5323, 0.5009], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4985, 0.5099, 0.5098, 0.4826, 0.4901], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5078
probs_neg mean: 0.5052

Pred distribution: 0=38, 1=90
Label distribution: 0=64, 1=64
Accuracy positive: 0.7344
Accuracy negative: 0.3281
 14%|█▍        | 197/1378 [00:40<03:47,  5.19it/s, Stage=Training, Epoch=1/3, Loss=0.691] 14%|█▍        | 198/1378 [00:40<03:48,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6835
loss_neg: 0.7047
total loss: 0.6941

Probs positive (first 5): tensor([0.5034, 0.5077, 0.5075, 0.4983, 0.5043], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5007, 0.5314, 0.5225, 0.5167, 0.5073], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5049
probs_neg mean: 0.5056

Pred distribution: 0=45, 1=83
Label distribution: 0=64, 1=64
Accuracy positive: 0.6406
Accuracy negative: 0.3438
 14%|█▍        | 198/1378 [00:40<03:48,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.694] 14%|█▍        | 199/1378 [00:40<03:49,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6860
loss_neg: 0.7052
total loss: 0.6956

Probs positive (first 5): tensor([0.4902, 0.5070, 0.5017, 0.4991, 0.4899], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5013, 0.5184, 0.5018, 0.5102, 0.4841], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5037
probs_neg mean: 0.5059

Pred distribution: 0=45, 1=83
Label distribution: 0=64, 1=64
Accuracy positive: 0.6250
Accuracy negative: 0.3281
 14%|█▍        | 199/1378 [00:41<03:49,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.696] 15%|█▍        | 200/1378 [00:41<03:51,  5.10it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6900
loss_neg: 0.6991
total loss: 0.6946

Probs positive (first 5): tensor([0.4959, 0.5104, 0.5034, 0.5018, 0.5056], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5184, 0.4988, 0.4873, 0.5114, 0.4995], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5017
probs_neg mean: 0.5028

Pred distribution: 0=52, 1=76
Label distribution: 0=64, 1=64
Accuracy positive: 0.6094
Accuracy negative: 0.4219
 15%|█▍        | 200/1378 [00:41<03:51,  5.10it/s, Stage=Training, Epoch=1/3, Loss=0.695] 15%|█▍        | 201/1378 [00:41<03:48,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6931
loss_neg: 0.7002
total loss: 0.6967

Probs positive (first 5): tensor([0.5101, 0.4891, 0.5037, 0.4877, 0.5014], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4993, 0.5133, 0.4963, 0.4922, 0.5261], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5001
probs_neg mean: 0.5034

Pred distribution: 0=53, 1=75
Label distribution: 0=64, 1=64
Accuracy positive: 0.5000
Accuracy negative: 0.3281
 15%|█▍        | 201/1378 [00:41<03:48,  5.15it/s, Stage=Training, Epoch=1/3, Loss=0.697] 15%|█▍        | 202/1378 [00:41<03:45,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.697]
=== LOSS & METRICS ===
loss_pos: 0.6932
loss_neg: 0.6926
total loss: 0.6929

Probs positive (first 5): tensor([0.4965, 0.4898, 0.4986, 0.4937, 0.4902], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5101, 0.4991, 0.5101, 0.5098, 0.5096], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5001
probs_neg mean: 0.4996

Pred distribution: 0=70, 1=58
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.5625
 15%|█▍        | 202/1378 [00:41<03:45,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.693] 15%|█▍        | 203/1378 [00:41<03:37,  5.40it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6959
loss_neg: 0.6966
total loss: 0.6963

Probs positive (first 5): tensor([0.4918, 0.5049, 0.4900, 0.4986, 0.4907], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5203, 0.5119, 0.4882, 0.5155, 0.4933], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4987
probs_neg mean: 0.5016

Pred distribution: 0=67, 1=61
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.4844
 15%|█▍        | 203/1378 [00:41<03:37,  5.40it/s, Stage=Training, Epoch=1/3, Loss=0.696] 15%|█▍        | 204/1378 [00:41<03:37,  5.41it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6918
loss_neg: 0.6926
total loss: 0.6922

Probs positive (first 5): tensor([0.5208, 0.4960, 0.5113, 0.4959, 0.4906], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4920, 0.4976, 0.4906, 0.5047, 0.5015], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.5008
probs_neg mean: 0.4996

Pred distribution: 0=69, 1=59
Label distribution: 0=64, 1=64
Accuracy positive: 0.4688
Accuracy negative: 0.5469
 15%|█▍        | 204/1378 [00:42<03:37,  5.41it/s, Stage=Training, Epoch=1/3, Loss=0.692] 15%|█▍        | 205/1378 [00:42<03:37,  5.40it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6976
loss_neg: 0.6921
total loss: 0.6948

Probs positive (first 5): tensor([0.5046, 0.5005, 0.4996, 0.5004, 0.4928], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5000, 0.4947, 0.4954, 0.4937, 0.4931], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4978
probs_neg mean: 0.4994

Pred distribution: 0=71, 1=57
Label distribution: 0=64, 1=64
Accuracy positive: 0.3906
Accuracy negative: 0.5000
 15%|█▍        | 205/1378 [00:42<03:37,  5.40it/s, Stage=Training, Epoch=1/3, Loss=0.695] 15%|█▍        | 206/1378 [00:42<03:39,  5.35it/s, Stage=Training, Epoch=1/3, Loss=0.695]
=== LOSS & METRICS ===
loss_pos: 0.6983
loss_neg: 0.6862
total loss: 0.6923

Probs positive (first 5): tensor([0.4928, 0.4968, 0.5044, 0.5016, 0.5066], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5030, 0.4994, 0.5074, 0.4959, 0.4895], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4975
probs_neg mean: 0.4965

Pred distribution: 0=87, 1=41
Label distribution: 0=64, 1=64
Accuracy positive: 0.3438
Accuracy negative: 0.7031
 15%|█▍        | 206/1378 [00:42<03:39,  5.35it/s, Stage=Training, Epoch=1/3, Loss=0.692] 15%|█▌        | 207/1378 [00:42<03:39,  5.35it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6955
loss_neg: 0.6891
total loss: 0.6923

Probs positive (first 5): tensor([0.5143, 0.4985, 0.5023, 0.4994, 0.4865], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4868, 0.4791, 0.4936, 0.4866, 0.5024], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.4979

Pred distribution: 0=68, 1=60
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.5469
 15%|█▌        | 207/1378 [00:42<03:39,  5.35it/s, Stage=Training, Epoch=1/3, Loss=0.692] 15%|█▌        | 208/1378 [00:42<03:38,  5.34it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.6960
loss_neg: 0.6929
total loss: 0.6944

Probs positive (first 5): tensor([0.5172, 0.4991, 0.4948, 0.4910, 0.4841], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.5083, 0.4979, 0.4913, 0.4921, 0.5248], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4987
probs_neg mean: 0.4998

Pred distribution: 0=76, 1=52
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.6250
 15%|█▌        | 208/1378 [00:42<03:38,  5.34it/s, Stage=Training, Epoch=1/3, Loss=0.694] 15%|█▌        | 209/1378 [00:42<03:39,  5.33it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.7013
loss_neg: 0.6913
total loss: 0.6963

Probs positive (first 5): tensor([0.4990, 0.4926, 0.4859, 0.4975, 0.4892], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4986, 0.4834, 0.4913, 0.5109, 0.4888], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4960
probs_neg mean: 0.4990

Pred distribution: 0=77, 1=51
Label distribution: 0=64, 1=64
Accuracy positive: 0.3281
Accuracy negative: 0.5312
 15%|█▌        | 209/1378 [00:42<03:39,  5.33it/s, Stage=Training, Epoch=1/3, Loss=0.696] 15%|█▌        | 210/1378 [00:42<03:41,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.696]
=== LOSS & METRICS ===
loss_pos: 0.6962
loss_neg: 0.6882
total loss: 0.6922

Probs positive (first 5): tensor([0.4697, 0.4878, 0.4998, 0.4988, 0.4969], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4926, 0.4905, 0.4952, 0.5027, 0.4998], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4986
probs_neg mean: 0.4974

Pred distribution: 0=74, 1=54
Label distribution: 0=64, 1=64
Accuracy positive: 0.4844
Accuracy negative: 0.6406
 15%|█▌        | 210/1378 [00:43<03:41,  5.28it/s, Stage=Training, Epoch=1/3, Loss=0.692] 15%|█▌        | 211/1378 [00:43<03:41,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.692]
=== LOSS & METRICS ===
loss_pos: 0.7003
loss_neg: 0.6868
total loss: 0.6935

Probs positive (first 5): tensor([0.4940, 0.4895, 0.4986, 0.4831, 0.4949], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4890, 0.5046, 0.5061, 0.5066, 0.5022], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4966
probs_neg mean: 0.4967

Pred distribution: 0=83, 1=45
Label distribution: 0=64, 1=64
Accuracy positive: 0.3281
Accuracy negative: 0.6250
 15%|█▌        | 211/1378 [00:43<03:41,  5.27it/s, Stage=Training, Epoch=1/3, Loss=0.694] 15%|█▌        | 212/1378 [00:43<03:43,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.694]
=== LOSS & METRICS ===
loss_pos: 0.6979
loss_neg: 0.6872
total loss: 0.6926

Probs positive (first 5): tensor([0.4961, 0.4977, 0.4908, 0.4973, 0.5029], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4993, 0.4835, 0.4913, 0.4928, 0.5132], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4977
probs_neg mean: 0.4969

Pred distribution: 0=79, 1=49
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.6406
 15%|█▌        | 212/1378 [00:43<03:43,  5.23it/s, Stage=Training, Epoch=1/3, Loss=0.693] 15%|█▌        | 213/1378 [00:43<03:45,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.693]
=== LOSS & METRICS ===
loss_pos: 0.6974
loss_neg: 0.6851
total loss: 0.6912

Probs positive (first 5): tensor([0.4888, 0.4974, 0.5094, 0.4943, 0.4947], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4903, 0.4948, 0.4956, 0.4883, 0.4970], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4980
probs_neg mean: 0.4959

Pred distribution: 0=80, 1=48
Label distribution: 0=64, 1=64
Accuracy positive: 0.4062
Accuracy negative: 0.6562
 15%|█▌        | 213/1378 [00:43<03:45,  5.16it/s, Stage=Training, Epoch=1/3, Loss=0.691] 16%|█▌        | 214/1378 [00:43<03:45,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.691]
=== LOSS & METRICS ===
loss_pos: 0.6954
loss_neg: 0.6911
total loss: 0.6933

Probs positive (first 5): tensor([0.5013, 0.5023, 0.4928, 0.4955, 0.5141], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4918, 0.5011, 0.5078, 0.4933, 0.4732], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4989
probs_neg mean: 0.4989

Pred distribution: 0=71, 1=57
Label distribution: 0=64, 1=64
Accuracy positive: 0.4375
Accuracy negative: 0.5469
 16%|█▌        | 214/1378 [00:43<03:45,  5.17it/s, Stage=Training, Epoch=1/3, Loss=0.693] 16%|█▌        | 215/1378 [00:43<03:46,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.693]slurmstepd: error: *** JOB 3503304 ON cn-007 CANCELLED AT 2025-12-23T13:19:31 ***

=== LOSS & METRICS ===
loss_pos: 0.6965
loss_neg: 0.6882
total loss: 0.6923

Probs positive (first 5): tensor([0.5164, 0.4864, 0.4895, 0.4917, 0.4909], device='cuda:0',
       grad_fn=<SliceBackward0>)
Probs negative (first 5): tensor([0.4748, 0.4897, 0.4852, 0.4941, 0.5029], device='cuda:0',
       grad_fn=<SliceBackward0>)
probs_pos mean: 0.4984
probs_neg mean: 0.4975

Pred distribution: 0=78, 1=50
Label distribution: 0=64, 1=64
Accuracy positive: 0.3750
Accuracy negative: 0.5938
 16%|█▌        | 215/1378 [00:44<03:46,  5.13it/s, Stage=Training, Epoch=1/3, Loss=0.692] 16%|█▌        | 216/1378 [00:44<03:40,  5.26it/s, Stage=Training, Epoch=1/3, Loss=0.692]